# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2023-09-21 08:08+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "ebernard"
msgstr "ebernardo"

#. type: YAML Front Matter: date
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "2020-04-21"
msgstr "2020-04-21"

#. type: YAML Front Matter: layout
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "post"
msgstr "posto"

#. type: YAML Front Matter: synopsis
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "Understand when and how to use the Quarkus IO thread and its influence on microbenchmarks."
msgstr "Compreender quando e como utilizar a thread IO do Quarkus e a sua influência nos microbenchmarks."

#. type: YAML Front Matter: tags
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "performance"
msgstr "desempenho"

#. type: YAML Front Matter: title
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "A IO thread and a worker thread walk into a bar: a microbenchmark story"
msgstr "Uma thread de IO e uma thread de trabalho entram em um bar: uma história de microbenchmark"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:17
#, fuzzy
msgid "A competitor recently published a microbenchmark comparing the performance of their stack to Quarkus.  The Quarkus team feels this microbenchmark shouldn’t be taken at face value because it wasn’t making a like-to-like comparison leading to incorrect conclusions.  Both of the two frameworks under comparison support reactive processing.  Reactive processing enables running the business logic directly on the _IO thread_, which ultimately performs better in microbenchmark focusing on response time and concurrency.  The microbenchmark should have been written so that both frameworks (or neither framework) obtain this benefit.  Anyway, this turns out to be a very interesting topic and good information for Quarkus users, so read on."
msgstr "Um concorrente publicou recentemente um microbenchmark comparando o desempenho de sua pilha com o Quarkus. A equipa do Quarkus considera que este microbenchmark não deve ser tomado pelo seu valor nominal, uma vez que não foi feita uma comparação entre pares, o que levou a conclusões incorrectas. Ambas as estruturas em comparação suportam processamento reativo. O processamento reativo permite executar a lógica empresarial diretamente na _thread de E/S_, o que acaba por ter um melhor desempenho em microbenchmark centrado no tempo de resposta e na concorrência. O microbenchmark deveria ter sido escrito de modo que ambas as estruturas (ou nenhuma delas) obtivessem esse benefício. De qualquer forma, este é um tópico muito interessante e uma boa informação para os utilizadores do Quarkus, por isso, continue a ler."

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:18
#, fuzzy, no-wrap
msgid "tl; dr;"
msgstr "tl; dr;"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:22
#, fuzzy
msgid "Quarkus https://quarkus.io/blog/runtime-performance/[has great performance] for both imperative and reactive workloads.  It’s because Quarkus is itself based on Eclipse Vert.x, a mature top performing reactive framework, in such a way that allows you to layer, mix and match the IO paradigm that best fits your use-case."
msgstr "O Quarkus  link:https://quarkus.io/blog/runtime-performance/[tem um excelente desempenho] tanto para cargas de trabalho imperativas como reactivas. Isto deve-se ao facto de o Quarkus se basear no Eclipse Vert.x, uma estrutura reactiva madura e de elevado desempenho, de tal forma que lhe permite criar camadas, misturar e combinar o paradigma de IO que melhor se adequa ao seu caso de utilização."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:24
#, fuzzy
msgid "If you have a REST scenario well suited to run _purely on the IO thread_, add a Vert.x Reactive Route using https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] and your app will get better performance than using Quarkus RESTEasy."
msgstr "Se tiver um cenário REST adequado para ser executado _exclusivamente na thread IO_, adicione uma rota reactiva Vert.x utilizando  link:https://quarkus.io/guides/reactive-routes[o Quarkus Reactive Routes] e a sua aplicação obterá um melhor desempenho do que utilizando o Quarkus RESTEasy."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:28
#, fuzzy
msgid "We ran this low-work REST + validation competitor-written microbenchmark which features no blocking operation, just returning static data.  When using Quarkus Reactive Routes to run Quarkus _purely on the IO thread_, **we observed 2.6x times the requests/sec and 30% less memory usage (RSS)** than running with Quarkus RESTEasy (which mixes IO thread and worker thread).  But that’s on a microbenchmark purpose built to this specific scenario (more on that later)."
msgstr "Executamos este microbenchmark REST de baixo trabalho + validação escrito por um concorrente que não apresenta nenhuma operação de bloqueio, apenas retornando dados estáticos. Ao usar o Quarkus Reactive Routes para executar o Quarkus _puramente na thread de IO_, observamos *2,6 vezes mais solicitações/segundo e 30% menos uso de memória (RSS)* do que ao executar com o Quarkus RESTEasy (que mistura thread de IO e thread de trabalho). Mas isso é num microbenchmark criado para este cenário específico (mais sobre isso mais tarde)."

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:29
#, no-wrap
msgid "throughput.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:31
#, fuzzy, no-wrap
msgid "More interesting read"
msgstr "Ler mais interessante"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:35
#, fuzzy
msgid "The microbenchmark itself is uninteresting, but it is a good demonstrator of a phenomenon that can happen in reactive stacks.  Let’s use it as a vehicle to learn more about Quarkus and its reactive engine."
msgstr "O microbenchmark em si não é interessante, mas é um bom demonstrador de um fenómeno que pode acontecer em pilhas reactivas. Vamos usá-lo como um veículo para aprender mais sobre o Quarkus e seu mecanismo reativo."

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:36
#, fuzzy, no-wrap
msgid "Imperative and Reactive: the elevator pitch"
msgstr "Imperativo e Reativo: o elevator pitch"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:40
#, fuzzy
msgid "This blog post does not explain the fundamental differences between the imperative execution model and the reactive execution model.  However, to understand why we see so much difference in the mentioned microbenchmark, we need some notions."
msgstr "Esta publicação do blogue não explica as diferenças fundamentais entre o modelo de execução imperativo e o modelo de execução reativo. No entanto, para entender por que vemos tanta diferença no microbenchmark mencionado, precisamos de algumas noções."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:49
#, fuzzy
msgid "In general, Java web applications use imperative programming combined with blocking IO operations.  This is incredibly popular because it is easier to reason about the code.  _Things_ get executed sequentially.  To make sure one request is not affected by another, they are run on different threads.  When your workload needs to interact with a database or another remote service, it relies on blocking IO.  The thread is blocked waiting for the answer.  Other requests running on different threads are not slowed down significantly.  But this means one thread for every concurrent request, which limits the overall concurrency."
msgstr "Em geral, as aplicações Web Java utilizam programação imperativa combinada com operações de IO bloqueantes. Isso é incrivelmente popular porque é mais fácil raciocinar sobre o código. _As coisas_ são executadas sequencialmente. Para garantir que um pedido não é afetado por outro, estes são executados em threads diferentes. Quando sua carga de trabalho precisa interagir com um banco de dados ou outro serviço remoto, ela depende do bloqueio de IO. A thread fica bloqueada à espera da resposta. Outros pedidos executados em threads diferentes não sofrem um abrandamento significativo. Mas isso significa um thread para cada pedido simultâneo, o que limita a simultaneidade geral."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:64
#, fuzzy
msgid "On the other side, the reactive execution model embraces asynchronous development models and non blocking IOs.  With this model, multiple requests can be handled by the same thread.  When the processing of a request cannot make progress anymore (because it requests a remote service, or interacts with a database), it uses non blocking IO.  This releases the thread immediately, which can then be used to serve another request.  When the result of the IO operation is available, the processing of the request is restored and continues its execution.  This model enables the usage of the _IO thread_ to handle multiple requests.  There are two significant benefits.  First, the response time is smaller because it does not have to jump to another thread.  Second, it reduces memory consumption as it decreases the usage of threads.  The reactive model uses the hardware resources more efficiently, but... there is a significant drawback.  If the processing of a request starts to block, this gets real bad.  No other request can be handled.  To avoid this, you need to learn how to write non blocking code, how to structure asynchronous processing, and how to use non blocking IOs.  It's a paradigm shift."
msgstr "Por outro lado, o modelo de execução reativo inclui modelos de desenvolvimento assíncronos e IOs não bloqueantes. Com este modelo, vários pedidos podem ser tratados pela mesma thread. Quando o processamento de um pedido não pode continuar a progredir (porque solicita um serviço remoto ou interage com uma base de dados), é utilizada uma IO não bloqueante. Isso libera o thread imediatamente, que pode então ser usado para atender a outro pedido. Quando o resultado da operação de IO estiver disponível, o processamento do pedido é restaurado e continua a sua execução. Este modelo permite a utilização da _thread de IO_ para tratar vários pedidos. Há dois benefícios significativos. Primeiro, o tempo de resposta é menor porque não é necessário saltar para outro thread. Segundo, reduz o consumo de memória, pois diminui o uso de threads. O modelo reativo utiliza os recursos de hardware de forma mais eficiente, mas... tem um inconveniente significativo. Se o processamento de um pedido começar a bloquear, isto torna-se muito mau. Nenhum outro pedido pode ser tratado. Para evitar isso, é preciso aprender a escrever código não bloqueante, como estruturar o processamento assíncrono e como usar IOs não bloqueantes. É uma mudança de paradigma."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:68
#, fuzzy
msgid "In Quarkus, we want to make the shift as easy as possible.  However, we have observed that the majority of user applications are written using the imperative model.  That is why, when the user application uses JAX-RS, Quarkus defaults to execute the (imperative) workload to a _worker thread_."
msgstr "No Quarkus, queremos tornar a mudança o mais fácil possível. No entanto, observámos que a maioria das aplicações de utilizador são escritas utilizando o modelo imperativo. É por isso que, quando a aplicação do utilizador utiliza JAX-RS, o Quarkus executa por defeito a carga de trabalho (imperativa) numa _thread de_ trabalho."

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:69
#, fuzzy, no-wrap
msgid "Hello world microbenchmark: IO thread or worker thread?"
msgstr "Microbenchmark Hello world: thread de IO ou thread de trabalho?"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:74
#, fuzzy
msgid "Back to the competitor’s microbenchmark, we have a REST endpoint doing some trivial processing and some equally trivial validation.  Pretty much no meaningful business work.  This is the Hello World of REST for all intents and purposes."
msgstr "Voltando ao microbenchmark do concorrente, temos um ponto de extremidade REST a efetuar um processamento trivial e uma validação igualmente trivial. Praticamente nenhum trabalho comercial significativo. Para todos os efeitos, este é o Hello World do REST."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:79
#, fuzzy
msgid "When you run the microbenchmark with Quarkus RESTEasy, the request is handled by the reactive engine on the _IO thread_ but then the processing work is handed over to a second thread from the _worker thread pool_.  That’s called _dispatch_.  When your microbenchmark does as little as Hello World, then the dispatch overhead is proportionally big.  The dispatch overhead is not visible in most (real life) applications but is very visible in artificial constructs like microbenchmarks."
msgstr "Quando se executa o microbenchmark com o Quarkus RESTEasy, o pedido é tratado pelo motor reativo na _thread IO_, mas depois o trabalho de processamento é entregue a uma segunda thread do _pool de threads de_ trabalho. Isso é chamado de _despacho_. Quando seu microbenchmark faz tão pouco quanto Hello World, então a sobrecarga de despacho é proporcionalmente grande. A sobrecarga de despacho não é visível na maioria das aplicações (da vida real), mas é muito visível em construções artificiais como microbenchmarks."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:83
#, fuzzy
msgid "The competitor’s stack, however, runs all the request operations on the IO thread by default.  So what this microbenchmark was actually comparing is just the cost of dispatching to the worker thread pool.  And frankly (according to the competitor's numbers) and in spite of this extra dispatch work, Quarkus did very very well achieving ~95% of the competitor’s throughput today! I say today because we are always improving upon performance, and in fact we expect to see further gains in the soon to be released 1.4 release."
msgstr "A pilha do concorrente, no entanto, executa todas as operações de solicitação na thread de IO por padrão. Portanto, o que esse microbenchmark estava realmente comparando é apenas o custo de envio para o pool de threads de trabalho. E, francamente (de acordo com os números do concorrente) e apesar desse trabalho extra de despacho, o Quarkus se saiu muito bem, atingindo ~95% da taxa de transferência do concorrente hoje! Digo hoje porque estamos sempre a melhorar o desempenho e, de facto, esperamos ver mais ganhos na versão 1.4 que será lançada em breve."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:85
#, fuzzy, no-wrap
msgid "*When compared at a disadvantage (dispatching to a worker thread), Quarkus is nevertheless almost as fast in throughput.*\n"
msgstr "*Quando comparado com uma desvantagem (envio para um thread de trabalho), o Quarkus é, no entanto, quase tão rápido em termos de produtividade.*"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:90
#, fuzzy
msgid "… But wait, Quarkus can also avoid the dispatch altogether and run operations on the IO Thread.  This is a more accurate comparison to how the competitor' stack was configured to do as in both case, it is the user's responsibility to ask for a dispatch if and when needed by the application.  To compare apples to apples, let’s use https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] backed by Eclipse Vert.x.  In this model, operations are run on the IO thread by default."
msgstr "... Mas espere, o Quarkus também pode evitar o despacho e executar operações na thread de IO. Esta é uma comparação mais precisa com a forma como a pilha do concorrente foi configurada para fazer, uma vez que em ambos os casos, é da responsabilidade do utilizador pedir um despacho se e quando a aplicação precisar. Para comparar maçãs com maçãs, vamos usar  link:https://quarkus.io/guides/reactive-routes[o Quarkus Reactive Routes] apoiado pelo Eclipse Vert.x. Neste modelo, as operações são executadas na thread IO por padrão."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:95
#, fuzzy
msgid "@ApplicationScoped public class MyDeclarativeRoutes {"
msgstr "@ApplicationScoped public class MyDeclarativeRoutes {"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:98
#, fuzzy, no-wrap
msgid ""
"  @Inject\n"
"  Validator validator;\n"
msgstr ""
"<pre>@Injetar\n"
"Validador validador;</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:111
#, fuzzy, no-wrap
msgid ""
"  @Route(path = \"/hello/:name\", methods = HttpMethod.GET)\n"
"  void greetings(RoutingExchange ex) {\n"
"    RequestWrapper requestWrapper = new RequestWrapper(ex.getParam(\"name\").orElse(\"world\"));\n"
"    Set<ConstraintViolation<RequestWrapper>> violations = validator.validate(requestWrapper));\n"
"    if( violations.size() == 0) {\n"
"      ex.ok(\"hello \" + requestWrapper.name);\n"
"    } else {\n"
"      StringBuilder validationError = new StringBuilder();\n"
"      violations.stream().forEach(violation -> validationError.append(violation.getMessage()));\n"
"      ex.response().setStatusCode(400).end(validationError.toString());\n"
"    }\n"
"  }\n"
msgstr ""
"<pre>@Route(path = \"/hello/:nome\", methods = HttpMethod.GET)\n"
"void greetings(RoutingExchange ex) {\n"
"  RequestWrapper requestWrapper = new RequestWrapper(ex.getParam(\"name\").orElse(\"world\"));\n"
"  Set&lt;ConstraintViolation&lt;RequestWrapper&gt;&gt; violations = validator.validate(requestWrapper));\n"
"  se( violações.tamanho() == 0) {\n"
"    ex.ok(\"hello \" + requestWrapper.name);\n"
"  } else {\n"
"    StringBuilder validationError = new StringBuilder();\n"
"    violations.stream().forEach(violation -&gt; validationError.append(violation.getMessage()));\n"
"    ex.response().setStatusCode(400).end(validationError.toString());\n"
"  }\n"
"}</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:115
#, fuzzy, no-wrap
msgid ""
"  private class RequestWrapper {\n"
"    @NotBlank\n"
"    public String name;\n"
msgstr ""
"<pre>private class RequestWrapper {\n"
"  @NotBlank\n"
"  public String name;</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:120
#, fuzzy, no-wrap
msgid ""
"    public RequestWrapper(String name) {\n"
"      this.name = name;\n"
"    }\n"
"  }\n"
msgstr ""
"<pre>  public RequestWrapper(String name) {\n"
"    this.name = name;\n"
"  }\n"
"}</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:122
#, fuzzy
msgid "}"
msgstr "}"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:125
#, fuzzy
msgid "This is not very different from your JAX-RS equivalent."
msgstr "Isto não é muito diferente do seu equivalente JAX-RS."

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:126
#, fuzzy, no-wrap
msgid "Throughput Numbers"
msgstr "Números de produtividade"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:129
#, fuzzy
msgid "We ran the microbenchmark application in a docker container constrained to reflect a typical resource allocation to a container orchestrated by Kubernetes:"
msgstr "Executámos a aplicação de microbenchmark num contentor docker limitado para refletir uma atribuição típica de recursos a um contentor orquestrado por Kubernetes:"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:131
#, fuzzy
msgid "4 CPU"
msgstr "4 CPU"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:132
#, fuzzy
msgid "256 MB of RAM"
msgstr "256 MB de RAM"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:133
#, fuzzy
msgid "and `-Xmx128m` heap usage for the Java process"
msgstr "e `-Xmx128m` utilização de heap para o processo Java"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:139
#, fuzzy
msgid "We saw that Quarkus using Reactive Routes ran 2.6 times the requests/sec.  2.6 times! It makes sense! Remember the application code virtually does nothing, so the dispatch cost is comparatively high.  If you were to write a more real life workload (maybe even having a blocking operation like a JPA access and therefore forcing a dispatch), then the results would be very different.  Context matters!"
msgstr "Vimos que o Quarkus utilizando rotas reactivas executava 2,6 vezes mais pedidos/seg. 2,6 vezes! Faz sentido! Lembre-se que o código da aplicação praticamente não faz nada, então o custo de despacho é comparativamente alto. Se escrevêssemos uma carga de trabalho mais real (talvez até com uma operação de bloqueio como um acesso JPA e, por conseguinte, forçando um despacho), os resultados seriam muito diferentes. O contexto é importante!"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:141
#, fuzzy
msgid "You can find code and how to reproduce the microbenchmark https://github.com/johnaohara/quarkus-iothread-workerpool/tree/1.3.1.Final[here on GitHub]."
msgstr "Pode encontrar o código e a forma de reproduzir o microbenchmark  link:https://github.com/johnaohara/quarkus-iothread-workerpool/tree/1.3.1.Final[aqui no GitHub]."

#. type: Block title
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:142
#, fuzzy, no-wrap
msgid "Microbenchmark results comparing Quarkus dispatching to a worker thread vs running purely on the IO thread"
msgstr "Resultados de microbenchmark comparando o envio do Quarkus para uma thread de trabalho com a execução puramente na thread de IO"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:146
#, fuzzy, no-wrap
msgid "Quarkus - 1.3.1.Final - 4 CPU's"
msgstr "Quarkus - 1.3.1.Final - 4 CPU's"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:147
#, fuzzy, no-wrap
msgid "Worker thread"
msgstr "Fio de trabalho"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:148
#, fuzzy, no-wrap
msgid "IO thread"
msgstr "Rosca IO"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:150
#, fuzzy, no-wrap
msgid "Ratio"
msgstr "Rácio"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:151
#, fuzzy, no-wrap
msgid "Mean Start Time to First Request (ms) footnote:[‘Mean Start Time to First Request’ was measured using an application built as an UberJar]"
msgstr "Tempo médio de início do primeiro pedido (ms) <sup class=\"footnote\">[ link:#_footnotedef_1[1, id=_footnoteref_1, role=footnote, title=View footnote.]]</sup>"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:152
#, fuzzy, no-wrap
msgid "993.9"
msgstr "993.9"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:153
#, fuzzy, no-wrap
msgid "868.3"
msgstr "868.3"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:155
#, fuzzy, no-wrap
msgid "87.4%"
msgstr "87.4%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:156
#, fuzzy, no-wrap
msgid "Max RSS (MB)"
msgstr "RSS máximo (MB)"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:157
#, fuzzy, no-wrap
msgid "138.8"
msgstr "138.8"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:158
#, fuzzy, no-wrap
msgid "97.9"
msgstr "97.9"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:160
#, fuzzy, no-wrap
msgid "70.5%"
msgstr "70.5%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:161
#, fuzzy, no-wrap
msgid "Max Throughput (req/sec)"
msgstr "Taxa de transferência máxima (req/seg.)"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:162
#, fuzzy, no-wrap
msgid "46,172.2"
msgstr "46,172.2"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:163
#, fuzzy, no-wrap
msgid "123,520.4"
msgstr "123,520.4"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:165
#, fuzzy, no-wrap
msgid "267.5%"
msgstr "267.5%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:166
#, fuzzy, no-wrap
msgid "Max Req/Sec/MB"
msgstr "Necessidade máxima/Segundo/MB"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:167
#, fuzzy, no-wrap
msgid "332.7"
msgstr "332.7"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:168
#, fuzzy, no-wrap
msgid "1,262.1"
msgstr "1,262.1"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:169
#, fuzzy, no-wrap
msgid "379.4%"
msgstr "379.4%"

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:171
#, no-wrap
msgid "throughput-percentile.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:174
#, fuzzy, no-wrap
msgid "*In a fair comparison (purely remaining on the IO thread - no dispatch), Quarkus more than double its throughput.*\n"
msgstr "*Numa comparação justa (permanecendo apenas na thread IO - sem despacho), o Quarkus mais do que duplicou o seu rendimento.*"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:179
#, fuzzy
msgid "As the generated load tends towards the maximum throughput of the system under test, the response time experienced by the client increases exponentially.  So the best system (for the workload) has a vertical line as far to the right as possible.  Equally important is to have as flat a line as possible for the longest time.  You do not want the response time to degrade before the system reaches maximum throughput."
msgstr "À medida que a carga gerada tende para o débito máximo do sistema em teste, o tempo de resposta registado pelo cliente aumenta exponencialmente. Assim, o melhor sistema (para a carga de trabalho) tem uma linha vertical o mais à direita possível. Igualmente importante é ter uma linha tão plana quanto possível durante o maior tempo possível. Não se pretende que o tempo de resposta se degrade antes de o sistema atingir o débito máximo."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:184
#, fuzzy
msgid "By the way, in the competitor microbenchmark Quarkus is shown as consuming more RSS (more RAM).This is also explained by the worker thread pool being operated whereas the competitor did not have a worker thread pool.  The Quarkus Reactive Routes solution (on a pure IO event run) shows a 30% RSS usage reduction."
msgstr "A propósito, no microbenchmark do concorrente, o Quarkus apresenta um maior consumo de RSS (mais RAM), o que também se explica pelo facto de o pool de threads de trabalho ser operado, ao passo que o concorrente não dispunha de um pool de threads de trabalho. A solução Quarkus Reactive Routes (numa execução de evento IO puro) mostra uma redução de 30% na utilização de RSS."

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:185
#, no-wrap
msgid "rss.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:189
#, fuzzy
msgid "In this graph, the lower, the better.  We see that the pure IO thread solution manages to increase throughput with little to no change to the memory usage (RSS), that's very good!"
msgstr "Neste gráfico, quanto mais baixo, melhor. Vemos que a solução de thread IO pura consegue aumentar a taxa de transferência com pouca ou nenhuma alteração no uso de memória (RSS), o que é muito bom!"

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:190
#, fuzzy, no-wrap
msgid "Conclusion"
msgstr "Conclusão"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:196
#, fuzzy
msgid "Quarkus offers you the ability to safely run blocking operations, run non blocking operations on the IO thread or mix both models.  The Quarkus team takes performance very seriously and we see Quarkus as offering great numbers whether you use the imperative or reactive models.  In more realistic workloads, the dispatch cost would be much less significant, you would not see such drastic differences between the two approaches.  As usual, test as close to your real application as possible."
msgstr "O Quarkus oferece-lhe a possibilidade de executar operações de bloqueio em segurança, executar operações não bloqueantes na thread IO ou misturar ambos os modelos. A equipa do Quarkus leva o desempenho muito a sério e consideramos que o Quarkus oferece excelentes números, quer se utilizem os modelos imperativos ou reactivos. Em cargas de trabalho mais realistas, o custo de despacho seria muito menos significativo, não se veriam diferenças tão drásticas entre as duas abordagens. Como de costume, teste o mais próximo possível da sua aplicação real."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:203
#, fuzzy
msgid "Mystery solved.  Benchmarks are hard, challenge them.  But the moral of the story is that in all bad comes some good.  We’ve now learned how to run Quarkus applications entirely on the IO thread.  And how in some situations that can make a big difference.  Remember, don’t block! In fact, Quarkus https://quarkus.io/guides/all-config#quarkus-vertx-core_quarkus.vertx.warning-exception-time[can warn you if you do so].  Oh and we also learned that Quarkus is so fast, it can even beat itself ;p"
msgstr "Mistério resolvido. Os objectivos de referência são difíceis, desafiem-nos. Mas a moral da história é que em tudo o que é mau vem algo de bom. Aprendemos agora como executar aplicações Quarkus inteiramente na thread IO. E como, em algumas situações, isso pode fazer uma grande diferença. Lembre-se, não bloqueie! De facto, o Quarkus  link:https://quarkus.io/guides/all-config#quarkus-vertx-core_quarkus.vertx.warning-exception-time[pode avisar-te se o fizeres]. Ah, e também aprendemos que o Quarkus é tão rápido que pode até vencer a si mesmo ;p"

msgid ""
msgstr ""
"Language: pt_BR\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"X-Generator: jekyll-l10n\n"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Crafting a Local RAG application with Quarkus"
msgstr "Elaboração de um aplicativo RAG local com o Quarkus"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "How to build a RAG chatbot using the Granite LLM."
msgstr "Como criar um chatbot RAG usando o Granite LLM."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"This blog post demonstrate how to build an AI-infused chatbot application using Quarkus, LangChain4j, https://infinispan.org/[Infinispan], and the https://github.com/ibm-granite/granite-code-models[Granite LLM].\n"
"In this post, we will create an **entirely** local solution, eliminating the need for any cloud services, including the LLM."
msgstr "Esta postagem do blog demonstra como criar um aplicativo de chatbot com infusão de IA usando Quarkus, LangChain4j, link:https://infinispan.org/[Infinispan] e o link:https://github.com/ibm-granite/granite-code-models[Granite LLM] . Nesta postagem, criaremos uma solução *totalmente* local, eliminando a necessidade de quaisquer serviços de nuvem, inclusive o LLM."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Our chatbot leverages the Granite LLM, a language model that generates contextually relevant text based on user prompts.\n"
"To run Granite locally, we'll be utilizing https://instructlab.ai/[InstructLab], though https://github.com/containers/podman-desktop-extension-ai-lab[Podman AI Studio] is another viable option."
msgstr "Nosso chatbot utiliza o Granite LLM, um modelo de linguagem que gera texto contextualmente relevante com base nas solicitações do usuário. Para executar o Granite localmente, utilizaremos o link:https://instructlab.ai/[InstructLab] , embora link:https://github.com/containers/podman-desktop-extension-ai-lab[o Podman AI Studio] seja outra opção viável."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"The core of our application is based on the RAG (Retrieval-Augmented Generation) pattern.\n"
"This approach enhances the chatbot's responses by retrieving pertinent information from a vector database — in this case, Infinispan — before generating a response."
msgstr "O núcleo do nosso aplicativo é baseado no padrão RAG (Retrieval-Augmented Generation). Essa abordagem aprimora as respostas do chatbot recuperando informações pertinentes de um banco de dados vetorial - nesse caso, o Infinispan - antes de gerar uma resposta."

#: _posts/2024-06-14-granite-rag.adoc
msgid "Architecture"
msgstr "Arquitetura"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Our chatbot application is composed of four main components:"
msgstr "Nosso aplicativo de chatbot é composto por quatro componentes principais:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"**Web Socket Endpoint**: This component serves as the communication bridge between the chatbot's backend and the frontend interface.\n"
"This component uses the new Quarkus WebSocket-Next extension to handle WebSocket connections efficiently.\n"
"It relies on the AI Service to interact with the LLM."
msgstr "*Ponto de extremidade do Web Socket* : Esse componente serve como ponte de comunicação entre o backend do chatbot e a interface do frontend. Esse componente usa a nova extensão Quarkus WebSocket-Next para lidar com conexões WebSocket de forma eficiente. Ele depende do serviço de IA para interagir com o LLM."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "**Ingestor**: The ingestor is responsible for populating the database with relevant data. It processes a set of local documents, split them into text segments, compute their vector representation and store them into Infinispan."
msgstr "*Ingestor* : O ingestor é responsável por preencher o banco de dados com dados relevantes. Ele processa um conjunto de documentos locais, divide-os em segmentos de texto, calcula sua representação vetorial e os armazena no Infinispan."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "**Retriever**: The retriever allows finding relevant text segments into Infinispan. When a user inputs a query, the retriever searches the vector database to find the most relevant pieces of information."
msgstr "*Retriever* : O recuperador permite encontrar segmentos de texto relevantes no Infinispan. Quando um usuário insere uma consulta, o recuperador pesquisa o banco de dados de vetores para encontrar as informações mais relevantes."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "**AI Service**: This is the core component of the chatbot, combining the capabilities of the retriever and the Granite LLM. The AI service takes the relevant information fetched by the retriever and uses the Granite LLM to generate the appropriate responses."
msgstr "*Serviço de IA* : Esse é o componente central do chatbot, combinando os recursos do retriever e do Granite LLM. O serviço de IA recebe as informações relevantes obtidas pelo retriever e usa o Granite LLM para gerar as respostas apropriadas."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The following picture illustrates the high-level architecture:"
msgstr "A imagem a seguir ilustra a arquitetura de alto nível:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "A simple explanation of the RAG pattern"
msgstr "Uma explicação simples do padrão RAG"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The RAG (Retrieval-Augmented Generation) pattern is one of the most popular AI patterns, combining a retrieval mechanism with a generation mechanism to provide more accurate and relevant responses."
msgstr "O padrão RAG (Retrieval-Augmented Generation) é um dos padrões de IA mais populares, combinando um mecanismo de recuperação com um mecanismo de geração para fornecer respostas mais precisas e relevantes."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The RAG pattern operates in two main steps:"
msgstr "O padrão RAG funciona em duas etapas principais:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "**Ingestion**: The application ingests a set of documents, processes them, and stores them in a vector database."
msgstr "*Ingestão* : O aplicativo ingere um conjunto de documentos, processa-os e os armazena em um banco de dados vetorial."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "**Retrieval**: When a user inputs a query, the application retrieves the most relevant information from the vector database."
msgstr "*Recuperação* : Quando um usuário insere uma consulta, o aplicativo recupera as informações mais relevantes do banco de dados de vetores."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The following image gives a high-level overview of the _traditional_ RAG pattern:"
msgstr "A imagem a seguir apresenta uma visão geral de alto nível do padrão RAG _tradicional_ :"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "There are more advanced version of the RAG pattern, but let's stick to the basics for this application."
msgstr "Há versões mais avançadas do padrão RAG, mas vamos nos ater ao básico para esta aplicação."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Ingestion"
msgstr "Ingestão"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Let's first look at the ingestion step.\n"
"The ingestion process involves reading a set of documents, splitting them into text segments, computing their vector representations, and storing them in Infinispan."
msgstr "Vamos examinar primeiro a etapa de ingestão. O processo de ingestão envolve a leitura de um conjunto de documentos, dividindo-os em segmentos de texto, calculando suas representações vetoriais e armazenando-os no Infinispan."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"The secret of an effective RAG implementation lies in how the text segments are computed.\n"
"In our application, we will follow a straightforward approach, but more advanced techniques are available and often required.\n"
"Depending on the document, you can use a variety of techniques to split the text into segments, such as paragraph splitting, sentence splitting, or more advanced techniques like the `recursive` splitter.\n"
"Also, if the document has a specific structure, you can use this structure to split the text into segments (like sections, chapters, etc.)."
msgstr "O segredo de uma implementação eficaz do RAG está em como os segmentos de texto são computados. Em nosso aplicativo, seguiremos uma abordagem direta, mas há técnicas mais avançadas disponíveis e, muitas vezes, necessárias. Dependendo do documento, o senhor pode usar uma variedade de técnicas para dividir o texto em segmentos, como divisão de parágrafos, divisão de frases ou técnicas mais avançadas, como o divisor `recursive` . Além disso, se o documento tiver uma estrutura específica, é possível usar essa estrutura para dividir o texto em segmentos (como seções, capítulos etc.)."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"The embedding model is responsible for converting text into a vector representation.\n"
"For simplicity, we use an in-process embedding model (`BGE-small`).\n"
"Other options, like the Universal Angle Embedding, are available, but we'll stick with BGE-small for simplicity."
msgstr "O modelo de incorporação é responsável pela conversão do texto em uma representação vetorial. Para simplificar, usamos um modelo de incorporação em processo ( `BGE-small` ). Outras opções, como o Universal Angle Embedding, estão disponíveis, mas, para simplificar, usaremos o BGE-small."

#: _posts/2024-06-14-granite-rag.adoc
msgid "Retrieval"
msgstr "Recuperação"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"The second step is the retrieval process.\n"
"When a user inputs a query, the application searches the vector database to find the most relevant text segments."
msgstr "A segunda etapa é o processo de recuperação. Quando um usuário insere uma consulta, o aplicativo pesquisa o banco de dados de vetores para encontrar os segmentos de texto mais relevantes."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"To achieve this, the application computes the vector representation of the user query using the **same** embedding model and compares it with the vector representations of the stored text segments in Infinispan.\n"
"It selects the most relevant text segments based on the similarity between the query vector and the text segment vectors."
msgstr "Para isso, o aplicativo calcula a representação vetorial da consulta do usuário usando o *mesmo* modelo de incorporação e a compara com as representações vetoriais dos segmentos de texto armazenados no Infinispan. Ele seleciona os segmentos de texto mais relevantes com base na similaridade entre o vetor de consulta e os vetores de segmentos de texto."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Then, it augments the user query with the retrieved text segments and sends it to the LLM.\n"
"Note that until this step, the LLM is not used."
msgstr "Em seguida, ele aumenta a consulta do usuário com os segmentos de texto recuperados e a envia para o LLM. Observe que, até essa etapa, o LLM não é usado."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Implementing the chatbot"
msgstr "Implementação do chatbot"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Enough theory—let's dive into the implementation.\n"
"You can find the final version on https://github.com/cescoffier/quarkus-granite-rag-demo[GitHub]."
msgstr "Chega de teoria, vamos nos aprofundar na implementação. O senhor pode encontrar a versão final no link:https://github.com/cescoffier/quarkus-granite-rag-demo[GitHub] ."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Used extensions and dependencies"
msgstr "Extensões e dependências usadas"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "To implement our chatbot, we rely on the following Quarkus extensions:"
msgstr "Para implementar nosso chatbot, contamos com as seguintes extensões do Quarkus:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "`quarkus-langchain4j-openai`: Integrates LLM providers using the OpenAI API, suitable for both InstructLab and Podman AI Studio."
msgstr "`quarkus-langchain4j-openai` : Integra provedores de LLM usando a API OpenAI, adequada tanto para o InstructLab quanto para o Podman AI Studio."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "`quarkus-websockets-next`: Provides support for WebSocket communication."
msgstr "`quarkus-websockets-next` : Oferece suporte à comunicação WebSocket."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "`quarkus-langchain4j-infinispan`: Integrates Infinispan with LangChain4j, allowing us to store and retrieve vector representations of text segments."
msgstr "`quarkus-langchain4j-infinispan` : Integra o Infinispan com o LangChain4j, o que nos permite armazenar e recuperar representações vetoriais de segmentos de texto."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "`quarkus-web-bundler`: Bundles frontend resources with the Quarkus application."
msgstr "`quarkus-web-bundler` : Agrupa recursos de front-end com o aplicativo Quarkus."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "We also need a specific dependency to use the BGE-small embedding model:"
msgstr "Também precisamos de uma dependência específica para usar o modelo de incorporação BGE-small:"

#: _posts/2024-06-14-granite-rag.adoc
msgid "Configuration"
msgstr "Configuração"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "We need a bit of configuration to ensure our application uses Granite and sets up the Infinispan database correctly:"
msgstr "Precisamos de um pouco de configuração para garantir que nosso aplicativo use o Granite e configure o banco de dados Infinispan corretamente:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Configure the dimension of the vectors stored in Infinispan, which depends on the embedding model (BGE-small in our case)."
msgstr "Configure a dimensão dos vetores armazenados no Infinispan, que depende do modelo de incorporação (BGE-small em nosso caso)."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Configure the OpenAI service to use InstructLab.\n"
"You can replace the base URL with the one for Podman AI Studio if you prefer.\n"
"Indeed, InstructLab and Podman AI Studio expose an OpenAI-compatible API."
msgstr "Configure o serviço OpenAI para usar o InstructLab. O senhor pode substituir o URL de base pelo URL do Podman AI Studio, se preferir. De fato, o InstructLab e o Podman AI Studio expõem uma API compatível com o OpenAI."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Set the default embedding model to BGE-small."
msgstr "Defina o modelo de incorporação padrão como BGE-small."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The Ingestor"
msgstr "O Ingeridor"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"With the configuration in place, let's implement the https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/Ingestion.java[ingestion part (Ingestion.java)].\n"
"The ingestor reads documents from the `documents` directory, splits them into text segments, computes their vector representations, and stores them in Infinispan:"
msgstr "Com a configuração pronta, vamos implementar a link:https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/Ingestion.java[parte de ingestão (Ingestion.java)] . O ingestor lê documentos do diretório `documents` , divide-os em segmentos de texto, calcula suas representações vetoriais e os armazena no Infinispan:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `@Startup` annotation ensures that the ingestion process starts when the application launches."
msgstr "A anotação `@Startup` garante que o processo de ingestão comece quando o aplicativo for iniciado."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `Ingestion` class uses an (automatically injected) `EmbeddingStore<TextSegment>` (Infinispan) and an `EmbeddingModel` (BGE-small)."
msgstr "A classe `Ingestion` usa um `EmbeddingStore<TextSegment>` (Infinispan) (injetado automaticamente) e um `EmbeddingModel` (BGE-small)."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"We use a simple document splitter (`recursive(1024, 0)`) to split the documents into text segments.\n"
"More advanced techniques may be used to improve the accuracy of the RAG model."
msgstr "Usamos um divisor de documentos simples ( `recursive(1024, 0)` ) para dividir os documentos em segmentos de texto. Técnicas mais avançadas podem ser usadas para melhorar a precisão do modelo RAG."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The retriever"
msgstr "O retriever"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Next, let's implement the https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/Retriever.java[retriever (Retriever.java)].\n"
"The retriever finds the most relevant text segments in Infinispan based on the user query:"
msgstr "Em seguida, vamos implementar o link:https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/Retriever.java[recuperador (Retriever.java)] . O recuperador encontra os segmentos de texto mais relevantes no Infinispan com base na consulta do usuário:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"To implement a retriever, expose a bean that implements the `Supplier<RetrievalAugmentor>` interface.\n"
"The `Retriever` class uses `EmbeddingStore<TextSegment>` (Infinispan) and `EmbeddingModel` (BGE-small) to build the retriever."
msgstr "Para implementar um recuperador, exponha um bean que implemente a interface `Supplier<RetrievalAugmentor>` . A classe `Retriever` usa `EmbeddingStore<TextSegment>` (Infinispan) e `EmbeddingModel` (BGE-small) para criar o recuperador."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"The `maxResults` method in the EmbeddingStoreContentRetriever builder specifies the number of text segments to retrieve.\n"
"Since our segments are large, we retrieve only two segments."
msgstr "O método `maxResults` no construtor EmbeddingStoreContentRetriever especifica o número de segmentos de texto a serem recuperados. Como nossos segmentos são grandes, recuperamos apenas dois segmentos."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The AI Service"
msgstr "O serviço de IA"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/ChatBot.java[AI Service (ChatBot.java)] is the core component of our chatbot, combining the capabilities of the retriever and the Granite LLM to generate appropriate responses."
msgstr "O link:https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/ChatBot.java[AI Service (ChatBot.java)] é o componente central do nosso chatbot, combinando os recursos do retriever e do Granite LLM para gerar respostas adequadas."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "With Quarkus, implementing an AI service is straightforward:"
msgstr "Com o Quarkus, a implementação de um serviço de IA é simples:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `@RegisterAiService` annotation specifies the retrieval augmentor to use, which in our case is the `Retriever` bean defined earlier."
msgstr "A anotação `@RegisterAiService` especifica o aumentador de recuperação a ser usado, que, no nosso caso, é o bean `Retriever` definido anteriormente."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `@SystemMessage` annotation provides the main instructions for the AI model."
msgstr "A anotação `@SystemMessage` fornece as principais instruções para o modelo de IA."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `@SessionScoped` annotation ensures that the AI service is stateful, maintaining context between user interactions for more engaging conversations."
msgstr "A anotação `@SessionScoped` garante que o serviço de IA tenha estado, mantendo o contexto entre as interações do usuário para conversas mais envolventes."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `ChatBot` interface defines a single method, `chat`, which takes a user question as input and returns the chatbot's response."
msgstr "A interface `ChatBot` define um único método, `chat` , que recebe uma pergunta do usuário como entrada e retorna a resposta do chatbot."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The WebSocket endpoint"
msgstr "O ponto de extremidade do WebSocket"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The final piece is the https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/ChatWebSocket.java[WebSocket endpoint (ChatWebSocket.java)], which serves as the communication bridge between the chatbot's backend and the frontend interface:"
msgstr "A parte final é o link:https://github.com/cescoffier/quarkus-granite-rag-demo/blob/main/src/main/java/me/escoffier/granite/rag/ChatWebSocket.java[endpoint WebSocket (ChatWebSocket.java)] , que serve como ponte de comunicação entre o backend do chatbot e a interface do frontend:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `@WebSocket` annotation specifies the WebSocket path."
msgstr "A anotação `@WebSocket` especifica o caminho do WebSocket."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `@OnOpen` method sends a welcome message when a user connects to the _WebSocket_."
msgstr "O método `@OnOpen` envia uma mensagem de boas-vindas quando um usuário se conecta ao _WebSocket_ ."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "The `@OnTextMessage` method processes the user's messages and returns the chatbot's responses, using the injected AI service."
msgstr "O método `@OnTextMessage` processa as mensagens do usuário e retorna as respostas do chatbot, usando o serviço de IA injetado."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "That's it! Our chatbot is now ready to chat with users, providing contextually relevant responses based on the RAG pattern."
msgstr "É isso aí! Nosso chatbot agora está pronto para conversar com os usuários, fornecendo respostas contextualmente relevantes com base no padrão RAG."

#: _posts/2024-06-14-granite-rag.adoc
msgid "Running the application"
msgstr "Executando a aplicação"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Let's run the application and see our chatbot in action.\n"
"First, clone the https://github.com/cescoffier/quarkus-granite-rag-demo/tree/main[repository] and run the following command:"
msgstr "Vamos executar o aplicativo e ver nosso chatbot em ação. Primeiro, clone o link:https://github.com/cescoffier/quarkus-granite-rag-demo/tree/main[repositório] e execute o seguinte comando:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"This command starts the Quarkus application in development mode.\n"
"Ensure you have InstructLab or Podman AI Studio running to use the Granite LLM.\n"
"You will also need Docker or Podman to automatically start Infinispan."
msgstr "Esse comando inicia o aplicativo Quarkus no modo de desenvolvimento. Certifique-se de que o InstructLab ou o Podman AI Studio esteja em execução para usar o Granite LLM. O senhor também precisará do Docker ou do Podman para iniciar automaticamente o Infinispan."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Podman AI Studio or InstructLab?"
msgstr "Podman AI Studio ou InstructLab?"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"You can use either Podman AI Studio or InstructLab to run the Granite LLM locally.\n"
"Depending on the OS, Podman may not have GPU support. Thus, response time can be high.\n"
"In this case, InstructLab is the preferred option for better response times.\n"
"Typically, on a Mac, you would use InstructLab, while on Linux, Podman AI Studio shows great performances."
msgstr "O senhor pode usar o Podman AI Studio ou o InstructLab para executar o Granite LLM localmente. Dependendo do sistema operacional, o Podman pode não ter suporte para GPU. Portanto, o tempo de resposta pode ser alto. Nesse caso, o InstructLab é a opção preferida para obter melhores tempos de resposta. Normalmente, em um Mac, o senhor usaria o InstructLab, enquanto no Linux, o Podman AI Studio apresenta ótimo desempenho."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"Once the application is up and running, open your browser and navigate to http://localhost:8080.\n"
"You should see the chatbot interface, where you can start chatting with Mona:"
msgstr "Quando o aplicativo estiver em funcionamento, abra o navegador e navegue até link:http://localhost:8080[http://localhost:8080.] O senhor verá a interface do chatbot, onde poderá começar a conversar com a Mona:"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid "Summary"
msgstr "Resumo"

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"That's it!\n"
"With just a few lines of code, we have implemented a chatbot using the RAG pattern, combining the capabilities of the Granite LLM, Infinispan, and Quarkus.\n"
"This application runs entirely locally, eliminating the need for any cloud services and addressing privacy concerns."
msgstr "É isso aí! Com apenas algumas linhas de código, implementamos um chatbot usando o padrão RAG, combinando os recursos do Granite LLM, Infinispan e Quarkus. Esse aplicativo é executado totalmente localmente, eliminando a necessidade de quaisquer serviços em nuvem e atendendo às preocupações com a privacidade."

#: _posts/2024-06-14-granite-rag.adoc
#, fuzzy
msgid ""
"This is just an example of what you can achieve with the Quarkus LangChain4j extension.\n"
"You can easily extend this application by adding more advanced features, such as sophisticated document splitters, embedding models, or retrieval mechanisms.\n"
"Quarkus LangChain4J also provides support for https://docs.langchain4j.dev/tutorials/rag/#advanced-rag[_advanced_ RAG], many other LLM and embedding models and vector stores.\n"
"Find out more on https://docs.quarkiverse.io/quarkus-langchain4j/dev/index.html[Quarkus LangChain4J]."
msgstr "Este é apenas um exemplo do que o senhor pode conseguir com a extensão Quarkus LangChain4j. O senhor pode ampliar facilmente esse aplicativo adicionando recursos mais avançados, como divisores de documentos sofisticados, modelos de incorporação ou mecanismos de recuperação. O Quarkus LangChain4J também oferece suporte para link:https://docs.langchain4j.dev/tutorials/rag/#advanced-rag[RAGavançado] , muitos outros modelos LLM e de incorporação e armazenamentos vetoriais. Saiba mais sobre o link:https://docs.quarkiverse.io/quarkus-langchain4j/dev/index.html[Quarkus LangChain4J] ."

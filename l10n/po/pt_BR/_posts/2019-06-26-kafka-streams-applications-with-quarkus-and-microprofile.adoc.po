# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2023-09-21 08:08+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "gmorling"
msgstr "gmorling"

#. type: YAML Front Matter: date
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "2019-06-26"
msgstr "2019-06-26"

#. type: YAML Front Matter: layout
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "post"
msgstr "posto"

#. type: YAML Front Matter: tags
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "kafka microprofile"
msgstr "microperfil do kafka"

#. type: YAML Front Matter: title
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "Building Kafka Streams applications with Quarkus and Eclipse MicroProfile"
msgstr "Criar aplicações Kafka Streams com o Quarkus e o Eclipse MicroProfile"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:12
#, fuzzy
msgid "https://kafka.apache.org/documentation/streams/[Kafka Streams] is a very popular solution for implementing stream processing applications based on Apache Kafka.  It lets you do typical data streaming tasks like filtering and transforming messages, joining multiple Kafka topics, performing (stateful) calculations, grouping and aggregating values in time windows and much more."
msgstr "link:https://kafka.apache.org/documentation/streams/[O Kafka Streams] é uma solução muito popular para implementar aplicações de processamento de fluxo baseadas no Apache Kafka. Permite-lhe realizar tarefas típicas de fluxo de dados, como filtrar e transformar mensagens, juntar vários tópicos Kafka, efetuar cálculos (com estado), agrupar e agregar valores em janelas de tempo e muito mais."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:17
#, fuzzy
msgid "Unlike other streaming query engines that run on specific processing clusters, Kafka Streams is a client library.  This means a (Java) application is needed which starts and runs the streaming pipeline, reading from and writing to the Apache Kafka cluster."
msgstr "Ao contrário de outros mecanismos de consulta de fluxo contínuo que são executados em clusters de processamento específicos, o Kafka Streams é uma biblioteca cliente. Isso significa que é necessário um aplicativo (Java) que inicia e executa o pipeline de streaming, lendo e escrevendo no cluster do Apache Kafka."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:20
#, fuzzy
msgid "In this blog post we'll discuss how the combination of Quarkus and https://microprofile.io/[Eclipse MicroProfile] is a great foundation for implementing Kafka Streams applications, running on the JVM and as native code compiled ahead of time via https://www.graalvm.org/[GraalVM]."
msgstr "Nesta postagem do blog, discutiremos como a combinação do Quarkus e do  link:https://microprofile.io/[Eclipse MicroProfile] é uma ótima base para a implementação de aplicativos Kafka Streams, executados na JVM e como código nativo compilado antecipadamente via  link:https://www.graalvm.org/[GraalVM]."

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:21
#, fuzzy, no-wrap
msgid "The Quarkus extension for Kafka Streams"
msgstr "A extensão Quarkus para o Kafka Streams"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:25
#, fuzzy
msgid "As of version 0.17.0, Quarkus comes with link:/guides/kafka-streams[an extension] for building Kafka Streams applications.  To create a new Quarkus project with this extension, run the following:"
msgstr "A partir da versão 0.17.0, o Quarkus vem com  link:/guides/kafka-streams[uma extensão] para criar aplicações Kafka Streams. Para criar um novo projeto Quarkus com esta extensão, execute o seguinte:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:32
#, no-wrap
msgid ""
"mvn io.quarkus:quarkus-maven-plugin:0.17.0:create \\\n"
"   -DprojectGroupId=org.acme \\\n"
"   -DprojectArtifactId=kafka-streams-quickstart-example \\\n"
"   -Dextensions=\"kafka-streams\"\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:36
#, fuzzy
msgid "This will set up a new project, adding the dependency to the Quarkus Kafka Streams extension, which in turn will pull in Kafka Streams and all its dependencies."
msgstr "Isto irá criar um novo projeto, adicionando a dependência à extensão Quarkus Kafka Streams, que por sua vez irá puxar o Kafka Streams e todas as suas dependências."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:40
#, fuzzy
msgid "If you've worked with Kafka Streams before, the implementation of a data streaming pipeline will look very familiar to you.  You first build up a `Topology` and then create a `KafkaStreams` instance.  For starting and stopping the latter, Quarkus' `StartupEvent` and `ShutdownEvent` classes come in handy."
msgstr "Se já trabalhou com o Kafka Streams antes, a implementação de um pipeline de fluxo de dados parecerá muito familiar para si. Primeiro constrói-se um `Topology` e depois cria-se uma instância `KafkaStreams`. Para iniciar e parar esta última, as classes `StartupEvent` e `ShutdownEvent` do Quarkus são úteis."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:42
#, fuzzy
msgid "Overall, the structure of a Kafka Streams pipeline running on Quarkus will look like so:"
msgstr "Em termos gerais, a estrutura de um pipeline do Kafka Streams em execução no Quarkus terá o seguinte aspeto:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:47
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:240
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class MyStreamingPipeline {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:49
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:182
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:245
#, no-wrap
msgid "    private KafkaStreams streams;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:54
#, no-wrap
msgid ""
"    void onStart(@Observes StartupEvent event) {\n"
"        // set up Kafka Streams config, e.g. sourced from application.properties\n"
"        Properties props = new Properties();\n"
"        // props.put(..., ...);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:58
#, no-wrap
msgid ""
"        // set up the stream topology\n"
"        StreamsBuilder builder = new StreamsBuilder();\n"
"        // builder.stream(...)\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:62
#, no-wrap
msgid ""
"        streams = new KafkaStreams(builder.build(), props);\n"
"        streams.start();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:67
#, no-wrap
msgid ""
"    void onStop(@Observes ShutdownEvent event) {\n"
"        streams.close();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:73
#, fuzzy
msgid "For the very common requirement that you'd like to serialize and deserialize Java types used in the streaming pipeline into/from JSON (e.g. when materializing them in a state store), the Quarkus Kafka Streams extension provides the class `io.quarkus.kafka.client.serialization.JsonbSerde`.  It's a `Serde` implementation based on JSON-B:"
msgstr "Para o requisito muito comum de querer serializar e deserializar tipos Java utilizados no pipeline de streaming de/para JSON (por exemplo, ao materializá-los num armazenamento de estado), a extensão Quarkus Kafka Streams fornece a classe `io.quarkus.kafka.client.serialization.JsonbSerde`. Trata-se de uma implementação `Serde` baseada em JSON-B:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:78
#, no-wrap
msgid ""
"...\n"
"JsonbSerde<WeatherStation> weatherStationSerde = new JsonbSerde<>(WeatherStation.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:84
#, no-wrap
msgid ""
"GlobalKTable<Integer, WeatherStation> stations = builder.globalTable(\n"
"    \"weather-stations\",\n"
"    Consumed.with(Serdes.Integer(), weatherStationSerde)\n"
");\n"
"...\n"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:86
#, fuzzy, no-wrap
msgid "Running Native"
msgstr "Nativo em funcionamento"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:91
#, fuzzy
msgid "Based on Kafka's notion of topic partitioning, Kafka Streams applications can easily be scaled out: the load will be shared amongst multiple instances of the application, each processing just a subset of the partitions of the input topic(s)."
msgstr "Com base na noção de particionamento de tópicos do Kafka, as aplicações Kafka Streams podem ser facilmente escaladas: a carga será partilhada entre várias instâncias da aplicação, cada uma processando apenas um subconjunto das partições do(s) tópico(s) de entrada."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:96
#, fuzzy
msgid "Running Quarkus applications in native code via GraalVM comes in very handy for that: besides the very fast start-up time, the applications will use significantly less memory when compiled to native code.  This lets you spin up many instances of a Quarkus-based Kafka Streams pipeline in parallel, in a very memory-efficient way."
msgstr "Executar aplicativos Quarkus em código nativo via GraalVM é muito útil para isso: além do tempo de inicialização muito rápido, os aplicativos usarão significativamente menos memória quando compilados em código nativo. Isto permite-lhe rodar muitas instâncias de um pipeline Kafka Streams baseado no Quarkus em paralelo, de uma forma muito eficiente em termos de memória."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:101
#, fuzzy
msgid "The extension takes care of everything needed for building native Kafka Streams applications, for instance it makes sure that the right RocksDB native libraries are added to the application image.  All you need to do is to specify the `enableJni` option for the Quarkus Maven plug-in, allowing those native libraries to be invoked via JNI:"
msgstr "A extensão trata de tudo o que é necessário para criar aplicações Kafka Streams nativas, por exemplo, certifica-se de que as bibliotecas nativas RocksDB correctas são adicionadas à imagem da aplicação. Tudo o que precisa de fazer é especificar a opção `enableJni` para o plug-in Quarkus Maven, permitindo que essas bibliotecas nativas sejam invocadas via JNI:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:118
#, no-wrap
msgid ""
"<plugin>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-maven-plugin</artifactId>\n"
"    <executions>\n"
"        <execution>\n"
"            <goals>\n"
"                <goal>native-image</goal>\n"
"            </goals>\n"
"            <configuration>\n"
"                <enableJni>true</enableJni>\n"
"            </configuration>\n"
"        </execution>\n"
"    </executions>\n"
"</plugin>\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:123
#, fuzzy
msgid "When using the `JsonbSerde` for unmarshalling JSON into corresponding Java objects, those types must be marked with the `@RegisterForReflection` annotation, so that they can to be instantiated reflectively by JSON-B in native mode:"
msgstr "Quando se utiliza o `JsonbSerde` para desmarcar JSON em objectos Java correspondentes, esses tipos devem ser marcados com a anotação `@RegisterForReflection`, para que possam ser instanciados refletidamente pelo JSON-B em modo nativo:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:128
#, no-wrap
msgid ""
"@RegisterForReflection\n"
"public class WeatherStation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:132
#, no-wrap
msgid ""
"    public int id;\n"
"    public String name;\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:136
#, fuzzy
msgid "Then build the application using the `native` profile (note this requires GraalVM to be installed on your system; refer to the Quarkus link:/guides/building-native-image[native image] guide to learn more):"
msgstr "Em seguida, construa a aplicação utilizando o perfil `native` (note que isto requer que o GraalVM esteja instalado no seu sistema; consulte o guia de  link:/guides/building-native-image[imagem nativa] Quarkus para saber mais):"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:140
#, no-wrap
msgid "mvn clean package -f aggregator/pom.xml -Pnative\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:147
#, fuzzy
msgid "Finding the right amount of memory needed for running the application can require some testing.  E.g. observe CPU load and run the native binary with the `-XX:+PrintGC -XX:+PrintGCTimeStamps -XX:+VerboseGC` options in order to gain insight into how often garbage collection kicks in.  If you started the application with not enough heap space, you'll typically observe that GC is happening very frequently, causing increased CPU load."
msgstr "Encontrar a quantidade certa de memória necessária para executar a aplicação pode exigir alguns testes. Por exemplo, observe a carga da CPU e execute o binário nativo com as opções `-XX:+PrintGC -XX:+PrintGCTimeStamps -XX:+VerboseGC` para obter informações sobre a frequência com que a coleta de lixo entra em ação. Se você iniciou o aplicativo com espaço heap insuficiente, você normalmente observará que o GC está acontecendo com muita frequência, causando aumento da carga da CPU."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:154
#, fuzzy
msgid "To give an example, for the https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-streams-quickstart[streaming pipeline] discussed in the Kafka Streams extension guide, a heap size of 32 MB (`-Xmx32m`) works very well, resulting in less than 50 MB memory needed by the process in total (RSS, resident set size).  Note that this number also contains the memory needed for the HTTP endpoint defined in that example, which is used for answering interactive queries via REST."
msgstr "Para dar um exemplo, para o  link:https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-streams-quickstart[pipeline de streaming] discutido no guia de extensão Kafka Streams, um tamanho de heap de 32 MB ( `-Xmx32m`) funciona muito bem, resultando em menos de 50 MB de memória necessária para o processo no total (RSS, tamanho do conjunto residente). Observe que esse número também contém a memória necessária para o ponto de extremidade HTTP definido nesse exemplo, que é usado para responder a consultas interativas via REST."

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:155
#, fuzzy, no-wrap
msgid "Gaining Operational Insight"
msgstr "Obtenção de informações operacionais"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:161
#, fuzzy
msgid "One of the nice things about Quarkus is that it comes with support for all the Eclipse MicroProfile APIs.  They help to address common requirements when building microservices, such as https://microprofile.io/project/eclipse/microprofile-health[health checks] (\"Is my application running and ready to handle requests?\")  and https://microprofile.io/project/eclipse/microprofile-metrics[metrics] (\"What's the throughput of my application?\", \"How many requests has it processed?\" etc.)."
msgstr "Uma das coisas boas do Quarkus é que ele vem com suporte para todas as APIs do Eclipse MicroProfile. Estas ajudam a responder a requisitos comuns quando se constroem microsserviços, tais como  link:https://microprofile.io/project/eclipse/microprofile-health[verificações de saúde] (\"A minha aplicação está a funcionar e pronta para processar pedidos?\") e  link:https://microprofile.io/project/eclipse/microprofile-metrics[métricas] (\"Qual é o débito da minha aplicação?\", \"Quantos pedidos processou?\", etc.)."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:165
#, fuzzy
msgid "Based on those APIs, it just requires a little bit of coding to implement health checks and metrics for a Kafka Streams application.  You can add the right dependencies by running:"
msgstr "Com base nessas APIs, é necessário apenas um pouco de codificação para implementar verificações de integridade e métricas para um aplicativo Kafka Streams. Você pode adicionar as dependências corretas executando:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:169
#, no-wrap
msgid "./mvnw quarkus:add-extension -Dextensions=\"health,metrics\"\n"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:171
#, fuzzy, no-wrap
msgid "Healthchecks"
msgstr "Controlos de saúde"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:174
#, fuzzy
msgid "Then creating the health check is as simple as adding the following to the pipeline implementation:"
msgstr "Em seguida, criar o controlo de saúde é tão simples como adicionar o seguinte à implementação do pipeline:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:180
#, no-wrap
msgid ""
"@Liveness\n"
"@ApplicationScoped\n"
"public class MyStreamingPipeline implements HealthCheck {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:184
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:254
#, no-wrap
msgid "    // ...\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:192
#, no-wrap
msgid ""
"    @Override\n"
"    public HealthCheckResponse call() {\n"
"        return HealthCheckResponse.named(\"My Pipeline\")\n"
"                .state(streams.state().isRunning())\n"
"                .build();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:196
#, fuzzy
msgid "This will expose a health check via HTTP under `/health/live`, which when queried will yield a response like this:"
msgstr "Isto irá expor um controlo de saúde através de HTTP em `/health/live`, que quando consultado irá produzir uma resposta como esta:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:204
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 144\n"
"Content-Type: application/json;charset=UTF-8\n"
"Date: Wed, 26 Jun 2019 10:08:36 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:214
#, no-wrap
msgid ""
"{\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"My Pipeline\",\n"
"            \"status\": \"UP\"\n"
"        }\n"
"    ],\n"
"    \"status\": \"UP\"\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:221
#, fuzzy
msgid "When using a container orchestrator such as Kubernetes, you could then set up a https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[liveness probe] for this endpoint.  If the health check fails (i.e. the streaming pipeline is not in the running state), it will return an HTTP 503 response.  This would be the indicator to the orchestrator to restart the pod of this application."
msgstr "Ao usar um orquestrador de contêineres, como o Kubernetes, você pode configurar uma  link:https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[sonda de vivacidade] para esse ponto de extremidade. Se a verificação de integridade falhar (ou seja, o pipeline de streaming não está no estado de execução), ele retornará uma resposta HTTP 503. Este seria o indicador para o orquestrador reiniciar o pod desta aplicação."

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:222
#, fuzzy, no-wrap
msgid "Metrics"
msgstr "Métricas"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:228
#, fuzzy
msgid "While a health check provides simple means of finding out whether the application is in a state where it can handle requests/messages or not, it is desirable to have more insight into the behaviour of the service.  E.g. it might be of interest to see how many messages have been processed by the streaming pipeline, what's the arrival rate of messages, what's the average processing time and much more."
msgstr "Embora uma verificação de saúde forneça meios simples de descobrir se a aplicação está num estado em que pode tratar pedidos/mensagens ou não, é desejável ter mais informações sobre o comportamento do serviço. Por exemplo, pode ser interessante ver quantas mensagens foram processadas pelo pipeline de fluxo contínuo, qual é a taxa de chegada das mensagens, qual é o tempo médio de processamento e muito mais."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:233
#, fuzzy
msgid "Kafka Streams comes with https://kafka.apache.org/22/javadoc/org/apache/kafka/streams/KafkaStreams.html#metrics--[rich metrics] capabilities which can help to answer these questions.  Using the MicroProfile Metrics API, these metrics can be exposed via HTTP.  From there they can be scraped by tools such as https://prometheus.io/[Prometheus] and eventually be fed to dashboard solutions such as https://grafana.com/[Grafana].  Note that exposing metrics via HTTP instead of JMX has the advantage that this also works when running the application in native mode via GraalVM."
msgstr "O Kafka Streams vem com recursos  link:https://kafka.apache.org/22/javadoc/org/apache/kafka/streams/KafkaStreams.html#metrics--[avançados de métricas] que podem ajudar a responder a essas perguntas. Usando a API de métricas do MicroProfile, essas métricas podem ser expostas via HTTP. A partir daí, elas podem ser extraídas por ferramentas como o  link:https://prometheus.io/[Prometheus] e, eventualmente, alimentadas por soluções de painel, como o  link:https://grafana.com/[Grafana]. Observe que a exposição de métricas via HTTP em vez de JMX tem a vantagem de que isso também funciona ao executar o aplicativo no modo nativo via GraalVM."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:235
#, fuzzy
msgid "Similar to the health check case, just a bit of glue code is needed for exposing the metrics:"
msgstr "À semelhança do caso do controlo de saúde, é necessário apenas um pouco de código cola para expor as métricas:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:243
#, no-wrap
msgid ""
"    @Inject\n"
"    MetricRegistry metricRegistry;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:248
#, no-wrap
msgid ""
"    void onStart(@Observes StartupEvent event) {\n"
"        // ...\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:252
#, no-wrap
msgid ""
"        streams.start();\n"
"        exportMetrics();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:257
#, no-wrap
msgid ""
"    private void exportMetrics() {\n"
"        Set<String> processed = new HashSet<>();\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:261
#, no-wrap
msgid ""
"        for (Metric metric : streams.metrics().values()) {                // <1>\n"
"            String name = metric.metricName().group() +\n"
"                    \":\" + metric.metricName().name();\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:265
#, no-wrap
msgid ""
"            if (processed.contains(name)) {\n"
"                continue;\n"
"            }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:277
#, no-wrap
msgid ""
"            // string-typed metric not supported\n"
"            if (name.contentEquals(\"app-info:commit-id\") ||               // <2>\n"
"                    name.contentEquals(\"app-info:version\")) {\n"
"                continue;\n"
"            }\n"
"            else if (name.endsWith(\"count\") || name.endsWith(\"total\")) {  // <3>\n"
"                registerCounter(metric, name);\n"
"            }\n"
"            else {\n"
"                registerGauge(metric, name);                              // <4>\n"
"            }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:281
#, no-wrap
msgid ""
"            processed.add(name);\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:285
#, no-wrap
msgid ""
"    private void registerGauge(Metric metric, String name) {\n"
"        Metadata metadata = new Metadata(name, MetricType.GAUGE);\n"
"        metadata.setDescription(metric.metricName().description());\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:287
#, no-wrap
msgid "        metricRegistry.register(metadata, new Gauge<Double>() {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:294
#, no-wrap
msgid ""
"            @Override\n"
"            public Double getValue() {\n"
"                return (Double) metric.metricValue();\n"
"            }\n"
"        } );\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:299
#, no-wrap
msgid ""
"    private void registerCounter(Metric metric, String name) {\n"
"        // ...\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:301
#, fuzzy
msgid "Process all Kafka Streams metrics, using a unique name to register them"
msgstr "Processar todas as métricas de Kafka Streams, utilizando um nome único para as registar"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:302
#, fuzzy
msgid "Some string-typed \"metrics\" must be excluded"
msgstr "Algumas \"métricas\" do tipo string devem ser excluídas"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:303
#, fuzzy
msgid "All metrics whose name ends with \"total\" or \"counter\" will be exposed as counter-typed metrics"
msgstr "Todas as métricas cujo nome termina com \"total\" ou \"contador\" serão expostas como métricas de tipo contador"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:304
#, fuzzy
msgid "All other metrics will be exposed as gauge-typed metrics, i.e. plain numeric values"
msgstr "Todas as outras métricas serão expostas como métricas do tipo gauge, ou seja, valores numéricos simples"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:307
#, fuzzy
msgid "Once the application is started, the metrics will be exposed under `/metrics`, returning the data in the OpenMetrics format by default:"
msgstr "Assim que a aplicação for iniciada, as métricas serão expostas em `/metrics`, devolvendo os dados no formato OpenMetrics por defeito:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:317
#, no-wrap
msgid ""
"# HELP application:stream_metrics_process_total The total number of occurrence of process operations.\n"
"# TYPE application:stream_metrics_process_total counter\n"
"application:stream_metrics_process_total 2866.0\n"
"# HELP application:stream_metrics_poll_latency_avg The average latency of poll operation.\n"
"# TYPE application:stream_metrics_poll_latency_avg gauge\n"
"application:stream_metrics_poll_latency_avg 83.3135593220339\n"
"# ...\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:323
#, fuzzy
msgid "From here it's a matter of minutes to set up Prometheus to scrape this target, configure a Prometheus data source in Grafana and configure a dashboard for visualizing the metrics of interest to you.  E.g. the following shows a simple dashboard displaying the poll/process/commit rates and latencies as well as the total number of processed events in the quickstart example:"
msgstr "A partir daqui, é uma questão de minutos para configurar o Prometheus para raspar esse destino, configurar uma fonte de dados do Prometheus no Grafana e configurar um painel para visualizar as métricas de seu interesse. Por exemplo, o seguinte mostra um painel simples que exibe as taxas e latências de sondagem/processamento/compromisso, bem como o número total de eventos processados no exemplo de início rápido:"

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:324
#, fuzzy, no-wrap
msgid "Kafka Streams metrics in Grafana"
msgstr "Métricas de fluxos do Kafka no Grafana"

#. type: Target for macro image
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:324
#, no-wrap
msgid "/assets/images/kafka-streams-metrics.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:326
#, fuzzy, no-wrap
msgid "Summary and Outlook"
msgstr "Resumo e perspectivas"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:332
#, fuzzy
msgid "Quarkus and Eclipse MicroProfile are a great basis for building Kafka Streams applications.  The Quarkus extension for Kafka Streams comes with everything needed to run stream processing pipelines on the JVM as well as in native mode via GraalVM.  The MicroProfile APIs for health checks and metrics can be used to expose the right information for gaining insight into running stream processing applications."
msgstr "O Quarkus e o Eclipse MicroProfile são uma óptima base para a criação de aplicações Kafka Streams. A extensão Quarkus para Kafka Streams vem com tudo o que é necessário para executar pipelines de processamento de fluxo na JVM, bem como no modo nativo via GraalVM. As APIs MicroProfile para verificações de integridade e métricas podem ser usadas para expor as informações corretas para obter informações sobre a execução de aplicativos de processamento de fluxo."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:336
#, fuzzy
msgid "Going forward, we plan to further reduce the efforts needed for building Kafka Streams applications on Quarkus.  Instead of having to deal with the lifecycle of the pipeline yourself, it should be enough to declare a CDI producer method returning the streaming `Topology`:"
msgstr "No futuro, planeamos reduzir ainda mais os esforços necessários para criar aplicações Kafka Streams na Quarkus. Em vez de ter de lidar com o ciclo de vida do pipeline, deve ser suficiente declarar um método produtor CDI que devolve o streaming `Topology`:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:344
#, no-wrap
msgid ""
"@Produces\n"
"public Topology buildTopology()  {\n"
"    // set up the stream topology\n"
"    StreamsBuilder builder = new StreamsBuilder();\n"
"    // builder.stream(...)\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:347
#, no-wrap
msgid ""
"    return builder.build();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:353
#, fuzzy
msgid "This means you'll be able to focus on implementing the actual pipeline logic, while the Quarkus extension would take care of everything else: configuring Kafka Streams based on the Quarkus `application.properties` file, starting the pipeline and automatically exposing healthchecks and metrics."
msgstr "Isto significa que se poderá concentrar na implementação da lógica real do pipeline, enquanto a extensão Quarkus trataria de tudo o resto: configurar os fluxos Kafka com base no ficheiro Quarkus `application.properties`, iniciar o pipeline e expor automaticamente os controlos de saúde e as métricas."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:357
#, fuzzy
msgid "In case this sounds interesting to you, have an eye on the next Quarkus release announcements, as this improved functionality should be out soon.  If you got any related ideas, let us know and join the discussion in Quarkus issue https://github.com/quarkusio/quarkus/issues/2863[#2863]."
msgstr "Caso isto lhe pareça interessante, esteja atento aos próximos anúncios de lançamento do Quarkus, uma vez que esta funcionalidade melhorada deverá ser lançada em breve. Se tiveres alguma ideia relacionada, avisa-nos e junta-te à discussão na edição  link:https://github.com/quarkusio/quarkus/issues/2863[#2863] do Quarkus."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:361
#, fuzzy
msgid "To learn more about the Quarkus extension for Kafka Streams and its current capabilities, check out link:/guides/kafka-streams[the detailed guide].  It not only discusses the actual stream pipeline implementation, but also touches on building (distributed) interactive queries for exposing the current processing state via REST."
msgstr "Para saber mais sobre a extensão Quarkus para Kafka Streams e seus recursos atuais, confira  link:/guides/kafka-streams[o guia detalhado]. Ele não apenas discute a implementação real do pipeline de fluxo, mas também aborda a criação de consultas interativas (distribuídas) para expor o estado de processamento atual via REST."

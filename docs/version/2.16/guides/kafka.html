<!DOCTYPE html>
<html lang="pt">







<head>
  <title>Guia de referência do Apache Kafka - 2.16 - Quarkus</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Security-Policy" content="
  connect-src 'self' https://dpm.demdex.net https://adobedc.demdex.net https://analytics.ossupstream.org/ https://search.quarkus.io https://smetrics.redhat.com https://ajax.googleapis.com; 
  script-src 'self' 'unsafe-inline' 'unsafe-eval'
      
      https://assets.adobedtm.com
      js.bizographics.com
      https://www.redhat.com
      https://static.redhat.com
      https://app.requestly.io/
      jsonip.com
      https://ajax.googleapis.com
      https://use.fontawesome.com
      http://www.youtube.com
      http://www.googleadservices.com
      https://googleads.g.doubleclick.net
      https://giscus.app
      https://analytics.ossupstream.org/
      https://app.mailjet.com;

  style-src 'self' https://fonts.googleapis.com https://use.fontawesome.com; 
  img-src 'self' * data:; 
  media-src 'self'; 
  frame-src https://redhat.demdex.net https://www.youtube.com https://player.restream.io https://app.mailjet.com http://xy0p2.mjt.lu https://mj.quarkus.io https://giscus.app; 
  base-uri 'none'; 
  object-src 'none'; 
  form-action 'none'; 
  font-src 'self' https://use.fontawesome.com https://fonts.gstatic.com;" />

  <script id="adobe_dtm" src="https://www.redhat.com/dtm.js" type="text/javascript"></script>
  <script src="/assets/javascript/highlight.pack.js" type="text/javascript"></script>
  <META HTTP-EQUIV='X-XSS-Protection' CONTENT="1; mode=block">
  <META HTTP-EQUIV='X-Content-Type-Options' CONTENT="nosniff">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Quarkus: Supersonic Subatomic Java">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@QuarkusIO"> 
  <meta name="twitter:creator" content="@QuarkusIO">
  <meta property="og:url" content="https://quarkus.io/version/2.16/guides/kafka" />
  <meta property="og:title" content="Guia de referência do Apache Kafka - 2.16" />
  <meta property="og:description" content="Quarkus: Supersonic Subatomic Java" />
  <meta property="og:image" content="https://quarkus.io/assets/images/quarkus_card.png" />
  
  <link rel="canonical" href="https://quarkus.io/guides/kafka">
  <link rel="shortcut icon" type="image/png" href="/favicon.ico" >
  <link rel="stylesheet" href="/guides/stylesheet/config.css" />
  <link rel="stylesheet" href="/assets/css/main.css?2021-07-29" />
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.5.2/css/all.css" crossorigin="anonymous">
  <link rel="alternate" type="application/rss+xml"  href="/feed.xml" title="Quarkus">
  <script src="/assets/javascript/hl.js" type="text/javascript"></script>
  
  
  
  
  <link rel="alternate" hreflang="en" href="https://quarkus.io/version/2.16/guides/kafka" />
  
  <link rel="alternate" hreflang="pt-br" href="https://pt.quarkus.io/version/2.16/guides/kafka" />
  
  <link rel="alternate" hreflang="es" href="https://es.quarkus.io/version/2.16/guides/kafka" />
  
  <link rel="alternate" hreflang="zh" href="https://cn.quarkus.io/version/2.16/guides/kafka" />
  
  <link rel="alternate" hreflang="ja" href="https://ja.quarkus.io/version/2.16/guides/kafka" />
  
  <link rel="alternate" hreflang="x-default" href="https://quarkus.io/" />  
  <script src="/assets/javascript/tracking.js"></script>
  
  <script src="/assets/javascript/colormode.js" type="text/javascript"></script>

</head>

<body class="guides">

  


<div class="grid-wrapper communitysite">
  <div class="grid__item width-12-12">The <a href="https://quarkus.io/version/2.16/guides/kafka">English version of quarkus.io</a> is the official project site. Translated sites are community supported on a best-effort basis.</div>
</div>


  <div class="nav-wrapper">
  <div class="grid-wrapper">
    <div class="width-12-12">
      <input type="checkbox" id="checkbox" />
      <nav id="main-nav" class="main-nav">
        <div class="logo-wrapper">
           <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_600px_reverse.png" class="project-logo" title="Quarkus"></a>
        </div>
    <label class="nav-toggle" for="checkbox"> <i class="fa fa-bars"></i>
</label>
    <ul id="menu" class="menu">
      <li class="dropdown">
        <span href="#">Why<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          <li><a href="/about" class="">O QUE É QUARKUS?</a></li>
          <li><a href="/developer-joy" class="">ALEGRIA DO DESENVOLVEDOR</a></li>
          <li><a href="/performance" class="">PERFORMANCE</a></li>
          <li><a href="/kubernetes-native" class="">KUBERNETES NATIVO</a></li>
          <li><a href="/standards" class="">PADRÕES</a></li>
          <li><a href="/versatility" class="">VERSATILITY</a></li>
          <li><a href="/container-first" class="">CONTAINER PRIMEIRO</a></li>
          <li><a href="/spring" class="">USING SPRING?</a></li>
          <li class="tertiarydropdown">
            <span href="#">AI<i class="fas fa-chevron-down"></i></span>
            <ul class="tertiarymenu">
              <li><a href="/ai" class="">AI OVERVIEW</a></li>
              <li><a href="/java-for-ai" class="">JAVA FOR AI</a></li>
              <li><a href="/quarkus-for-ai" class="">WHY QUARKUS FOR AI</a></li>
              <li><a href="/ai-blueprints" class="">AI BLUEPRINTS</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li class="dropdown">
        <span href="#">Learn<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          <li><a href="/get-started" class="">COMEÇAR</a></li>
          <li><a href="/guides" class="active">DOCUMENTAÇÃO</a></li>
          <li><a href="/userstories/" class="">USER STORIES</a></li>  
          <li><a href="/qtips" class="">VÍDEOS "Q" TIP</a></li>          
          <li><a href="/books" class="">LIVROS</a></li>
          </ul>
      </li>
      <li class="dropdown">
        <span href="#">Extensions<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          
          <!-- Note that quarkus.io is hardcoded here, because it is the only url which supports extensions -->
<li><a href="https://quarkus.io/extensions/" class="">PROCURAR EXTENSÕES</a></li>
          <li><a href="/faq/#what-is-a-quarkus-extension" class="">USAR
EXTENSÕES</a></li>
          <li><a href="/guides/writing-extensions" class="">CRIAR
EXTENSÕES</a></li>
          <li><a href="https://hub.quarkiverse.io" class="">COMPARTILHE EXTENSÕES</a></li>
        </ul>
      </li>
      <li class="dropdown">
        <span href="#">Community<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          <li><a href="/support/" class="">SUPORTE</a></li>
          <li><a href="/blog" class="">BLOG</a></li>
          <li><a href="/discussion" class="">DISCUSSÃO</a></li>
          <li><a href="/working-groups" class="">WORKING GROUPS</a></li>
          <li><a href="/insights" class="">PODCAST</a></li>
          <li><a href="/events" class="">EVENTOS</a></li>
          <li><a href="/newsletter" class="">BOLETIM INFORMATIVO</a></li>
          <li><a href="https://github.com/orgs/quarkusio/projects/13/views/1" class="">ROADMAP</a></li>
          <li><a href="/benefactors" class="">BENEFACTORS</a></li>
          </ul>
      </li>
      <li>
        <a href="https://code.quarkus.io" class="button-cta secondary white">COMECE
A CODIFICAR</a>
      </li>
      <li class="dropdown">
        <span href="/language/"><div class="fas fa-globe langicon"></div><i class="fas fa-chevron-down"></i></span>
        <ul class="submenu">
          <li><a href="https://quarkus.io/version/2.16/guides/kafka" >OFFICIAL (ENGLISH)</a></li>
          <li><a href="https://pt.quarkus.io/version/2.16/guides/kafka">PORTUGUÊS (BR)</a></li>
          <li><a href="https://es.quarkus.io/version/2.16/guides/kafka">ESPAÑOL</a></li>
          <li><a href="https://cn.quarkus.io/version/2.16/guides/kafka">简体中文</a></li>
          <li><a href="https://ja.quarkus.io/version/2.16/guides/kafka">日本語</a></li>
          </ul>
      </li>
      <li>
        <span href="#" class="modeswitcher" id='theme-toggle'><i class="fas
fa-sun"></i><i class="fas fa-moon"></i><i class="fas fa-cog"></i></span>
      </li>
    </ul>
      </nav>
    </div>
  </div>
</div>

  <div class="content">
    





<section class="full-width-version-bg flexfilterbar guides">
    <div class="guideflexcontainer">
        <div class="docslink">
            <a class="returnlink" href="/version/2.16/guides/"> Voltar aos Guias</a>
        </div>
        <div class="flexlabel">
            <label>Por Versão</label>
        </div>
        <div class="guidepulldown version">
            <select id="guide-version-dropdown">
                
                
                
                <option value="main" >Main - SNAPSHOT</option>
                
                
                
                <option value="latest" >3.32.1 - Latest</option>
                
                
                
                <option value="3.27" >3.27</option>
                
                
                
                <option value="3.20" >3.20</option>
                
                
                
                <option value="3.15" >3.15</option>
                
                
                
                <option value="3.8" >3.8</option>
                </select>
        </div>
    </div>
</section>

<div class="guide">
    <div class="grid-wrapper">
        <div class="grid__item width-8-12 width-12-12-m">
            <h1 class="text-caps">Guia de referência do Apache Kafka </h1>
            <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Este guia de referência demonstra como sua aplicação Quarkus pode utilizar a Mensageria Reativa do SmallRye para interagir com o Apache Kafka.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="introduction"><a class="anchor" href="#introduction"></a>1. Introdução</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://kafka.apache.org">O Apache Kafka</a> é uma plataforma popular de streaming de eventos distribuídos de código aberto. É comumente usado para pipelines de dados de alto desempenho, análise de streaming, integração de dados e aplicações de missão crítica. Semelhante a uma fila de mensagens ou a uma plataforma de mensagens corporativas, ele permite que você:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>publique</strong> (escreva) e <strong>assine</strong> (leia) fluxos de eventos, chamados de <em>registros</em>.</p>
</li>
<li>
<p><strong>armazene</strong> fluxos de registros de forma durável e confiável dentro de <em>tópicos</em>.</p>
</li>
<li>
<p><strong>processe</strong> fluxos de registros à medida que eles ocorrem ou retrospectivamente.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>E toda esta funcionalidade é fornecida de uma forma distribuída, altamente escalável, elástica, tolerante a falhas e segura.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="quarkus-extension-for-apache-kafka"><a class="anchor" href="#quarkus-extension-for-apache-kafka"></a>2. Extensão Quarkus para o Apache Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O Quarkus oferece suporte ao Apache Kafka por meio da estrutura <a href="https://smallrye.io/smallrye-reactive-messaging/">Mensageria Reativa do SmallRye</a>. Com base na especificação 2.0 da Mensageria Reativa do Eclipse MicroProfile, ele propõe um modelo de programação flexível que une o CDI e a orientação a eventos.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Este guia fornece uma visão detalhada do Apache Kafka e da estrutura da Mensageria Reativa do SmallRye. Para um início rápido, dê uma olhada em <a href="kafka-reactive-getting-started">Introdução à Mensageria Reativa do SmallRye com Apache Kafka</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Você pode adicionar as extensões <code>smallrye-reactive-messaging-kafka</code> ao seu projeto executando o seguinte comando no diretório base do seu projeto:</p>
</div>
<div class="listingblock primary asciidoc-tabs-sync-cli">
<div class="title">CLI</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">quarkus extension add 'smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-sync-maven">
<div class="title">Maven</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./mvnw quarkus:add-extension -Dextensions='smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-sync-gradle">
<div class="title">Gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./gradlew addExtension --extensions='smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Isto irá adicionar o seguinte trecho no seu arquivo de build:</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-smallrye-reactive-messaging-kafka&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.quarkus:quarkus-smallrye-reactive-messaging-kafka")</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A extensão inclui <code>kafka-clients</code> versão 3.2.1 como uma dependência transitiva e é compatível com os brokers Kafka versão 2.x.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="configuring-smallrye-kafka-connector"><a class="anchor" href="#configuring-smallrye-kafka-connector"></a>3. Configurando o Conector Kafka Smallrye</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Como a estrutura da Mensageria Reativa do Smallrye suporta diferentes backends de mensagens, como Apache Kafka, AMQP, Apache Camel, JMS, MQTT, etc., ela usa um vocabulário genérico:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>As aplicações enviam e recebem <strong>mensagens</strong>. Uma mensagem envolve uma <em>conteúdo</em> e pode ser estendida com alguns <em>metadados</em>. Com o conector Kafka, uma <em>mensagem</em> corresponde a um <em>registro</em> Kafka.</p>
</li>
<li>
<p>As mensagens transitam nos <strong>canais</strong>. Os componentes da aplicação ligam-se aos canais para publicar e consumir mensagens. O conector Kafka mapeia <em>canais</em> para <em>tópicos</em> Kafka.</p>
</li>
<li>
<p>Os canais são ligados a backends de mensagens através de <strong>conectores</strong>. Os conectores são configurados para mapear as mensagens de entrada para um canal específico (consumido pela aplicação) e recolher as mensagens de saída enviadas para um canal específico. Cada conector é dedicado a uma tecnologia de mensagens específica. Por exemplo, o conector que lida com o Kafka tem o nome de <code>smallrye-kafka</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Uma configuração mínima para o conector Kafka com um canal de entrada tem o seguinte aspecto:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.kafka.bootstrap.servers=kafka:9092 <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.incoming.prices.connector=smallrye-kafka <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configure a localização do broker para o perfil de produção. Você pode configurá-lo globalmente ou por canal usando a propriedade <code>mp.messaging.incoming.$channel.bootstrap.servers</code>. No modo de desenvolvimento e ao executar testes, <a href="#kafka-dev-services">Dev Services para o Kafka</a> inicia automaticamente um broker Kafka. Quando não fornecida, esta propriedade tem o valor padrão <code>localhost:9092</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Configure o conector para gerenciar o canal de preços. Por padrão, o nome do tópico é o mesmo que o nome do canal. Você pode configurar o atributo do tópico para o substituir.</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
O prefixo <code>%prod</code> indica que a propriedade só é utilizada quando a aplicação é executada em modo de produção (portanto, não em desenvolvimento ou teste). Consulte a <a href="config-reference#profiles">documentação do Perfil</a> para obter mais detalhes.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">Fixação automática do conector</div>
<div class="paragraph">
<p>Se você tiver um único conector no classpath, poderá omitir a configuração do atributo <code>connector</code>. O Quarkus associa automaticamente os canais <em>órfãos</em> ao conector (único) encontrado no classpath. Os canais <em>órfãos</em> são canais de saída sem um consumidor downstream ou canais de entrada sem um produtor ascendente.</p>
</div>
<div class="paragraph">
<p>Esta ligação automática pode ser desativada utilizando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.reactive-messaging.auto-connector-attachment=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="receiving-messages-from-kafka"><a class="anchor" href="#receiving-messages-from-kafka"></a>4. Recebendo mensagens do Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Continuando com a configuração mínima anterior, a sua aplicação Quarkus pode receber diretamente a conteúdo da mensagem:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;

@ApplicationScoped
public class PriceConsumer {

    @Incoming("prices")
    public void consume(double price) {
        // process your price.
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Existem várias outras formas da sua aplicação consumir mensagens recebidas:</p>
</div>
<div class="listingblock">
<div class="title">Message</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; consume(Message&lt;Double&gt; msg) {
    // access record metadata
    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();
    // process the message payload.
    double price = msg.getPayload();
    // Acknowledge the incoming message (commit the offset)
    return msg.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>O tipo <code>Message</code> permite que o método consumidor acesse os metadados da mensagem recebida e manipule a confirmação manualmente. Iremos explorar diferentes estratégias de confirmação em <a href="#commit-strategies">Estratégias de Confirmação</a>.</p>
</div>
<div class="paragraph">
<p>Se você pretende acessar diretamente os objetos do registro Kafka, utilize:</p>
</div>
<div class="listingblock">
<div class="title">ConsumerRecord</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(ConsumerRecord&lt;String, Double&gt; record) {
    String key = record.key(); // Can be `null` if the incoming record has no key
    String value = record.value(); // Can be `null` if the incoming record has no value
    String topic = record.topic();
    int partition = record.partition();
    // ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ConsumerRecord</code> é fornecido pelo cliente Kafka subjacente e pode ser injetado diretamente no método do consumidor. Outra abordagem mais simples consiste em usar <code>Record</code>:</p>
</div>
<div class="listingblock">
<div class="title">Record</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(Record&lt;String, Double&gt; record) {
    String key = record.key(); // Can be `null` if the incoming record has no key
    String value = record.value(); // Can be `null` if the incoming record has no value
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>Record</code> é um simples encapsulador em torno da chave e do conteúdo do registro Kafka recebido.</p>
</div>
<div class="paragraph">
<div class="title">@Channel</div>
<p>Alternativamente, sua aplicação pode injetar um <code>Multi</code> no seu bean e assinar os seus eventos, como no exemplo seguinte:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.mutiny.Multi;
import io.smallrye.reactive.messaging.annotations.Channel;

import javax.inject.Inject;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import org.jboss.resteasy.reactive.RestStreamElementType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("prices")
    Multi&lt;Double&gt; prices;

    @GET
    @Path("/prices")
    @RestStreamElementType(MediaType.TEXT_PLAIN)
    public Multi&lt;Double&gt; stream() {
        return prices;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Esse é um bom exemplo de como integrar um consumidor Kafka com outro downstream, neste exemplo, expondo-o como um endpoint Server-Sent Events.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Ao consumir mensagens com <code>@Channel</code>, o código da aplicação é responsável pela assinatura. No exemplo acima, o endpoint do RESTEasy Reativo cuida disso para você.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Os seguintes tipos podem ser injetados como canais:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Inject @Channel("prices") Multi&lt;Double&gt; streamOfPayloads;

@Inject @Channel("prices") Multi&lt;Message&lt;Double&gt;&gt; streamOfMessages;

@Inject @Channel("prices") Publisher&lt;Double&gt; publisherOfPayloads;

@Inject @Channel("prices") Publisher&lt;Message&lt;Double&gt;&gt; publisherOfMessages;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Assim como no exemplo anterior com <code>Message</code>, se o seu canal injetado recebe payloads (<code>Multi&lt;T&gt;</code>), ele reconhece a mensagem automaticamente e suporta múltiplos assinantes. Se o seu canal injetado recebe Mensagem (<code>Multi&lt;Message&lt;T&gt;&gt;</code>), você será responsável pela confirmação e transmissão. Iremos explorar o envio de mensagens de transmissão em <a href="#broadcasting-messages-on-multiple-consumers">Difusão de mensagens em vários consumidores</a>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Injetar <code>@Channel("prices")</code> ou ter <code>@Incoming("prices")</code> não configura automaticamente a aplicação para consumir mensagens do Kafka. Você precisa configurar um conector de entrada com <code>mp.messaging.incoming.prices&#8230;&#8203;</code> ou ter um método <code>@Outgoing("prices")</code> em algum lugar do sua aplicação (nesse caso, <code>prices</code> será um canal na memória).</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="blocking-processing"><a class="anchor" href="#blocking-processing"></a>4.1. Bloqueando o processamento</h3>
<div class="paragraph">
<p>A Mensageria Reativa invoca seu método em um thread de E/S. Consulte a <a href="quarkus-reactive-architecture">documentação da Arquitetura Reativa do Quarkus</a> para obter mais detalhes sobre esse tópico. Mas, muitas vezes, você precisa combinar o envio de mensagens reativas com processamento blocante, como interações de banco de dados. Para isso, você precisa usar a anotação <code>@Blocking</code> indicando que o processamento está <em>bloqueando</em> e não deve ser executado no thread do chamador.</p>
</div>
<div class="paragraph">
<p>Por exemplo, o código a seguir ilustra como é possível armazenar conteúdos recebidos em uma base de dados usando o Hibernate com Panache:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.reactive.messaging.annotations.Blocking;
import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;
import javax.transaction.Transactional;

@ApplicationScoped
public class PriceStorage {

    @Incoming("prices")
    @Transactional
    public void store(int priceInUsd) {
        Price price = new Price();
        price.value = priceInUsd;
        price.persist();
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The complete example is available in the <code>kafka-panache-quickstart</code> <a href="https://github.com/quarkusio/quarkus-quickstarts/tree/2.16/kafka-panache-quickstart">directory</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Existem 2 anotações de <code>@Blocking</code>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>io.smallrye.reactive.messaging.annotations.Blocking</code></p>
</li>
<li>
<p><code>io.smallrye.common.annotation.Blocking</code></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Eles têm o mesmo efeito. Portanto, você pode usar os dois. O primeiro fornece um ajuste mais refinado, como o pool de trabalho a ser usado e se ele preserva a ordem. O segundo, usado também com outros recursos reativos do Quarkus, usa o pool de trabalho padrão e preserva a ordem.</p>
</div>
<div class="paragraph">
<p>Informações detalhadas sobre a utilização da anotação <code>@Blocking</code> podem ser encontradas em <a href="https://smallrye.io/smallrye-reactive-messaging/latest/concepts/blocking/">Mensageria Reativa do SmallRye - Lidando com execução blocante</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">@Transactional</div>
<div class="paragraph">
<p>Se o seu método estiver anotado com <code>@Transactional</code>, será considerado <em>blocante</em> automaticamente, mesmo que o método não esteja anotado com <code>@Blocking</code>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="acknowledgment-strategies"><a class="anchor" href="#acknowledgment-strategies"></a>4.2. Estratégias de Reconhecimento</h3>
<div class="paragraph">
<p>Todas as mensagens recebidas por um consumidor devem ser confirmadas. Na ausência de confirmação, o processamento é considerado um erro. Se o método do consumidor receber um <code>Record</code> ou um conteúdo, a mensagem será confirmada no retorno do método, também conhecido como <code>Strategy.POST_PROCESSING</code>. Se o método do consumidor retornar outro fluxo reativo ou <code>CompletionStage</code>, a mensagem será confirmada quando a mensagem downstream for confirmada. Você pode substituir o comportamento padrão para acessar a mensagem na chegada (<code>Strategy.PRE_PROCESSING</code>) ou não acessar a mensagem de forma alguma (<code>Strategy.NONE</code>) no método do consumidor, como no exemplo a seguir:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
@Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING)
public void process(double price) {
    // process price
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Se o método consumidor receber uma <code>Message</code>, a estratégia de reconhecimento será <code>Strategy.MANUAL</code> e o método consumidor será responsável por reconhecer/não reconhecer a mensagem.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; process(Message&lt;Double&gt; msg) {
    // process price
    return msg.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Como mencionado acima, o método também pode substituir a estratégia de confirmação para <code>PRE_PROCESSING</code> ou <code>NONE</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="commit-strategies"><a class="anchor" href="#commit-strategies"></a>4.3. Estratégias de Confirmação</h3>
<div class="paragraph">
<p>Quando uma mensagem produzida a partir de um registro do Kafka é reconhecida, o conector invoca uma estratégia de confirmação. Essas estratégias decidem quando o deslocamento do consumidor para um tópico/partição específico é confirmado. A confirmação de um deslocamento indica que todos os registros anteriores foram processados. É também a posição em que a aplicação reiniciaria o processamento após uma recuperação de falha ou uma reinicialização.</p>
</div>
<div class="paragraph">
<p>A confirmação de cada deslocamento tem penalidades de desempenho, pois o gerenciamento de deslocamento do Kafka pode ser lento. No entanto, não confirmar o deslocamento com frequência suficiente pode levar à duplicação de mensagens se a aplicação falhar entre duas confirmações.</p>
</div>
<div class="paragraph">
<p>O conector Kafka suporta três estratégias:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>throttled</code> mantém o controle das mensagens recebidas e confirma um deslocamento da última mensagem recebida em sequência (ou seja, todas as mensagens anteriores também foram recebidas). Essa estratégia garante a entrega pelo menos uma vez, mesmo que o canal execute o processamento assíncrono. O conector rastreia os registros recebidos e periodicamente (período especificado por <code>auto.commit.interval.ms</code>, padrão: 5000 ms) confirma o maior deslocamento consecutivo. O conector será marcado como não saudável se uma mensagem associada a um registro não for confirmada em <code>throttled.unprocessed-record-max-age.ms</code> (padrão: 60000 ms). Na verdade, essa estratégia não pode confirmar o deslocamento assim que houver falha no processamento de um único registro. Se <code>throttled.unprocessed-record-max-age.ms</code> for definido como menor ou igual a <code>0</code>, ele não realizará nenhuma verificação de integridade. Essa configuração pode levar à falta de memória se houver mensagens do tipo "pílula de veneno" (que nunca são aceitas). Essa estratégia é o padrão se <code>enable.auto.commit</code> não estiver explicitamente definido como verdadeiro.</p>
</li>
<li>
<p><code>checkpoint</code> allows persisting consumer offsets on a <strong>state store</strong>, instead of committing them back to the Kafka broker.
Using the <code>CheckpointMetadata</code> API, consumer code can persist a <em>processing state</em> with the record offset to mark the progress of a consumer.
When the processing continues from a previously persisted offset, it seeks the Kafka consumer to that offset and also restores the persisted state, continuing the stateful processing from where it left off.
The checkpoint strategy holds locally the processing state associated with the latest offset, and persists it periodically to the state store (period specified by <code>auto.commit.interval.ms</code> (default: 5000)).
The connector will be marked as unhealthy if no processing state is persisted to the state store in <code>checkpoint.unsynced-state-max-age.ms</code> (default: 10000).
If <code>checkpoint.unsynced-state-max-age.ms</code> is set to less than or equal to 0, it does not perform any health check verification.
For more information, see <a href="#Stateful processing with Checkpointing">[Stateful processing with Checkpointing]</a></p>
</li>
<li>
<p><code>latest</code> confirma o deslocamento do registro recebido pelo consumidor do Kafka assim que a mensagem associada é confirmada (se o deslocamento for maior do que o deslocamento confirmado anteriormente). Essa estratégia oferece entrega pelo menos uma vez se o canal processar a mensagem sem executar nenhum processamento assíncrono. Essa estratégia não deve ser usada em ambientes de alta carga, pois a confirmação de deslocamento é cara. No entanto, ela reduz o risco de duplicatas.</p>
</li>
<li>
<p><code>ignore</code> não realiza nenhuma confirmação. Essa estratégia é a estratégia padrão quando o consumidor é configurado explicitamente com <code>enable.auto.commit</code> como true. Ela delega a confirmação de deslocamento para o cliente Kafka subjacente. Quando <code>enable.auto.commit</code> é <code>true</code>, essa estratégia <strong>NÃO</strong> garante a entrega pelo menos uma vez. A Mensageria Reativa do SmallRye processa registros de forma assíncrona, de modo que os deslocamentos podem ser confirmados para registros que foram pesquisados, mas ainda não processados. Em caso de falha, apenas os registros que ainda não foram confirmados serão reprocessados.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>O conector Kafka desativa a confirmação automática do Kafka quando ela não está explicitamente ativada. Esse comportamento difere do consumidor tradicional do Kafka. Se a alta taxa de transferência for importante para você, e se não estiver limitado pelo downstream, recomendamos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>utilizar a política <code>throttled</code>,</p>
</li>
<li>
<p>ou definir <code>enable.auto.commit</code> como verdadeiro e anotar o método de consumo com <code>@Acknowledgment(Acknowledgment.Strategy.NONE)</code>.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A Mensageria Reativa do Smallrye permite a implementação de estratégias de confirmação personalizadas. Consulte a <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement">documentação da Mensageria Reativa do SmallRye</a> para obter mais informações.</p>
</div>
</div>
<div class="sect2">
<h3 id="error-handling"><a class="anchor" href="#error-handling"></a>4.4. Estratégias de Tratamento de Erros</h3>
<div class="paragraph">
<p>Se uma mensagem produzida a partir de um registro Kafka não for enviada, é aplicada uma estratégia de falha. O conector Kafka suporta três estratégias:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>fail</code>: falha a aplicação, não serão processados mais registros (estratégia padrão). O deslocamento do registro que não foi processado corretamente não é confirmado.</p>
</li>
<li>
<p><code>ignore</code>: a falha é registrada, mas o processamento continua. O deslocamento do registro que não foi processado corretamente é confirmado.</p>
</li>
<li>
<p><code>dead-letter-queue</code>: o deslocamento do registro que não foi processado corretamente é confirmado, mas o registro é escrito em um tópico de letra morta do Kafka.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A estratégia é selecionada utilizando o atributo <code>failure-strategy</code>.</p>
</div>
<div class="paragraph">
<p>No caso do <code>dead-letter-queue</code>, você pode configurar os seguintes atributos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>dead-letter-queue.topic</code>: o tópico usado para escrever os registros não processados corretamente, o padrão é <code>dead-letter-topic-$channel</code>, sendo <code>$channel</code> o nome do canal.</p>
</li>
<li>
<p><code>dead-letter-queue.key.serializer</code>: o serializador usado para escrever a chave de registro na fila de letra morta. Por padrão, o serializador é deduzido a partir do desserializador da chave.</p>
</li>
<li>
<p><code>dead-letter-queue.value.serializer</code>: o serializador usado para escrever o valor do registro na fila de letras mortas. Por padrão, o serializador é deduzido a partir do desserializador do valor.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>O registro escrito na fila de cartas mortas contém um conjunto de cabeçalhos adicionais sobre o registro original:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>dead-letter-reason</strong>: o motivo da falha</p>
</li>
<li>
<p><strong>dead-letter-cause</strong>: a causa da falha, se houver</p>
</li>
<li>
<p><strong>dead-letter-topic</strong>: o tópico original do registro</p>
</li>
<li>
<p><strong>dead-letter-partition</strong>: a partição original do registro (inteiro mapeado para String)</p>
</li>
<li>
<p><strong>dead-letter-deslocamento</strong>: o deslocamento original do registro (long mapeado para String)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A Mensageria Reativa do Smallrye permite a implementação de estratégias de falha personalizadas. Para obter mais informações, consulte <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement">a documentação da Mensageria Reativa do SmallRye</a>.</p>
</div>
<div class="sect3">
<h4 id="retrying-processing"><a class="anchor" href="#retrying-processing"></a>4.4.1. Repetindo o processamento</h4>
<div class="paragraph">
<p>Você pode combinar a Mensageria Reativa com a <a href="https://github.com/smallrye/smallrye-fault-tolerance">Tolerância a Falhas do SmallRye</a> e tentar novamente o processamento em caso de falha:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("kafka")
@Retry(delay = 10, maxRetries = 5)
public void consume(String v) {
   // ... retry if this method throws an exception
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Você pode configurar o atraso, o número de tentativas, o jitter, etc.</p>
</div>
<div class="paragraph">
<p>Se o método devolver um <code>Uni</code> ou <code>CompletionStage</code>, é necessário acrescentar a anotação <code>@NonBlocking</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("kafka")
@Retry(delay = 10, maxRetries = 5)
@NonBlocking
public Uni&lt;String&gt; consume(String v) {
   // ... retry if this method throws an exception or the returned Uni produce a failure
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A anotação <code>@NonBlocking</code> só é necessária com a Tolerância a Falha do SmallRye 5.1.0 e versões anteriores. A partir da Tolerância a Falha do SmallRye 5.2.0 (disponível desde o Quarkus 2.1.0.Final), ela não é necessária. Consulte <a href="https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode">a documentação da Tolerância a Falha do SmallRye</a> para obter mais informações.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>As mensagens recebidas são reconhecidas somente quando o processamento é concluído com êxito. Portanto, ele confirma o deslocamento após o processamento bem-sucedido. Se o processamento ainda falhar, mesmo depois de todas as tentativas, a mensagem será <em>não reconhecida</em> e a estratégia de falha será aplicada.</p>
</div>
</div>
<div class="sect3">
<h4 id="handling-deserialization-failures"><a class="anchor" href="#handling-deserialization-failures"></a>4.4.2. Tratando Falhas de Desserialização</h4>
<div class="paragraph">
<p>Quando ocorre uma falha na desserialização, você pode interceptá-la e fornecer uma estratégia de falha. Para isso, você precisa criar um bean que implemente a interface <code>DeserializationFailureHandler&lt;T&gt;</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
@Identifier("failure-retry") // Set the name of the failure handler
public class MyDeserializationFailureHandler
    implements DeserializationFailureHandler&lt;JsonObject&gt; { // Specify the expected type

    @Override
    public JsonObject decorateDeserialization(Uni&lt;JsonObject&gt; deserialization, String topic, boolean isKey,
            String deserializer, byte[] data, Headers headers) {
        return deserialization
                    .onFailure().retry().atMost(3)
                    .await().atMost(Duration.ofMillis(200));
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para utilizar este manipulador de falhas, o bean deve ser exposto com o qualificador <code>@Identifier</code> e a configuração do conector deve especificar o atributo <code>mp.messaging.incoming.$channel.[key|value]-deserialization-failure-handler</code> (para desserializadores de chave ou de valor).</p>
</div>
<div class="paragraph">
<p>O manipulador é chamado com detalhes da desserialização, inclusive a ação representada como <code>Uni&lt;T&gt;</code>. Na desserialização <code>Uni</code> podem ser implementadas estratégias de falha, como tentar novamente, fornecer um valor de reserva ou aplicar o tempo limite.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="consumer-groups"><a class="anchor" href="#consumer-groups"></a>4.5. Grupos de Consumidores</h3>
<div class="paragraph">
<p>No Kafka, um grupo de consumidores é um conjunto de consumidores que cooperam para consumir dados de um tópico. Um tópico é dividido em um conjunto de partições. As partições de um tópico são atribuídas entre os consumidores do grupo, o que permite dimensionar efetivamente a taxa de transferência do consumo. Observe que cada partição é atribuída a um único consumidor de um grupo. No entanto, um consumidor pode ser atribuído a várias partições se o número de partições for maior que o número de consumidores no grupo.</p>
</div>
<div class="paragraph">
<p>Vamos explorar brevemente diferentes padrões de produtor/consumidor e como implementá-los usando o Quarkus:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Uma única thread de consumidor dentro de um grupo de consumidores</strong></p>
<div class="paragraph">
<p>Esse é o comportamento padrão de uma aplicação que se inscreve em um tópico do Kafka: Cada conector Kafka criará um único thread de consumidor e o colocará em um único grupo de consumidores. O ID do grupo de consumidores tem como padrão o nome da aplicação, conforme definido pela propriedade de configuração <code>quarkus.application.name</code>. Ele também pode ser definido por meio da propriedade <code>kafka.group.id</code>.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-one-app-one-consumer.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>Vários threads de consumidores em um grupo de consumidores</strong></p>
<div class="paragraph">
<p>For a given application instance, the number of consumers inside the consumer group can be configured using <code>mp.messaging.incoming.$channel.partitions</code> property.
The partitions of the subscribed topic will be divided among the consumer threads.
Note that if the <code>partitions</code> value exceed the number of partitions of the topic, some consumer threads won&#8217;t be assigned any partitions.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-one-app-two-consumers.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>Várias aplicações de consumo dentro de um grupo de consumidores</strong></p>
<div class="paragraph">
<p>Da mesma forma que no exemplo anterior, várias instâncias de uma aplicação podem se inscrever em um único grupo de consumidores, configurado por meio da propriedade <code>mp.messaging.incoming.$channel.group.id</code> ou deixado como padrão para o nome da aplicação. Isso, por sua vez, dividirá as partições do tópico entre as instâncias da aplicação.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-two-app-one-consumer-group.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>Pub/Sub: Vários grupos de consumidores inscritos em um tópico</strong></p>
<div class="paragraph">
<p>Por fim, diferentes aplicações podem se inscrever independentemente nos mesmos tópicos usando diferentes <strong>IDs de grupos de consumidores</strong>. Por exemplo, as mensagens publicadas em um tópico chamado <em>pedidos</em> podem ser consumidas de forma independente em duas aplicações de consumo, uma com <code>mp.messaging.incoming.orders.group.id=invoicing</code> e a segunda com <code>mp.messaging.incoming.orders.group.id=shipping</code>. Assim, diferentes grupos de consumidores podem ser dimensionados de forma independente de acordo com os requisitos de consumo de mensagens.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-two-app-two-consumer-groups.png" alt="Architecture" width="60%">
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Um requisito negocial comum é consumir e processar os registros do Kafka em ordem. O broker Kafka preserva a ordem dos registros dentro de uma partição e não dentro de um tópico. Portanto, é importante pensar em como os registros são particionados dentro de um tópico. O particionador padrão usa o hash da chave do registro para calcular a partição de um registro ou, quando a chave não é definida, escolhe uma partição aleatoriamente por lote ou registros.</p>
</div>
<div class="paragraph">
<p>Durante a operação normal, um consumidor Kafka preserva a ordem dos registros dentro de cada partição atribuída a ele. A Mensageria Reativa do Smallrye mantém essa ordem para processamento, a menos que <code>@Blocking(ordered = false)</code> seja usado (veja <a href="#blocking-processing">Bloqueando o processamento</a>).</p>
</div>
<div class="paragraph">
<p>Note que, devido aos rebalanceamentos dos consumidores, os consumidores Kafka apenas garantem o processamento pelo menos uma vez de registros individuais, o que significa que os registros não confirmados <em>podem</em> ser processados novamente pelos consumidores.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="consumer-rebalance-listener"><a class="anchor" href="#consumer-rebalance-listener"></a>4.5.1. Listener de Rebalanceamento do Consumidor</h4>
<div class="paragraph">
<p>Em um grupo de consumidores, à medida que novos membros do grupo chegam e membros antigos saem, as partições são reatribuídas para que cada membro receba uma parte proporcional das partições. Isso é conhecido como rebalanceamento do grupo. Para lidar com a confirmação de deslocamento e as partições atribuídas, você pode fornecer um listener de rebalanceamento de consumidor. Para isso, implemente a interface <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> e exponha-a como um bean CDI com o qualificador <code>@Idenfier</code>. Um caso de uso comum é armazenar o deslocamento em um armazém de dados separado para implementar a semântica exatamente único ou iniciar o processamento em um deslocamento específico.</p>
</div>
<div class="paragraph">
<p>O listener é chamado sempre que a atribuição de tópico/partição do consumidor é alterada. Por exemplo, quando a aplicação é iniciada, ele invoca call-back <code>partitionsAssigned</code> com o conjunto inicial de tópicos/partições associados ao consumidor. Se, mais tarde, esse conjunto for alterado, ele chama novamente os callbacks <code>partitionsRevoked</code> e <code>partitionsAssigned</code>, para que você possa implementar uma lógica personalizada.</p>
</div>
<div class="paragraph">
<p>Observe que os métodos do ouvinte de rebalanceamento são chamados a partir da thread de polling do Kafka e <strong>bloquearão</strong> a thread do chamador até a conclusão. Isso ocorre porque o protocolo de rebalanceamento tem barreiras de sincronização, e o uso de código assíncrono em um ouvinte de rebalanceamento pode ser executado após a barreira de sincronização.</p>
</div>
<div class="paragraph">
<p>Quando os tópicos/partições são atribuídos ou revogados por um consumidor, o envio de mensagens é interrompido e retomado após a conclusão do rebalanceamento.</p>
</div>
<div class="paragraph">
<p>Se o ouvinte de rebalanceamento lidar com a confirmação de deslocamento em nome do usuário (usando a estratégia de confirmação <code>NONE</code>), o ouvinte de rebalanceamento deverá confirmar o deslocamento de forma síncrona na chamada de retorno partitionsRevoked. Também recomendamos aplicar a mesma lógica quando a aplicação for interrompida.</p>
</div>
<div class="paragraph">
<p>Ao contrário dos métodos <code>ConsumerRebalanceListener</code> do Apache Kafka, os métodos <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> transmitem o consumidor Kafka e o conjunto de tópicos/partições.</p>
</div>
<div class="paragraph">
<p>No exemplo a seguir, configuramos um consumidor que sempre inicia com mensagens de, no máximo, 10 minutos atrás (ou deslocamento 0). Primeiro, precisamos fornecer um bean que implemente <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> e seja anotado com <code>io.smallrye.common.annotation.Identifier</code>. Em seguida, devemos configurar nosso conector de entrada para usar esse bean.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package inbound;

import io.smallrye.common.annotation.Identifier;
import io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.OffsetAndTimestamp;
import org.apache.kafka.clients.consumer.TopicPartition;

import javax.enterprise.context.ApplicationScoped;
import java.util.Collection;
import java.util.HashMap;
import java.util.Map;
import java.util.logging.Logger;

@ApplicationScoped
@Identifier("rebalanced-example.rebalancer")
public class KafkaRebalancedConsumerRebalanceListener implements KafkaConsumerRebalanceListener {

    private static final Logger LOGGER = Logger.getLogger(KafkaRebalancedConsumerRebalanceListener.class.getName());

    /**
     * When receiving a list of partitions, will search for the earliest offset within 10 minutes
     * and seek the consumer to it.
     *
     * @param consumer   underlying consumer
     * @param partitions set of assigned topic partitions
     */
    @Override
    public void onPartitionsAssigned(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions) {
        long now = System.currentTimeMillis();
        long shouldStartAt = now - 600_000L; //10 minute ago

        Map&lt;TopicPartition, Long&gt; request = new HashMap&lt;&gt;();
        for (TopicPartition partition : partitions) {
            LOGGER.info("Assigned " + partition);
            request.put(partition, shouldStartAt);
        }
        Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = consumer.offsetsForTimes(request);
        for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; position : offsets.entrySet()) {
            long target = position.getValue() == null ? 0L : position.getValue().offset();
            LOGGER.info("Seeking position " + target + " for " + position.getKey());
            consumer.seek(position.getKey(), target);
        }
    }

}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package inbound;

import io.smallrye.reactive.messaging.kafka.IncomingKafkaRecord;
import org.eclipse.microprofile.reactive.messaging.Acknowledgment;
import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.CompletionStage;

@ApplicationScoped
public class KafkaRebalancedConsumer {

    @Incoming("rebalanced-example")
    @Acknowledgment(Acknowledgment.Strategy.NONE)
    public CompletionStage&lt;Void&gt; consume(IncomingKafkaRecord&lt;Integer, String&gt; message) {
        // We don't need to ACK messages because in this example,
        // we set offset during consumer rebalance
        return CompletableFuture.completedFuture(null);
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para configurar o conector de entrada para usar o ouvinte fornecido, definimos o identificador do ouvinte de rebalanceamento do consumidor: <code>mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer</code></p>
</div>
<div class="paragraph">
<p>Ou fazer com que o nome do ouvinte seja o mesmo que o ID do grupo:</p>
</div>
<div class="paragraph">
<p><code>mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer</code></p>
</div>
<div class="paragraph">
<p>A definição do nome do ouvinte de rebalanceamento do consumidor tem precedência sobre a utilização do ID do grupo.</p>
</div>
</div>
<div class="sect3">
<h4 id="using-unique-consumer-groups"><a class="anchor" href="#using-unique-consumer-groups"></a>4.5.2. Utilizando grupos de consumidores únicos</h4>
<div class="paragraph">
<p>Para processar todos os registros de um tópico (desde o seu início), é necessário:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>definir <code>auto.deslocamento.reset = earliest</code></p>
</li>
<li>
<p>atribuir o seu consumidor a um grupo de consumidores não utilizado por nenhuma outra aplicação.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>O Quarkus gera um UUID que muda entre duas execuções (inclusive no modo de desenvolvimento). Assim, você tem certeza de que nenhum outro consumidor o utiliza e recebe um novo ID de grupo exclusivo sempre que a aplicação é iniciada.</p>
</div>
<div class="paragraph">
<p>Você pode utilizar esse UUID gerado como o grupo de consumidores da seguinte forma:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.your-channel.auto.offset.reset=earliest
mp.messaging.incoming.your-channel.group.id=${quarkus.uuid}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Se o atributo <code>group.id</code> não estiver definido, a propriedade de configuração <code>quarkus.application.name</code> é utilizada por padrão.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="receiving-kafka-records-in-batches"><a class="anchor" href="#receiving-kafka-records-in-batches"></a>4.6. Recebendo Registros Kafka em Lotes</h3>
<div class="paragraph">
<p>Por padrão, os métodos de entrada recebem cada registro do Kafka individualmente. Por trás disso, os clientes consumidores do Kafka consultam o broker constantemente e recebem registros em lotes, apresentados dentro do contêiner <code>ConsumerRecords</code>.</p>
</div>
<div class="paragraph">
<p>No modo <strong>batch</strong>, a sua aplicação pode receber todos os registros devolvidos pela <strong>consulta</strong> do consumidor de uma só vez.</p>
</div>
<div class="paragraph">
<p>Para tal, é necessário especificar um tipo de contêiner compatível para receber todos os dados:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(List&lt;Double&gt; prices) {
    for (double price : prices) {
        // process price
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The incoming method can also receive <code>Message&lt;List&lt;Payload&gt;&gt;</code>, <code>KafkaRecordBatch&lt;Key, Payload&gt;</code> <code>ConsumerRecords&lt;Key, Payload&gt;</code> types.
They give access to record details such as offset or timestamp:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; consumeMessage(KafkaRecordBatch&lt;String, Double&gt; records) {
    for (KafkaRecord&lt;String, Double&gt; record : records) {
        String payload = record.getPayload();
        String topic = record.getTopic();
        // process messages
    }
    // ack will commit the latest offsets (per partition) of the batch.
    return records.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Observe que o processamento bem-sucedido do lote de registros de entrada confirmará os deslocamentos mais recentes de cada partição recebida dentro do lote. A estratégia de confirmação configurada será aplicada somente a esses registros.</p>
</div>
<div class="paragraph">
<p>Inversamente, se o processamento lançar uma exceção, todas as mensagens são <em>não reconhecidas</em>, aplicando a estratégia de falha a todos os registros dentro do lote.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>O Quarkus detecta automaticamente os tipos de lote para os canais de entrada e define a configuração do lote automaticamente. Você pode configurar o modo de lote explicitamente com a propriedade <code>mp.messaging.incoming.$channel.batch</code>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="stateful-processing-with-checkpointing"><a class="anchor" href="#stateful-processing-with-checkpointing"></a>4.7. Processamento com estado com Ponto de Verificação</h3>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A estratégia de submissão <code>checkpoint (ponto de verificação)</code> é uma funcionalidade experimental e pode ser alterada no futuro.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Smallrye Reactive Messaging <code>checkpoint</code> commit strategy allows consumer applications to process messages in a stateful manner, while also respecting Kafka consumer scalability.
An incoming channel with <code>checkpoint</code> commit strategy persists consumer offsets on an external
<a href="#state-stores">state store</a>, such as a relational database or a key-value store.
As a result of processing consumed records, the consumer application can accumulate an internal state for each topic-partition assigned to the Kafka consumer.
This local state will be periodically persisted to the state store and will be associated with the offset of the record that produced it.</p>
</div>
<div class="paragraph">
<p>Essa estratégia não confirma nenhum deslocamento para o broker Kafka, portanto, quando novas partições são atribuídas ao consumidor, ou seja, o consumidor é reiniciado ou as instâncias do grupo de consumidores são escalonadas, o consumidor retoma o processamento a partir do último deslocamento do <em>ponto de verificação</em> com seu estado salvo.</p>
</div>
<div class="paragraph">
<p>O código do consumidor do canal <code>@Incoming</code> pode manipular o estado de processamento por meio da API <code>CheckpointMetadata</code>. Por exemplo, um consumidor que calcula a média móvel dos preços recebidos em um tópico do Kafka teria a seguinte aparência:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Message;

import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import io.smallrye.reactive.messaging.kafka.commit.CheckpointMetadata;

@ApplicationScoped
public class MeanCheckpointConsumer {

    @Incoming("prices")
    public CompletionStage&lt;Void&gt; consume(Message&lt;Double&gt; record) {
        // Get the `CheckpointMetadata` from the incoming message
        CheckpointMetadata&lt;AveragePrice&gt; checkpoint = CheckpointMetadata.fromMessage(record);

        // `CheckpointMetadata` allows transforming the processing state
        // Applies the given function, starting from the value `0.0` when no previous state exists
        checkpoint.transform(new AveragePrice(), average -&gt; average.update(record.getPayload()), /* persistOnAck */ true);

        // `persistOnAck` flag set to true, ack will persist the processing state
        // associated with the latest offset (per partition).
        return record.ack();
    }

    static class AveragePrice {
        long count;
        double mean;

        AveragePrice update(double newPrice) {
            mean += ((newPrice - mean) / ++count);
            return this;
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>O método <code>transform</code> aplica a função de transformação ao estado atual, produzindo um estado alterado e registrando-o localmente para checkpointing. Por padrão, o estado local é mantido no armazém de estado periodicamente, período especificado por <code>auto.commit.interval.ms</code>, (padrão: 5000). Se o sinalizador <code>persistOnAck</code> for fornecido, o estado mais recente será persistido no armazém de estado ansiosamente no reconhecimento da mensagem. O método <code>setNext</code> funciona de forma semelhante, definindo diretamente o estado mais recente.</p>
</div>
<div class="paragraph">
<p>A estratégia de confirmação de ponto de verificação rastreia quando um estado de processamento foi mantido pela última vez para cada partição de tópico. Se uma alteração de estado pendente não puder ser mantida por <code>checkpoint.unsynced-state-max-age.ms</code> (padrão: 10000), o canal será marcado como não saudável.</p>
</div>
<div class="sect3">
<h4 id="state-stores"><a class="anchor" href="#state-stores"></a>4.7.1. State stores (armazéns de estado)</h4>
<div class="paragraph">
<p>As implementações de armazém de estado determinam onde e como os estados de processamento são mantidos. Isso é configurado pela propriedade <code>mp.messaging.incoming.[channel-name].checkpoint.state-store</code>. A serialização de objetos de estado depende da implementação do armazém de estado. Para instruir os armazéns de estado para serialização, pode ser necessário configurar o nome da classe dos objetos de estado usando a propriedade <code>mp.messaging.incoming.[channel-name].checkpoint.state-type</code>.</p>
</div>
<div class="paragraph">
<p>O Quarkus fornece as seguintes implementações de armazém de estado:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>quarkus-redis</code>: Uses the <a href="redis-reference"><code>quarkus-redis-client</code></a> extension to persist processing states.
Jackson is used to serialize processing state in Json. For complex objects it is required to configure the <code>checkpoint.state-type</code> property with the class name of the object.
By default, the state store uses the default redis client, but if a <a href="https://quarkus.io/guides/redis-reference#default-and-named-clients">named client</a> is to be used, the client name can be specified using the <code>mp.messaging.incoming.[channel-name].checkpoint.quarkus-redis.client-name</code> property.
Processing states will be stored in Redis using the key naming scheme <code>[consumer-group-id]:[topic]:[partition]</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Por exemplo, a configuração do código anterior seria a seguinte:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices.group.id=prices-checkpoint
# ...
mp.messaging.incoming.prices.commit-strategy=checkpoint
mp.messaging.incoming.prices.checkpoint.state-store=quarkus-redis
mp.messaging.incoming.prices.checkpoint.state-type=org.acme.MeanCheckpointConsumer.AveragePrice
# ...
# if using a named redis client
mp.messaging.incoming.prices.checkpoint.quarkus-redis.client-name=my-redis
quarkus.redis.my-redis.hosts=redis://localhost:7000
quarkus.redis.my-redis.password=&lt;redis-pwd&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>quarkus-hibernate-reactive</code>: Uses the <a href="hibernate-reactive"><code>quarkus-hibernate-reactive</code></a> extension to persist processing states.
Processing state objects are required to be a JPA entity and extend the <code>CheckpointEntity</code> class,
which handles object identifiers composed of the consumer group id, topic and partition.
Therefore, the class name of the entity needs to be configured using the <code>checkpoint.state-type</code> property.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Por exemplo, a configuração do código anterior seria a seguinte:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices.group.id=prices-checkpoint
# ...
mp.messaging.incoming.prices.commit-strategy=checkpoint
mp.messaging.incoming.prices.checkpoint.state-store=quarkus-hibernate-reactive
mp.messaging.incoming.prices.checkpoint.state-type=org.acme.AveragePriceEntity</code></pre>
</div>
</div>
<div class="paragraph">
<p>With <code>AveragePriceEntity</code> being a JPA entity extending <code>CheckpointEntity</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.persistence.Entity;

import io.quarkus.smallrye.reactivemessaging.kafka.CheckpointEntity;

@Entity
public class AveragePriceEntity extends CheckpointEntity {
    public long count;
    public double mean;

    public AveragePriceEntity update(double newPrice) {
        mean += ((newPrice - mean) / ++count);
        return this;
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>quarkus-hibernate-orm</code>: Usa a extensão <a href="hibernate-orm">quarkus-hibernate-orm</a> para manter os estados de processamento. É semelhante ao armazém de estado anterior, mas usa o Hibernate ORM em vez do Hibernate Reativo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Quando configurado, ele pode usar um <code>persistence-unit</code> nomeado para o armazém de estado de ponto de verificação:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices.commit-strategy=checkpoint
mp.messaging.incoming.prices.checkpoint.state-store=quarkus-hibernate-orm
mp.messaging.incoming.prices.checkpoint.state-type=org.acme.AveragePriceEntity
mp.messaging.incoming.prices.checkpoint.quarkus-hibernate-orm.persistence-unit=prices
# ... Setup "prices" persistence unit
quarkus.datasource."prices".db-kind=postgresql
quarkus.datasource."prices".username=&lt;your username&gt;
quarkus.datasource."prices".password=&lt;your password&gt;
quarkus.datasource."prices".jdbc.url=jdbc:postgresql://localhost:5432/hibernate_orm_test
quarkus.hibernate-orm."prices".datasource=prices
quarkus.hibernate-orm."prices".packages=org.acme</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para obter instruções sobre como implementar armazéns de estado personalizados, consulte <a href="https://smallrye.io/smallrye-reactive-messaging/3.22.0/kafka/receiving-kafka-records/#implementing-state-stores">Implementando Armazéns de Estado</a>.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sending-messages-to-kafka"><a class="anchor" href="#sending-messages-to-kafka"></a>5. Enviando mensagens para o Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A configuração dos canais de saída do conector Kafka é semelhante à dos canais de entrada:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.kafka.bootstrap.servers=kafka:9092 <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.outgoing.prices-out.connector=smallrye-kafka <i class="conum" data-value="2"></i><b>(2)</b>
mp.messaging.outgoing.prices-out.topic=prices <i class="conum" data-value="3"></i><b>(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configure a localização do broker para o perfil de produção. Você pode configurá-lo globalmente ou por canal usando a propriedade <code>mp.messaging.outgoing.$channel.bootstrap.servers</code>. No modo de desenvolvimento e ao executar testes, <a href="#kafka-dev-services">Dev Services para o Kafka</a> inicia automaticamente um broker Kafka. Quando não fornecida, esta propriedade tem o valor padrão <code>localhost:9092</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Configure o conector para gerenciar o canal <code>prices-out</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Por padrão, o nome do tópico é igual ao nome do canal. Você pode configurar o atributo de tópico para o substituir.</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Dentro da configuração da aplicação, os nomes dos canais são exclusivos. Portanto, se quiser configurar um canal de entrada e de saída no mesmo tópico, você precisará nomear os canais de forma diferente (como nos exemplos deste guia, <code>mp.messaging.incoming.prices</code> e <code>mp.messaging.outgoing.prices-out</code>).</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Em seguida, sua aplicação pode gerar mensagens e publicá-las no canal <code>prices-out</code>. Ele pode usar os conteúdos do <code>double</code>, como no trecho a seguir:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.mutiny.Multi;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;
import java.time.Duration;
import java.util.Random;

@ApplicationScoped
public class KafkaPriceProducer {

    private final Random random = new Random();

    @Outgoing("prices-out")
    public Multi&lt;Double&gt; generate() {
        // Build an infinite stream of random prices
        // It emits a price every second
        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -&gt; random.nextDouble());
    }

}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Você não deve chamar métodos anotados com <code>@Incoming</code> e/ou <code>@Outgoing</code> diretamente a partir do seu código. Eles são invocados pela estrutura. O fato do código do usuário os invocar não teria o resultado esperado.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Observe que o método <code>generate</code> retorna um <code>Multi&lt;Double&gt;</code>, que implementa a interface <code>Publisher</code> do Reactive Streams. Esse publicador será usado pela estrutura para gerar mensagens e enviá-las ao tópico Kafka configurado.</p>
</div>
<div class="paragraph">
<p>Em vez de devolver uma conteúdo, você pode devolver um <code>io.smallrye.reactive.messaging.kafka.Record</code> para enviar pares de chave/valor:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("out")
public Multi&lt;Record&lt;String, Double&gt;&gt; generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
        .map(x -&gt; Record.of("my-key", random.nextDouble()));
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>O conteúdo pode ser envolvido em uma <code>org.eclipse.microprofile.reactive.messaging.Message</code> para ter mais controle sobre os registros escritos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("generated-price")
public Multi&lt;Message&lt;Double&gt;&gt; generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -&gt; Message.of(random.nextDouble())
                    .addMetadata(OutgoingKafkaRecordMetadata.&lt;String&gt;builder()
                            .withKey("my-key")
                            .withTopic("my-key-prices")
                            .withHeaders(new RecordHeaders().add("my-header", "value".getBytes()))
                            .build()));
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>OutgoingKafkaRecordMetadata</code> permite definir atributos de metadados do registro do Kafka, como <code>key</code>, <code>topic</code>, <code>partition</code> ou <code>timestamp</code>. Um caso de uso é selecionar dinamicamente o tópico de destino de uma mensagem. Nesse caso, em vez de configurar o tópico dentro do arquivo de configuração da aplicação, você precisa usar os metadados de saída para definir o nome do tópico.</p>
</div>
<div class="paragraph">
<p>Além das assinaturas de método que retornam um <code>Publisher</code> do Reactive Stream (<code>Multi</code> é uma implementação de <code>Publisher</code>), o método de saída também pode retornar uma única mensagem. Nesse caso, o produtor usará esse método como gerador para criar um fluxo infinito.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("prices-out") T generate(); // T excluding void

@Outgoing("prices-out") Message&lt;T&gt; generate();

@Outgoing("prices-out") Uni&lt;T&gt; generate();

@Outgoing("prices-out") Uni&lt;Message&lt;T&gt;&gt; generate();

@Outgoing("prices-out") CompletionStage&lt;T&gt; generate();

@Outgoing("prices-out") CompletionStage&lt;Message&lt;T&gt;&gt; generate();</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="sending-messages-with-emitter"><a class="anchor" href="#sending-messages-with-emitter"></a>5.1. Enviando mensagens com @Emitter</h3>
<div class="paragraph">
<p>Às vezes, você precisa ter uma forma imperativa de enviar mensagens.</p>
</div>
<div class="paragraph">
<p>Por exemplo, se você precisar enviar uma mensagem para um fluxo ao receber uma solicitação POST dentro de um endpoint REST. Nesse caso, você não pode usar <code>@Outgoing</code> porque seu método tem parâmetros.</p>
</div>
<div class="paragraph">
<p>Para tal, pode utilizar um <code>Emitter</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    Emitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public void addPrice(Double price) {
        CompletionStage&lt;Void&gt; ack = priceEmitter.send(price);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>O envio de um conteúdo devolve um <code>CompletionStage</code>, concluído quando a mensagem é recebida. Se a transmissão da mensagem falhar, o <code>CompletionStage</code> é completado excepcionalmente com a razão do não reconhecimento.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A configuração de <code>Emitter</code> é efetuada da mesma forma que a outra configuração de fluxo utilizada por <code>@Incoming</code> e <code>@Outgoing</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Usando o <code>Emitter</code>, você envia mensagens do seu código imperativo para mensagens reativas. Essas mensagens são armazenadas em uma fila até serem enviadas. Se o cliente produtor do Kafka não conseguir acompanhar as mensagens que tentam ser enviadas para o Kafka, essa fila pode se tornar um consumidor de memória e você pode até ficar sem memória. Você pode usar <code>@OnOverflow</code> para configurar a estratégia de contrapressão (back-pressure). Ele permite que você configure o tamanho da fila (o padrão é 256) e a estratégia a ser aplicada quando o tamanho do buffer for atingido. As estratégias disponíveis são <code>DROP</code>, <code>LATEST</code>, <code>FAIL</code>, <code>BUFFER</code>, <code>UNBOUNDED_BUFFER</code> e <code>NONE</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Com a API <code>Emitter</code>, você também pode encapsular o payload de saída dentro de <code>Message&lt;T&gt;</code>. Tal como nos exemplos anteriores, <code>Message</code> te permite tratar os casos de reconhecimento/não reconhecimento de forma diferente.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.concurrent.CompletableFuture;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

@Path("/prices")
public class PriceResource {

    @Inject @Channel("price-create") Emitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public void addPrice(Double price) {
        priceEmitter.send(Message.of(price)
            .withAck(() -&gt; {
                // Called when the message is acked
                return CompletableFuture.completedFuture(null);
            })
            .withNack(throwable -&gt; {
                // Called when the message is nacked
                return CompletableFuture.completedFuture(null);
            }));
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Se preferir usar APIs de fluxo reativo, você pode usar <code>MutinyEmitter</code> que retornará <code>Uni&lt;Void&gt;</code> do método <code>send</code>. Portanto, você pode usar as APIs do Mutiny para lidar com mensagens e erros downstream.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Channel;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

import io.smallrye.reactive.messaging.MutinyEmitter;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    MutinyEmitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public Uni&lt;String&gt; addPrice(Double price) {
        return quoteRequestEmitter.send(price)
                .map(x -&gt; "ok")
                .onFailure().recoverWithItem("ko");
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Também é possível bloquear o envio do evento para o emissor com o método <code>sendAndAwait</code>. Ele só retornará do método quando o evento for aceito ou bloqueado pelo receptor.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Depreciação</div>
<div class="paragraph">
<p>As classes <code>io.smallrye.reactive.messaging.annotations.Emitter</code>, <code>io.smallrye.reactive.messaging.annotations.Channel</code> e <code>io.smallrye.reactive.messaging.annotations.OnOverflow</code> são agora obsoletas e substituídas por:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.Emitter</code></p>
</li>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.Channel</code></p>
</li>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.OnOverflow</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>O novo método <code>Emitter.send</code> devolve um <code>CompletionStage</code> concluído quando a mensagem produzida é confirmada.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Depreciation</div>
<div class="paragraph">
<p><code>MutinyEmitter#send(Message msg)</code> está obsoleto em favor dos seguintes métodos que recebem <code>Message</code> para emitir:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; Uni&lt;Void&gt; sendMessage(M msg)</code></p>
</li>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; void sendMessageAndAwait(M msg)</code></p>
</li>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; Cancellable sendMessageAndForget(M msg)</code></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Mais informações sobre como usar <code>Emitter</code> podem ser encontradas em <a href="https://smallrye.io/smallrye-reactive-messaging/latest/concepts/emitter/">Mensageria Reativa do SmallRye - Emissores e Canais</a></p>
</div>
</div>
<div class="sect2">
<h3 id="write-acknowledgement"><a class="anchor" href="#write-acknowledgement"></a>5.2. Escrever Reconhecimento</h3>
<div class="paragraph">
<p>Quando o broker do Kafka recebe um registro, seu reconhecimento pode demorar, dependendo da configuração. Além disso, ele armazena na memória os registros que não podem ser gravados.</p>
</div>
<div class="paragraph">
<p>Por padrão, o conector espera que o Kafka confirme o registro para continuar o processamento (reconhecendo a mensagem recebida). Você pode desativar isso definindo o atributo <code>waitForWriteCompletion</code> como <code>false</code>.</p>
</div>
<div class="paragraph">
<p>Note que o atributo <code>acks</code> tem um enorme impacto no reconhecimento do registro.</p>
</div>
<div class="paragraph">
<p>Se não for possível escrever um registro, a mensagem é não reconhecida.</p>
</div>
</div>
<div class="sect2">
<h3 id="backpressure"><a class="anchor" href="#backpressure"></a>5.3. Contrapressão</h3>
<div class="paragraph">
<p>O conector de saída do Kafka lida com a contrapressão, monitorando o número de mensagens em trânsito que aguardam gravação no broker do Kafka. O número de mensagens em trânsito é configurado usando o atributo <code>max-inflight-messages</code> e o padrão é 1024.</p>
</div>
<div class="paragraph">
<p>O conector envia apenas essa quantidade de mensagens ao mesmo tempo. Nenhuma outra mensagem será enviada até que pelo menos uma mensagem em andamento seja confirmada pelo broker. Em seguida, o conector grava uma nova mensagem no Kafka quando uma das mensagens em andamento do broker é reconhecida. Certifique-se de configurar o <code>batch.size</code> e o <code>linger.ms</code> do Kafka adequadamente.</p>
</div>
<div class="paragraph">
<p>Você também pode remover o limite de mensagens em andamento definindo <code>max-inflight-messages</code> como <code>0</code>. No entanto, observe que o produtor do Kafka poderá bloquear se o número de solicitações atingir <code>max.in.flight.requests.per.connection</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="retrying-message-dispatch"><a class="anchor" href="#retrying-message-dispatch"></a>5.4. Nova tentativa de envio de mensagens</h3>
<div class="paragraph">
<p>Quando o produtor Kafka recebe um erro do servidor, se for um erro transitório e recuperável, o cliente tentará enviar novamente o lote de mensagens. Esse comportamento é controlado pelos parâmetros <code>retries</code> e <code>retry.backoff.ms</code>. Além disso, a Mensageria Reativa do SmallRye tentará enviar novamente mensagens individuais em erros recuperáveis, dependendo dos parâmetros <code>retries</code> e <code>delivery.timeout.ms</code>.</p>
</div>
<div class="paragraph">
<p>Observe que, embora ter novas tentativas em um sistema confiável seja uma prática recomendada, o parâmetro <code>max.in.flight.requests.per.connection</code> tem como padrão <code>5</code>, o que significa que a ordem das mensagens não é garantida. Se a ordem das mensagens for imprescindível para o seu caso de uso, definir <code>max.in.flight.requests.per.connection</code> como <code>1</code> garantirá que um único lote de mensagens seja enviado por vez, às custas de limitar a taxa de transferência do produtor.</p>
</div>
<div class="paragraph">
<p>Para aplicar um mecanismo de retentativa em erros de processamento, consulte a seção sobre <a href="#retrying-processing">Repetindo o processamento</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="handling-serialization-failures"><a class="anchor" href="#handling-serialization-failures"></a>5.5. Tratando Falhas de Serialização</h3>
<div class="paragraph">
<p>Para o cliente produtor do Kafka, as falhas de serialização não são recuperáveis e, portanto, o envio da mensagem não é repetido. Nesses casos, talvez seja necessário aplicar uma estratégia de falha para o serializador. Para isso, você precisa criar um bean que implemente a interface <code>SerializationFailureHandler&lt;T&gt;</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
@Identifier("failure-fallback") // Set the name of the failure handler
public class MySerializationFailureHandler
    implements SerializationFailureHandler&lt;JsonObject&gt; { // Specify the expected type

    @Override
    public byte[] decorateSerialization(Uni&lt;byte[]&gt; serialization, String topic, boolean isKey,
        String serializer, Object data, Headers headers) {
        return serialization
                    .onFailure().retry().atMost(3)
                    .await().indefinitely();
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para utilizar este manipulador de falhas, o bean deve ser exposto com o qualificador <code>@Identifier</code> e a configuração do conector deve especificar o atributo <code>mp.messaging.outgoing.$channel.[key|value]-serialization-failure-handler</code> (para serializadores de chave ou de valor).</p>
</div>
<div class="paragraph">
<p>O manipulador é chamado com detalhes da serialização, incluindo a ação representada como <code>Uni&lt;byte[]&gt;</code>. Observe que o método deve aguardar o resultado e retornar o vetor de bytes serializado.</p>
</div>
</div>
<div class="sect2">
<h3 id="in-memory-channels"><a class="anchor" href="#in-memory-channels"></a>5.6. Canais na memória</h3>
<div class="paragraph">
<p>Em alguns casos de uso, é conveniente usar os padrões de mensagens para transferir mensagens dentro da mesma aplicação. Quando você não conecta um canal a um backend de mensagens como o Kafka, tudo acontece na memória, e os fluxos são criados encadeando métodos. Cada cadeia ainda é um fluxo reativo e aplica o protocolo de contrapressão.</p>
</div>
<div class="paragraph">
<p>A estrutura verifica se a cadeia produtor/consumidor está completa, o que significa que, se a aplicação gravar mensagens em um canal na memória (usando um método com apenas <code>@Outgoing</code>, ou um <code>Emitter</code>), ele também deverá consumir as mensagens de dentro da aplicação (usando um método com apenas <code>@Incoming</code> ou usando um fluxo não gerenciado).</p>
</div>
</div>
<div class="sect2">
<h3 id="broadcasting-messages-on-multiple-consumers"><a class="anchor" href="#broadcasting-messages-on-multiple-consumers"></a>5.7. Difusão de mensagens em vários consumidores</h3>
<div class="paragraph">
<p>Por padrão, um canal pode ser vinculado a um único consumidor, usando o método <code>@Incoming</code> ou o fluxo reativo <code>@Channel</code>. Na inicialização da aplicação, os canais são verificados para formar uma cadeia de consumidores e produtores com um único consumidor e produtor. Você pode substituir esse comportamento definindo <code>mp.messaging.$channel.broadcast=true</code> em um canal.</p>
</div>
<div class="paragraph">
<p>No caso dos canais na memória, a anotação <code>@Broadcast</code> pode ser utilizada no método <code>@Outgoing</code>. Por exemplo,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.Random;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.smallrye.reactive.messaging.annotations.Broadcast;

@ApplicationScoped
public class MultipleConsumer {

    private final Random random = new Random();

    @Outgoing("in-memory-channel")
    @Broadcast
    double generate() {
        return random.nextDouble();
    }

    @Incoming("in-memory-channel")
    void consumeAndLog(double price) {
        System.out.println(price);
    }

    @Incoming("in-memory-channel")
    @Outgoing("prices2")
    double consumeAndSend(double price) {
        return price;
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Reciprocamente, vários produtores no mesmo canal podem ser mesclados com a configuração <code>mp.messaging.incoming.$channel.merge=true</code>. Nos métodos <code>@Incoming</code>, você pode controlar como vários canais são mesclados usando a anotação <code>@Merge</code>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="kafka-transactions"><a class="anchor" href="#kafka-transactions"></a>5.8. Transações Kafka</h3>
<div class="paragraph">
<p>As transações do Kafka permitem gravações atômicas em vários tópicos e partições do Kafka. O conector Kafka fornece o emissor personalizado <code>KafkaTransactions</code> para gravar registros do Kafka dentro de uma transação. Ele pode ser injetado como um emissor regular <code>@Channel</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Channel;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@ApplicationScoped
public class KafkaTransactionalProducer {

    @Channel("tx-out-example")
    KafkaTransactions&lt;String&gt; txProducer;

    public Uni&lt;Void&gt; emitInTransaction() {
        return txProducer.withTransaction(emitter -&gt; {
            emitter.send(KafkaRecord.of(1, "a"));
            emitter.send(KafkaRecord.of(2, "b"));
            emitter.send(KafkaRecord.of(3, "c"));
            return Uni.createFrom().voidItem();
        });
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>A função dada ao método <code>withTransaction</code> recebe um <code>TransactionalEmitter</code> para produzir registros e devolve um <code>Uni</code> que fornece o resultado da transação.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Se o processamento for concluído com êxito, o produtor é descarregado e a transação é confirmada.</p>
</li>
<li>
<p>Se o processamento lançar uma exceção, retornar uma <code>Uni</code> de falha, ou marcar o <code>TransactionalEmitter</code> para abortar, a transação é abortada.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Os produtores transacionais do Kafka exigem a configuração da propriedade do cliente <code>acks=all</code> e um ID exclusivo para <code>transactional.id</code>, o que implica <code>enable.idempotence=true</code>. Quando o Quarkus detecta o uso de <code>KafkaTransactions</code> para um canal de saída, ele configura essas propriedades no canal, fornecendo um valor padrão de <code>"${quarkus.application.name}-${channelName}"</code> para a propriedade <code>transactional.id</code>.</p>
</div>
<div class="paragraph">
<p>Note que, para utilização em produção, o <code>transactional.id</code> deve ser único em todas as instâncias da aplicação.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Enquanto um emissor de mensagens normal suportaria chamadas simultâneas para os métodos <code>send</code> e, consequentemente, colocaria em fila as mensagens de saída a serem gravadas no Kafka, um emissor <code>KafkaTransactions</code> suporta apenas uma transação por vez. Uma transação é considerada em andamento desde a chamada para o <code>withTransaction</code> até o retorno do <code>Uni</code> resultar em sucesso ou falha. Enquanto uma transação estiver em andamento, as chamadas subsequentes para <code>withTransaction</code>, inclusive as aninhadas dentro da função fornecida, lançarão <code>IllegalStateException</code>.</p>
</div>
<div class="paragraph">
<p>Note that in Reactive Messaging, the execution of processing methods, is already serialized, unless <code>@Blocking(ordered = false)</code> is used.
If <code>withTransaction</code> can be called concurrently, for example from a REST endpoint, it is recommended to limit the concurrency of the execution.
This can be done using the <code>@Bulkhead</code> annotation from <a href="https://quarkus.io/guides/smallrye-fault-tolerance"><em>Microprofile Fault Tolerance</em></a>.</p>
</div>
<div class="paragraph">
<p>Um exemplo de uso pode ser encontrado em <a href="#chaining-kafka-transactions-with-hibernate-reactive-transactions">Encadeando Transações do Kafka com transações Reativas do Hibernate</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="transaction-aware-consumers"><a class="anchor" href="#transaction-aware-consumers"></a>5.8.1. Consumidores conscientes das transações</h4>
<div class="paragraph">
<p>Se você pretende consumir apenas registros escritos e confirmados no âmbito de uma transação Kafka, terá de configurar a propriedade <code>isolation.level</code> no canal de entrada como:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices-in.isolation.level=read_committed</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="processing-messages"><a class="anchor" href="#processing-messages"></a>6. Processando Mensagens</h2>
<div class="sectionbody">
<div class="paragraph">
<p>As aplicações que transmitem dados geralmente precisam consumir alguns eventos de um tópico, processá-los e publicar o resultado em um tópico diferente. Um método processador pode ser implementado de forma simples usando as anotações <code>@Incoming</code> e <code>@Outgoing</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;

@ApplicationScoped
public class PriceProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("price-in")
    @Outgoing("price-out")
    public double process(double price) {
        return price * CONVERSION_RATE;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>O parâmetro do método <code>process</code> é o conteúdo da mensagem de entrada, enquanto o valor de retorno será usado como conteúdo da mensagem de saída. As assinaturas mencionadas anteriormente para os tipos de parâmetro e retorno também são compatíveis, como <code>Message&lt;T&gt;</code>, <code>Record&lt;K, V&gt;</code>, etc.</p>
</div>
<div class="paragraph">
<p>É possível aplicar o processamento assíncrono de fluxos consumindo e devolvendo o tipo de fluxo reativo <code>Multi&lt;T&gt;</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.smallrye.mutiny.Multi;

@ApplicationScoped
public class PriceProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("price-in")
    @Outgoing("price-out")
    public Multi&lt;Double&gt; process(Multi&lt;Integer&gt; prices) {
        return prices.filter(p -&gt; p &gt; 100).map(p -&gt; p * CONVERSION_RATE);
    }

}</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="propagating-record-key"><a class="anchor" href="#propagating-record-key"></a>6.1. Propagando a Chave de Registro</h3>
<div class="paragraph">
<p>Ao processar mensagens, é possível propagar a chave do registro de entrada para o registro de saída.</p>
</div>
<div class="paragraph">
<p>Ativada com a configuração <code>mp.messaging.outgoing.$channel.propagate-record-key=true</code>, a propagação da chave de registro produz o registro de saída com a mesma <em>chave</em> do registro de entrada.</p>
</div>
<div class="paragraph">
<p>Se o registro de saída já contiver uma <em>chave</em>, ela <strong>não será substituída</strong> pela chave do registro de entrada. Se o registro de entrada tiver uma chave <em>nula</em>, será usada a propriedade <code>mp.messaging.outgoing.$channel.key</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="exactly-once-processing"><a class="anchor" href="#exactly-once-processing"></a>6.2. Processamento Exactly-Once (Exatamente Único)</h3>
<div class="paragraph">
<p>O Kafka Transactions permite gerenciar os deslocamentos do consumidor dentro de uma transação, juntamente com as mensagens produzidas. Isso permite acoplar um consumidor a um produtor transacional em um padrão <em>consume-transforma-produz</em>, também conhecido como <strong>processamento exatamente único</strong>.</p>
</div>
<div class="paragraph">
<p>O emissor personalizado <code>KafkaTransactions</code> fornece uma forma de aplicar um processamento exatamente único a uma mensagem Kafka de entrada dentro de uma transação.</p>
</div>
<div class="paragraph">
<p>O exemplo seguinte inclui um lote de registros Kafka dentro de uma transação.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.OnOverflow;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import io.smallrye.reactive.messaging.kafka.KafkaRecordBatch;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@ApplicationScoped
public class KafkaExactlyOnceProcessor {

    @Channel("prices-out")
    @OnOverflow(value = OnOverflow.Strategy.BUFFER, bufferSize = 500) <i class="conum" data-value="3"></i><b>(3)</b>
    KafkaTransactions&lt;Integer&gt; txProducer;

    @Incoming("prices-in")
    public Uni&lt;Void&gt; emitInTransaction(KafkaRecordBatch&lt;String, Integer&gt; batch) { <i class="conum" data-value="1"></i><b>(1)</b>
        return txProducer.withTransactionAndAck(batch, emitter -&gt; { <i class="conum" data-value="2"></i><b>(2)</b>
            for (KafkaRecord&lt;String, Integer&gt; record : batch) {
                emitter.send(KafkaRecord.of(record.getKey(), record.getPayload() + 1)); <i class="conum" data-value="3"></i><b>(3)</b>
            }
            return Uni.createFrom().voidItem();
        });
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Recomenda-se usar o processamento exatamente único junto com o modo de consumo em lote. Embora seja possível usá-lo com uma única mensagem do Kafka, isso terá um impacto significativo no desempenho.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>A mensagem consumida em <code>KafkaRecordBatch</code> é transmitida a <code>KafkaTransactions#withTransactionAndAck</code> para tratar os confirmações de deslocamento e os reconhecimentos de mensagens.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>O método <code>send</code> grava registros no Kafka dentro da transação, sem aguardar o recebimento do envio pelo broker. As mensagens pendentes de gravação no Kafka serão armazenadas em buffer e liberadas antes de confirmar a transação. Portanto, é recomendável configurar o <code>@OnOverflow</code> <code>bufferSize</code> para que caibam mensagens suficientes, por exemplo, o <code>max.poll.records</code>, quantidade máxima de registros retornados em um lote.
<div class="ulist">
<ul>
<li>
<p>Se o processamento for concluído com êxito, <em>antes de confirmar a transação</em>, os deslocamentos da partição de tópicos da mensagem de lote indicada serão confirmados na transação.</p>
</li>
<li>
<p>Se o processamento precisar de ser abortado, <em>depois de abortar a transação</em>, a posição do consumidor é redefinida para o último deslocamento confirmado, retomando efetivamente o consumo a partir desse deslocamento. Se nenhum deslocamento do consumidor tiver sido comprometido com uma partição de tópico, a posição do consumidor é redefinida para o início da partição de tópico, <em>mesmo que a política de redefinição de deslocamento seja `latest`</em>.</p>
</li>
</ul>
</div></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Ao usar o processamento exatamente único, as confirmações de deslocamento de mensagens consumidas são tratadas pela transação e, portanto, a aplicação não deve confirmar os deslocamentos por outros meios. O consumidor deve ter <code>enable.auto.commit=false</code> (o padrão) e definir explicitamente <code>commit-strategy=ignore</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices-in.commit-strategy=ignore
mp.messaging.incoming.prices-in.failure-strategy=ignore</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="error-handling-for-the-exactly-once-processing"><a class="anchor" href="#error-handling-for-the-exactly-once-processing"></a>6.2.1. Tratamento de erros para o processamento exatamente único</h4>
<div class="paragraph">
<p>O <code>Uni</code> retornado do <code>KafkaTransactions#withTransaction</code> produzirá uma falha se a transação falhar e for abortada. A aplicação pode optar por tratar o caso de erro, mas se um <code>Uni</code> com falha for retornado do método <code>@Incoming</code>, o canal de entrada falhará efetivamente e interromperá o fluxo reativo.</p>
</div>
<div class="paragraph">
<p>O método <code>KafkaTransactions#withTransactionAndAck</code> reconhece e não reconhece a mensagem, mas <strong>não</strong> retornará um <code>Uni</code> com falha. As mensagens não reconhecidas serão tratadas pela estratégia de falha do canal de entrada (veja <a href="#error-handling">Estratégias de Tratamento de Erros</a>). Configurar <code>failure-strategy=ignore</code> simplesmente redefine o consumidor Kafka para os últimos deslocamentos confirmados e retoma o consumo a partir daí.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-bare-clients"><a class="anchor" href="#kafka-bare-clients"></a>7. Acessando clientes Kafka diretamente</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Em casos raros, você pode precisar acessar os clientes Kafka subjacentes. <code>KafkaClientService</code> fornece acesso thread-safe a <code>Producer</code> e <code>Consumer</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.event.Observes;
import javax.inject.Inject;

import org.apache.kafka.clients.producer.ProducerRecord;

import io.quarkus.runtime.StartupEvent;
import io.smallrye.reactive.messaging.kafka.KafkaClientService;
import io.smallrye.reactive.messaging.kafka.KafkaConsumer;
import io.smallrye.reactive.messaging.kafka.KafkaProducer;

@ApplicationScoped
public class PriceSender {

    @Inject
    KafkaClientService clientService;

    void onStartup(@Observes StartupEvent startupEvent) {
        KafkaProducer&lt;String, Double&gt; producer = clientService.getProducer("generated-price");
        producer.runOnSendingThread(client -&gt; client.send(new ProducerRecord&lt;&gt;("prices", 2.4)))
            .await().indefinitely();
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A <code>KafkaClientService</code> é uma API experimental e pode sofrer alterações no futuro.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Você também pode obter a configuração do Kafka injetada na sua aplicação e criar diretamente clientes produtores, consumidores e administradores do Kafka:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.common.annotation.Identifier;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.AdminClientConfig;
import org.apache.kafka.clients.admin.KafkaAdminClient;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.inject.Produces;
import javax.inject.Inject;
import java.util.HashMap;
import java.util.Map;

@ApplicationScoped
public class KafkaClients {

    @Inject
    @Identifier("default-kafka-broker")
    Map&lt;String, Object&gt; config;

    @Produces
    AdminClient getAdmin() {
        Map&lt;String, Object&gt; copy = new HashMap&lt;&gt;();
        for (Map.Entry&lt;String, Object&gt; entry : config.entrySet()) {
            if (AdminClientConfig.configNames().contains(entry.getKey())) {
                copy.put(entry.getKey(), entry.getValue());
            }
        }
        return KafkaAdminClient.create(copy);
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>O mapa de configuração <code>default-kafka-broker</code> contém todas as propriedades da aplicação prefixadas com <code>kafka.</code> ou <code>KAFKA_</code>. Para mais opções de configuração, consulte <a href="#kafka-configuration-resolution">Resolução de Configuração do Kafka</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-serialization"><a class="anchor" href="#kafka-serialization"></a>8. Serialização JSON</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O Quarkus tem capacidades incorporadas para lidar com mensagens JSON Kafka.</p>
</div>
<div class="paragraph">
<p>Imagine que temos uma classe de dados <code>Fruit</code> da seguinte forma:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class Fruit {

    public String name;
    public int price;

    public Fruit() {
    }

    public Fruit(String name, int price) {
        this.name = name;
        this.price = price;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>E queremos utilizá-la para receber mensagens do Kafka, fazer alguma transformação de preços e enviar mensagens de volta para o Kafka.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.reactive.messaging.annotations.Broadcast;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;

/**
* A bean consuming data from the "fruit-in" channel and applying some price conversion.
* The result is pushed to the "fruit-out" channel.
*/
@ApplicationScoped
public class FruitProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("fruit-in")
    @Outgoing("fruit-out")
    @Broadcast
    public Fruit process(Fruit fruit) {
        fruit.price = fruit.price * CONVERSION_RATE;
        return fruit;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para isso, precisamos configurar a serialização JSON com Jackson ou JSON-B.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Com a serialização JSON corretamente configurada, também é possível utilizar <code>Publisher&lt;Fruit&gt;</code> e <code>Emitter&lt;Fruit&gt;</code>.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="jackson-serialization"><a class="anchor" href="#jackson-serialization"></a>8.1. Serialização via Jackson</h3>
<div class="paragraph">
<p>Quarkus has built-in support for JSON serialization and deserialization based on Jackson.
It will also <a href="#serialization-generation">generate</a> the serializer and deserializer for you, so you do not have to configure anything.
When generation is disabled, you can use the provided <code>ObjectMapperSerializer</code> and <code>ObjectMapperDeserializer</code> as explained below.</p>
</div>
<div class="paragraph">
<p>Existe um <code>ObjectMapperSerializer</code> que pode ser usado para serializar todos os objetos de dados via Jackson. Você pode criar uma subclasse vazia se quiser usar <a href="#serialization-autodetection">Detecção automática de serializador/desserializador</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Por padrão, o <code>ObjectMapperSerializer</code> serializa null como a String <code>"null"</code>. Isso pode ser personalizado com a definição da propriedade de configuração do Kafka <code>json.serialize.null-as-null=true</code>, que serializará null como <code>null</code>. Isso é útil quando se usa um tópico compactado, pois <code>null</code> é usado como uma tombstone para saber quais mensagens são excluídas durante a fase de compactação.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A classe correspondente do desserializador precisa ser uma subclasse. Portanto, vamos criar um <code>FruitDeserializer</code> que estende o <code>ObjectMapperDeserializer</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jackson;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Por fim, configure os seus canais para utilizarem o serializador e desserializador Jackson.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Configure the Kafka source (we read from it)
mp.messaging.incoming.fruit-in.topic=fruit-in
mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer

# Configure the Kafka sink (we write to it)
mp.messaging.outgoing.fruit-out.topic=fruit-out
mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Agora, suas mensagens Kafka conterão uma representação serializada pelo Jackson do seu objeto de dados <code>Fruit</code>. Nesse caso, a configuração do <code>deserializer</code> não é necessária, pois a <a href="#serialization-autodetection">Detecção automática de serializador/desserializador</a> está habilitada por padrão.</p>
</div>
<div class="paragraph">
<p>Se você pretende desserializar uma lista de fruits, tem de criar um desserializador com um Jackson <code>TypeReference</code> denotando a coleção genérica utilizada.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jackson;

import java.util.List;
import com.fasterxml.jackson.core.type.TypeReference;
import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class ListOfFruitDeserializer extends ObjectMapperDeserializer&lt;List&lt;Fruit&gt;&gt; {
    public ListOfFruitDeserializer() {
        super(new TypeReference&lt;List&lt;Fruit&gt;&gt;() {});
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="jsonb-serialization"><a class="anchor" href="#jsonb-serialization"></a>8.2. Serialização via JSON-B</h3>
<div class="paragraph">
<p>Em primeiro lugar, é necessário incluir a extensão <code>quarkus-jsonb</code>.</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-jsonb&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.quarkus:quarkus-jsonb")</code></pre>
</div>
</div>
<div class="paragraph">
<p>Existe um <code>JsonbSerializer</code> que pode ser usado para serializar todos os objetos de dados via JSON-B. Você pode criar uma subclasse vazia se quiser usar <a href="#serialization-autodetection">Detecção automática de serializador/desserializador</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Por padrão, o <code>JsonbSerializer</code> serializa null como a String <code>"null"</code>. Isso pode ser personalizado com a definição da propriedade de configuração do Kafka <code>json.serialize.null-as-null=true</code>, que serializará null como <code>null</code>. Isso é útil quando se usa um tópico compactado, pois <code>null</code> é usado como uma tombstone para saber quais mensagens são excluídas durante a fase de compactação.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A classe correspondente do desserializador precisa ser uma subclasse. Portanto, vamos criar um <code>FruitDeserializer</code> que estende o genérico <code>JsonbDeserializer</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jsonb;

import io.quarkus.kafka.client.serialization.JsonbDeserializer;

public class FruitDeserializer extends JsonbDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Por fim, configure os seus canais para utilizarem o serializador e desserializador JSON-B.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Configure the Kafka source (we read from it)
mp.messaging.incoming.fruit-in.connector=smallrye-kafka
mp.messaging.incoming.fruit-in.topic=fruit-in
mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer

# Configure the Kafka sink (we write to it)
mp.messaging.outgoing.fruit-out.connector=smallrye-kafka
mp.messaging.outgoing.fruit-out.topic=fruit-out
mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Agora, as suas mensagens Kafka conterão uma representação serializada JSON-B do seu objeto de dados <code>Fruit</code>.</p>
</div>
<div class="paragraph">
<p>Para desserializar uma lista de fruits, é necessário criar um desserializador com um <code>Tipo</code> denotando a coleção genérica utilizada.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jsonb;
import java.lang.reflect.Type;
import java.util.ArrayList;
import java.util.List;
import io.quarkus.kafka.client.serialization.JsonbDeserializer;

public class ListOfFruitDeserializer extends JsonbDeserializer&lt;List&lt;Fruit&gt;&gt; {
    public ListOfFruitDeserializer() {
        super(new ArrayList&lt;MyEntity&gt;() {}.getClass().getGenericSuperclass());
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Se não quiser criar um desserializador para cada objeto de dados, você pode usar o genérico <code>io.vertx.kafka.client.serialization.JsonObjectDeserializer</code> que desserializará para um <code>io.vertx.core.json.JsonObject</code>. O serializador correspondente também pode ser usado: <code>io.vertx.kafka.client.serialization.JsonObjectSerializer</code>.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="avro-serialization"><a class="anchor" href="#avro-serialization"></a>9. Serialização Avro</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Isso é descrito em um guia dedicado: <a href="kafka-schema-registry-avro">Usando Apache Kafka com Registro de Esquema e o Avro</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="serialization-autodetection"><a class="anchor" href="#serialization-autodetection"></a>10. Detecção automática de serializador/desserializador</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ao usar a Mensageria Reativa do SmallRye com Kafka (<code>io.quarkus:quarkus-smallrye-reactive-messaging-kafka</code>), o Quarkus pode detectar automaticamente a classe correta de serializador e desserializador. Essa detecção automática baseia-se nas declarações dos métodos <code>@Incoming</code> e <code>@Outgoing</code>, bem como nos métodos <code>@Channel</code> injetados.</p>
</div>
<div class="paragraph">
<p>Por exemplo, se você declarar</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("generated-price")
public Multi&lt;Integer&gt; generate() {
    ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>e a sua configuração indicar que o canal <code>generated-price</code> utiliza o conector <code>smallrye-kafka</code>, o Quarkus definirá automaticamente o <code>value.serializer</code> para o <code>IntegerSerializer</code> incorporado no Kafka.</p>
</div>
<div class="paragraph">
<p>Da mesma forma, se você declarar</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("my-kafka-records")
public void consume(KafkaRecord&lt;Long, byte[]&gt; record) {
    ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>e a sua configuração indicar que o canal <code>my-kafka-records</code> utiliza o conector <code>smallrye-kafka</code>, então o Quarkus definirá automaticamente o <code>key.deserializer</code> para o <code>LongDeserializer</code> incorporado no Kafka, bem como o <code>value.deserializer</code> para <code>ByteArrayDeserializer</code>.</p>
</div>
<div class="paragraph">
<p>Finalmente, se você declarar</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Inject
@Channel("price-create")
Emitter&lt;Double&gt; priceEmitter;</code></pre>
</div>
</div>
<div class="paragraph">
<p>e a sua configuração indicar que o canal <code>price-create</code> utiliza o conector <code>smallrye-kafka</code>, o Quarkus definirá automaticamente o <code>value.serializer</code> para o <code>DoubleSerializer</code> incorporado no Kafka.</p>
</div>
<div class="paragraph">
<p>O conjunto completo de tipos suportados pela autodetecção do serializador/desserializador é:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>short</code> e <code>java.lang.Short</code></p>
</li>
<li>
<p><code>int</code> e <code>java.lang.Integer</code></p>
</li>
<li>
<p><code>long</code> e <code>java.lang.Long</code></p>
</li>
<li>
<p><code>float</code> e <code>java.lang.Float</code></p>
</li>
<li>
<p><code>double</code> e <code>java.lang.Double</code></p>
</li>
<li>
<p><code>byte[]</code></p>
</li>
<li>
<p><code>java.lang.String</code></p>
</li>
<li>
<p><code>java.util.UUID</code></p>
</li>
<li>
<p><code>java.nio.ByteBuffer</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.utils.Bytes</code></p>
</li>
<li>
<p><code>io.vertx.core.buffer.Buffer</code></p>
</li>
<li>
<p><code>io.vertx.core.json.JsonObject</code></p>
</li>
<li>
<p><code>io.vertx.core.json.JsonArray</code></p>
</li>
<li>
<p>classes para as quais existe uma implementação direta de <code>org.apache.kafka.common.serialization.Serializer&lt;T&gt;</code> / <code>org.apache.kafka.common.serialization.Deserializer&lt;T&gt;</code>.</p>
<div class="ulist">
<ul>
<li>
<p>a implementação tem de especificar o argumento do tipo <code>T</code> como o tipo (des)serializado.</p>
</li>
</ul>
</div>
</li>
<li>
<p>classes geradas a partir de esquemas Avro, bem como Avro <code>GenericRecord</code>, se o Confluent ou o Apicurio Registry <em>serde</em> estiver presente</p>
<div class="ulist">
<ul>
<li>
<p>no caso de existirem vários serdes Avro, o serializador/desserializador deve ser configurado manualmente para as classes geradas pelo Avro, uma vez que a detecção automática é impossível</p>
</li>
<li>
<p>consulte <a href="kafka-schema-registry-avro">Usando Apache Kafka com Registro de Esquema e Avro</a> para obter mais informações sobre a utilização das bibliotecas Confluent ou Apicurio Registry</p>
</li>
</ul>
</div>
</li>
<li>
<p>classes para as quais uma subclasse de <code>ObjectMapperSerializer</code> / <code>ObjectMapperDeserializer</code> está presente, conforme descrito em <a href="#jackson-serialization">Serialização via Jackson</a></p>
<div class="ulist">
<ul>
<li>
<p>tecnicamente não é necessário criar subclasse de <code>ObjectMapperSerializer</code>, mas, nesse caso, a detecção automática não é possível</p>
</li>
</ul>
</div>
</li>
<li>
<p>classes para as quais uma subclasse de <code>JsonbSerializer</code> / <code>JsonbDeserializer</code> está presente, conforme descrito em <a href="#jsonb-serialization">Serialização via JSON-B</a></p>
<div class="ulist">
<ul>
<li>
<p>tecnicamente não é necessário criar subclasse de <code>JsonbSerializer</code>, mas, nesse caso, a detecção automática não é possível</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Se um serializador/desserializador for definido pela configuração, não será substituído pela detecção automática.</p>
</div>
<div class="paragraph">
<p>Caso tenha algum problema com a autodetecção do serializador, você pode desativá-la completamente definindo <code>quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false</code>. Se achar que precisa fazer isso, registre um bug no <a href="https://github.com/quarkusio/quarkus/issues">rastreador de issues do Quarkus</a> para que possamos corrigir o problema que você tiver.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="serialization-generation"><a class="anchor" href="#serialization-generation"></a>11. Geração de serializador/desserializador JSON</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O Quarkus gera automaticamente serializadores e desserializadores para canais onde:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>o serializador/desserializador não está configurado</p>
</li>
<li>
<p>a detecção automática não encontrou um serializador/desserializador correspondente</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Utiliza Jackson por baixo.</p>
</div>
<div class="paragraph">
<p>Esta geração pode ser desativada utilizando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.reactive-messaging.kafka.serializer-generation.enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
A geração não suporta coleções como <code>List&lt;Fruit&gt;</code>. Consulte <a href="#jackson-serialization">Serialização via Jackson</a> para escrever seu próprio serializador/desserializador para este caso.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-schema-registry"><a class="anchor" href="#using-schema-registry"></a>12. Usando Registro de Esquemas</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Isso é descrito em um guia dedicado: <a href="kafka-schema-registry-avro">Usando Apache Kafka com Registro de Esquema e o Avro</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-health-check"><a class="anchor" href="#kafka-health-check"></a>13. Verificações de Integridade</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O Quarkus fornece várias verificações de integridade para o Kafka. Essas verificações são usadas em conjunto com a extensão <code>quarkus-smallrye-health</code>.</p>
</div>
<div class="sect2">
<h3 id="kafka-broker-readiness-check"><a class="anchor" href="#kafka-broker-readiness-check"></a>13.1. Verificação de Prontidão do Broker Kafka</h3>
<div class="paragraph">
<p>Ao usar a extensão <code>quarkus-kafka-client</code>, você pode ativar a verificação de integridade da <em>prontidão</em> definindo a propriedade <code>quarkus.kafka.health.enabled</code> como <code>true</code> no seu <code>application.properties</code>. Essa verificação informa o status da interação com um broker Kafka <em>padrão</em> (configurado usando <code>kafka.bootstrap.servers</code>). Ela requer uma <em>conexão de administrador</em> com o broker Kafka e está desativada por padrão. Se estiver ativada, quando o usuário acessar o endpoint <code>/q/health/ready</code> da sua aplicação, terá informações sobre o status de validação da conexão.</p>
</div>
</div>
<div class="sect2">
<h3 id="kafka-reactive-messaging-health-checks"><a class="anchor" href="#kafka-reactive-messaging-health-checks"></a>13.2. Verificações de Integridade da Mensageria Reativa do Kafka</h3>
<div class="paragraph">
<p>Quando usar Mensageria Reativa e o conector Kafka, cada canal configurado (de entrada ou de saída) fornece verificações de <em>inicialização</em>, <em>vivacidade</em> e <em>prontidão</em>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A verificação de <em>inicialização</em> verifica se a comunicação com o cluster Kafka está estabelecida.</p>
</li>
<li>
<p>A verificação de <em>vivacidade</em> capta qualquer falha irrecuperável que ocorra durante a comunicação com o Kafka.</p>
</li>
<li>
<p>A verificação de <em>prontidão</em> verifica se o conector Kafka está pronto para consumir/produzir mensagens para os tópicos Kafka configurados.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Para cada canal, é possível desativar as verificações utilizando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Disable both liveness and readiness checks with `health-enabled=false`:

# Incoming channel (receiving records form Kafka)
mp.messaging.incoming.your-channel.health-enabled=false
# Outgoing channel (writing records to Kafka)
mp.messaging.outgoing.your-channel.health-enabled=false

# Disable only the readiness check with `health-readiness-enabled=false`:

mp.messaging.incoming.your-channel.health-readiness-enabled=false
mp.messaging.outgoing.your-channel.health-readiness-enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Você pode configurar o <code>bootstrap.servers</code> para cada canal usando a propriedade <code>mp.messaging.incoming|outgoing.$channel.bootstrap.servers</code>. O padrão é <code>kafka.bootstrap.servers</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>As verificações de <em>inicialização</em> e <em>prontidão</em> da Mensageria Reativa oferecem duas estratégias. A estratégia padrão verifica se uma conexão ativa foi estabelecida com o broker. Essa abordagem não é intrusiva, pois se baseia em métricas incorporadas do cliente Kafka.</p>
</div>
<div class="paragraph">
<p>Usando o atributo <code>health-topic-verification-enabled=true</code>, a sonda de <em>inicialização</em> usa um <em>cliente administrador</em> para verificar a lista de tópicos. Já a sonda de <em>prontidão</em> para um canal de entrada verifica se pelo menos uma partição está atribuída para consumo e, para um canal de saída, verifica se o tópico usado pelo produtor existe no broker.</p>
</div>
<div class="paragraph">
<p>Observe que, para isso, é necessária uma <em>conexão de administrador</em>. Você pode ajustar o tempo limite das chamadas de verificação de tópico para o broker usando a configuração <code>health-topic-verification-timeout</code>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-streams"><a class="anchor" href="#kafka-streams"></a>14. Fluxos Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Isso é descrito em um guia dedicado: <a href="kafka-streams">Usando Fluxos do Apache Kafka</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-snappy-for-message-compression"><a class="anchor" href="#using-snappy-for-message-compression"></a>15. Usando Snappy para compressão de mensagens</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nos canais de <em>saída</em>, você pode ativar a compressão Snappy definindo o atributo <code>compression.type</code> para <code>snappy</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.fruit-out.compression.type=snappy</code></pre>
</div>
</div>
<div class="paragraph">
<p>In JVM mode, it will work out of the box.
However, to compile your application to a native executable, you need to:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Uses GraalVM 21.+</p>
</li>
<li>
<p>Add <code>quarkus.kafka.snappy.enabled=true</code> to your <code>application.properties</code></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>No modo nativo, o Snappy está desativado por padrão, uma vez que a utilização do Snappy requer a incorporação de uma biblioteca nativa e a sua descompactação quando a aplicação é iniciada.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="authentication-with-oauth"><a class="anchor" href="#authentication-with-oauth"></a>16. Autenticação com OAuth</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Se o seu broker Kafka usar o OAuth como mecanismo de autenticação, você precisará configurar o consumidor Kafka para habilitar esse processo de autenticação. Primeiro, adicione a seguinte dependência à sua aplicação:</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.strimzi&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-oauth-client&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.strimzi:kafka-oauth-client")</code></pre>
</div>
</div>
<div class="paragraph">
<p>Essa dependência fornece o manipulador de retorno de chamada necessário para lidar com o fluxo de trabalho do OAuth. Em seguida, em <code>application.properties</code>, adicione:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT
mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER
mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
  oauth.client.id="team-a-client" \
  oauth.client.secret="team-a-client-secret" \
  oauth.token.endpoint.uri="http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token" ;
mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler

quarkus.ssl.native=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Atualize os valores <code>oauth.client.id</code>, <code>oauth.client.secret</code> e <code>oauth.token.endpoint.uri</code>.</p>
</div>
<div class="paragraph">
<p>A autenticação OAuth funciona nos modos JVM e nativo. Como o SSL não é habilitado por padrão no modo nativo, <code>quarkus.ssl.native=true</code> deve ser adicionado para dar suporte ao JaasClientOauthLoginCallbackHandler, que usa SSL. (Consulte o guia <a href="native-and-ssl">Usando SSL com Executáveis Nativos</a> para obter mais detalhes.)</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="testing-a-kafka-application"><a class="anchor" href="#testing-a-kafka-application"></a>17. Testando uma aplicação Kafka</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="testing-without-a-broker"><a class="anchor" href="#testing-without-a-broker"></a>17.1. Testando sem um broker</h3>
<div class="paragraph">
<p>Pode ser útil testar a aplicação sem ter que iniciar um broker Kafka. Para isso, você pode <em>trocar</em> os canais gerenciados pelo conector Kafka para a <em>em memória</em>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Esta abordagem só funciona para testes JVM. Não pode ser utilizada para testes nativos (porque estes não suportam a injeção).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Digamos que queremos testar a seguinte aplicação de processador:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
public class BeverageProcessor {

    @Incoming("orders")
    @Outgoing("beverages")
    Beverage process(Order order) {
        System.out.println("Order received " + order.getProduct());
        Beverage beverage = new Beverage();
        beverage.setBeverage(order.getProduct());
        beverage.setCustomer(order.getCustomer());
        beverage.setOrderId(order.getOrderId());
        beverage.setPreparationState("RECEIVED");
        return beverage;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Em primeiro lugar, adicione a seguinte dependência de teste à sua aplicação:</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.smallrye.reactive&lt;/groupId&gt;
    &lt;artifactId&gt;smallrye-reactive-messaging-in-memory&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">testImplementation("io.smallrye.reactive:smallrye-reactive-messaging-in-memory")</code></pre>
</div>
</div>
<div class="paragraph">
<p>Em seguida, crie um recurso de teste Quarkus da seguinte forma:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {

    @Override
    public Map&lt;String, String&gt; start() {
        Map&lt;String, String&gt; env = new HashMap&lt;&gt;();
        Map&lt;String, String&gt; props1 = InMemoryConnector.switchIncomingChannelsToInMemory("orders");     <i class="conum" data-value="1"></i><b>(1)</b>
        Map&lt;String, String&gt; props2 = InMemoryConnector.switchOutgoingChannelsToInMemory("beverages");  <i class="conum" data-value="2"></i><b>(2)</b>
        env.putAll(props1);
        env.putAll(props2);
        return env;  <i class="conum" data-value="3"></i><b>(3)</b>
    }

    @Override
    public void stop() {
        InMemoryConnector.clear();  <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Mude o canal de entrada <code>orders</code> (esperando mensagens do Kafka) para em memória.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Mude o canal de saída <code>beverages</code> (escrever mensagens para o Kafka) para em memória.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Constrói e devolve um <code>Map</code> que contém todas as propriedades necessárias para configurar a aplicação para utilizar canais em memória.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Quando o teste parar, limpe o <code>InMemoryConnector</code> (elimine todas as mensagens recebidas e enviadas)</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Crie um teste Quarkus utilizando o recurso de teste criado acima:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@QuarkusTest
@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)
class BaristaTest {

    @Inject
    InMemoryConnector connector; <i class="conum" data-value="1"></i><b>(1)</b>

    @Test
    void testProcessOrder() {
        InMemorySource&lt;Order&gt; ordersIn = connector.source("orders");     <i class="conum" data-value="2"></i><b>(2)</b>
        InMemorySink&lt;Beverage&gt; beveragesOut = connector.sink("beverages");  <i class="conum" data-value="3"></i><b>(3)</b>

        Order order = new Order();
        order.setProduct("coffee");
        order.setName("Coffee lover");
        order.setOrderId("1234");

        ordersIn.send(order);  <i class="conum" data-value="4"></i><b>(4)</b>

        await().&lt;List&lt;? extends Message&lt;Beverage&gt;&gt;&gt;until(beveragesOut::received, t -&gt; t.size() == 1); <i class="conum" data-value="5"></i><b>(5)</b>

        Beverage queuedBeverage = beveragesOut.received().get(0).getPayload();
        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());
        Assertions.assertEquals("coffee", queuedBeverage.getBeverage());
        Assertions.assertEquals("Coffee lover", queuedBeverage.getCustomer());
        Assertions.assertEquals("1234", queuedBeverage.getOrderId());
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Injete o conector em memória na sua classe de teste.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Recupere o canal de entrada (<code>orders</code>) - o canal deve ter sido trocado para em memória no recurso de teste.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Recuperar o canal de saída (<code>beverages</code>) - o canal deve ter sido trocado para em memória no recurso de teste.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Use o método <code>send</code> para enviar uma mensagem ao canal <code>orders</code>. A aplicação processará essa mensagem e enviará uma mensagem ao canal <code>beverages</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Utilize o método <code>received</code> no canal <code>beverages</code> para verificar as mensagens produzidas pela aplicação.</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Com os canais em memória, pudemos testar o código da aplicação processando mensagens sem iniciar um broker Kafka. Note que os diferentes canais em memória são independentes, e a troca do conector do canal para em memória não simula a entrega de mensagens entre canais configurados para o mesmo tópico do Kafka.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="testing-using-a-kafka-broker"><a class="anchor" href="#testing-using-a-kafka-broker"></a>17.2. Testando usando um broker Kafka</h3>
<div class="paragraph">
<p>Se você estiver usando <a href="#kafka-dev-services">Dev Services para o Kafka</a>, um broker Kafka será iniciado e estará disponível durante os testes, a menos que seja desativado no perfil <code>%test</code>. Embora seja possível conectar-se a este broker usando a API do Kafka Clients, <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/test-companion/">A Biblioteca Companheira do Kafka</a> propõe uma forma mais fácil de interagir com um broker Kafka e criar ações de consumidor, produtor e administrador dentro dos testes.</p>
</div>
<div class="paragraph">
<p>Para utilizar a API <code>KafkaCompanion</code> nos testes, comece adicionando a seguinte dependência:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-test-kafka-companion&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>que fornece <code>io.quarkus.test.kafka.KafkaCompanionResource</code> - uma implementação de <code>io.quarkus.test.common.QuarkusTestResourceLifecycleManager</code>.</p>
</div>
<div class="paragraph">
<p>Em seguida, utilize <code>@QuarkusTestResource</code> para configurar o Kafka Companion em testes, por exemplo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import static org.junit.jupiter.api.Assertions.assertEquals;

import java.util.UUID;

import org.apache.kafka.clients.producer.ProducerRecord;
import org.junit.jupiter.api.Test;

import io.quarkus.test.common.QuarkusTestResource;
import io.quarkus.test.junit.QuarkusTest;
import io.quarkus.test.kafka.InjectKafkaCompanion;
import io.quarkus.test.kafka.KafkaCompanionResource;
import io.smallrye.reactive.messaging.kafka.companion.ConsumerTask;
import io.smallrye.reactive.messaging.kafka.companion.KafkaCompanion;

@QuarkusTest
@QuarkusTestResource(KafkaCompanionResource.class)
public class OrderProcessorTest {

    @InjectKafkaCompanion <i class="conum" data-value="1"></i><b>(1)</b>
    KafkaCompanion companion;

    @Test
    void testProcessor() {
        companion.produceStrings().usingGenerator(i -&gt; new ProducerRecord&lt;&gt;("orders", UUID.randomUUID().toString())); <i class="conum" data-value="2"></i><b>(2)</b>

        // Expect that the tested application processes orders from 'orders' topic and write to 'orders-processed' topic

        ConsumerTask&lt;String, String&gt; orders = companion.consumeStrings().fromTopics("orders-processed", 10); <i class="conum" data-value="3"></i><b>(3)</b>
        orders.awaitCompletion(); <i class="conum" data-value="4"></i><b>(4)</b>
        assertEquals(10, orders.count());
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><code>@InjectKafkaCompanion</code> injeta a instância <code>KafkaCompanion</code>, configurada para acessar o broker Kafka criado para os testes.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Utilize <code>KafkaCompanion</code> para criar uma tarefa de produção que escreva 10 registros no tópico 'orders'.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Crie uma tarefa de consumidor que subscreva o tópico 'orders-processed' e consuma 10 registros.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Aguarde a conclusão da tarefa do consumidor.</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Se o Dev Service Kafka estiver disponível durante os testes, <code>KafkaCompanionResource</code> utiliza o broker Kafka criado, caso contrário cria um broker Kafka utilizando <a href="https://github.com/strimzi/test-container">Strimzi Test Container</a>.</p>
</div>
<div class="paragraph">
<p>A configuração do broker Kafka criado pode ser personalizada usando <code>@ResourceArg</code>, por exemplo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@QuarkusTestResource(value = KafkaCompanionResource.class, initArgs = {
        @ResourceArg(name = "strimzi.kafka.image", value = "quay.io/strimzi/kafka:0.28.0-kafka-3.0.0"), // Image name
        @ResourceArg(name = "kafka.port", value = "9092"), // Fixed port for kafka, by default it will be exposed on a random port
        @ResourceArg(name = "kraft", value = "true"), // Enable Kraft mode
        @ResourceArg(name = "num.partitions", value = "3"), // Other custom broker configurations
})
public class OrderProcessorTest {
    // ...
}</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="custom-test-resource"><a class="anchor" href="#custom-test-resource"></a>17.2.1. Recurso de teste personalizado</h4>
<div class="paragraph">
<p>Como alternativa, você pode iniciar um broker Kafka em um recurso de teste. O trecho a seguir mostra um recurso de teste iniciando um broker do Kafka usando <a href="https://www.testcontainers.org/modules/kafka/">Testcontainers</a> :</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class KafkaResource implements QuarkusTestResourceLifecycleManager {

    private final KafkaContainer kafka = new KafkaContainer();

    @Override
    public Map&lt;String, String&gt; start() {
        kafka.start();
        return Collections.singletonMap("kafka.bootstrap.servers", kafka.getBootstrapServers());  <i class="conum" data-value="1"></i><b>(1)</b>
    }

    @Override
    public void stop() {
        kafka.close();
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configure a localização do bootstrap do Kafka, para que a aplicação se ligue a este broker.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-dev-services"><a class="anchor" href="#kafka-dev-services"></a>18. Dev Services para o Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If any Kafka-related extension is present (e.g. <code>quarkus-smallrye-reactive-messaging-kafka</code>), Dev Services for Kafka automatically starts a Kafka broker in dev mode and when running tests.
So, you don&#8217;t have to start a broker manually.
The application is configured automatically.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Como a inicialização de um broker Kafka pode ser demorada, o Dev Services para o Kafka usa o  <a href="https://vectorized.io/redpanda">Redpanda</a>, um broker compatível com o Kafka que inicia em aproximadamente 1 segundo.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="enabling-disabling-dev-services-for-kafka"><a class="anchor" href="#enabling-disabling-dev-services-for-kafka"></a>18.1. Ativar/desativar Dev Services para o Kafka</h3>
<div class="paragraph">
<p>Os Dev Services para o Kafka é ativado automaticamente, a menos que:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>quarkus.kafka.devservices.enabled</code> esteja definido como <code>false</code></p>
</li>
<li>
<p>o <code>kafka.bootstrap.servers</code> esteja configurado</p>
</li>
<li>
<p>todos os canais Kafka de mensagens reativas tenham o atributo <code>bootstrap.servers</code> definido</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Dev Services for Kafka relies on Docker to start the broker.
If your environment does not support Docker, you will need to start the broker manually, or connect to an already running broker.
You can configure the broker address using <code>kafka.bootstrap.servers</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="shared-broker"><a class="anchor" href="#shared-broker"></a>18.2. broker compartilhado</h3>
<div class="paragraph">
<p>Most of the time you need to share the broker between applications.
Dev Services for Kafka implements a <em>service discovery</em> mechanism for your multiple Quarkus applications running in <em>dev</em> mode to share a single broker.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
O Dev Services para o Kafka inicia o broker com a etiqueta <code>quarkus-dev-service-kafka</code> que é utilizada para identificar o container.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you need multiple (shared) brokers, you can configure the <code>quarkus.kafka.devservices.service-name</code> attribute and indicate the broker name.
It looks for a container with the same value, or starts a new one if none can be found.
The default service name is <code>kafka</code>.</p>
</div>
<div class="paragraph">
<p>Sharing is enabled by default in dev mode, but disabled in test mode.
You can disable the sharing with <code>quarkus.kafka.devservices.shared=false</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="setting-the-port"><a class="anchor" href="#setting-the-port"></a>18.3. Definindo a porta</h3>
<div class="paragraph">
<p>By default, Dev Services for Kafka picks a random port and configures the application.
You can set the port by configuring the <code>quarkus.kafka.devservices.port</code> property.</p>
</div>
<div class="paragraph">
<p>Note que o endereço anunciado do Kafka é automaticamente configurado com a porta escolhida.</p>
</div>
</div>
<div class="sect2">
<h3 id="configuring-the-image"><a class="anchor" href="#configuring-the-image"></a>18.4. Configurando a imagem</h3>
<div class="paragraph">
<p>Dev Services for Kafka supports <a href="https://redpanda.com">Redpanda</a>, <a href="https://github/ozangunalp/kafka-native">kafka-native</a>
and <a href="https://strimzi.io">Strimzi</a> (in <a href="https://github.com/apache/kafka/blob/trunk/config/kraft/README.md">Kraft</a> mode)  images.</p>
</div>
<div class="paragraph">
<p><strong>Redpanda</strong> is a Kafka compatible event streaming platform.
Because it provides a fast startup times, dev services defaults to Redpanda images from <code>vectorized/redpanda</code>.
You can select any version from <a href="https://hub.docker.com/r/vectorized/redpanda" class="bare">https://hub.docker.com/r/vectorized/redpanda</a>.</p>
</div>
<div class="paragraph">
<p><strong>kafka-native</strong> provides images of standard Apache Kafka distribution compiled to native binary using Quarkus and GraalVM.
While still being <em>experimental</em>, it provides very fast startup times with small footprint.</p>
</div>
<div class="paragraph">
<p>O tipo da imagem pode ser configurado utilizando</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.provider=kafka-native</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Strimzi</strong> provides container images and Operators for running Apache Kafka on Kubernetes.
While Strimzi is optimized for Kubernetes, the images work perfectly in classic container environments.
Strimzi container images run "genuine" Kafka broker on JVM, which is slower to start.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.provider=strimzi</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para  o Strimzi, você pode selecionar qualquer imagem com uma versão Kafka que tenha suporte para o Kraft (2.8.1 e superior) em  <a href="https://quay.io/repository/strimzi-test-container/test-container?tab=tags" class="bare">https://quay.io/repository/strimzi-test-container/test-container?tab=tags</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.image-name=quay.io/strimzi-test-container/test-container:0.100.0-kafka-3.1.0</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="configuring-kafka-topics"><a class="anchor" href="#configuring-kafka-topics"></a>18.5. Configurando os tópicos no Kafka</h3>
<div class="paragraph">
<p>You can configure the Dev Services for Kafka to create topics once the broker is started.
Topics are created with given number of partitions and 1 replica.</p>
</div>
<div class="paragraph">
<p>The following example creates a topic named <code>test</code> with 3 partitions, and a second topic named <code>messages</code> with 2 partitions.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.topic-partitions.test=3
quarkus.kafka.devservices.topic-partitions.messages=2</code></pre>
</div>
</div>
<div class="paragraph">
<p>If a topic already exists with the given name, the creation is skipped,
without trying to re-partition the existing topic to a different number of partitions.</p>
</div>
<div class="paragraph">
<p>Você pode configurar o tempo limite para as chamadas do client admin do Kafka utilizadas na criação de tópicos utilizando <code>quarkus.kafka.devservices.topic-partitions-timeout</code>. A predefinição é de 2 segundos.</p>
</div>
</div>
<div class="sect2">
<h3 id="redpanda-transactions"><a class="anchor" href="#redpanda-transactions"></a>18.6. Suporte aos producers transacionais e idempotentes</h3>
<div class="paragraph">
<p>By default, the Red Panda broker is configured to enable transactions and idempotence features.
You can disable those using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.redpanda.transaction-enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
As transações Redpanda não suportam um processamento exatamente único.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-dev-ui"><a class="anchor" href="#kafka-dev-ui"></a>19. Kafka Dev UI</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If any Kafka-related extension is present (e.g. <code>quarkus-smallrye-reactive-messaging-kafka</code>),
the Quarkus Dev UI is extended with a Kafka broker management UI.
It is connected automatically to the Kafka broker configured for the application.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-dev-ui-link.png" alt="Kafka Dev UI link" width="25%">
</div>
</div>
<div class="paragraph">
<p>Com o <strong>Kafka Dev UI</strong>, pode gerenciar diretamente o seu cluster Kafka e executar tarefas, tais como:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Listar e criar tópicos</p>
</li>
<li>
<p>Visualização de registros</p>
</li>
<li>
<p>Publicação de novos registros</p>
</li>
<li>
<p>Inspeção da lista de grupos de consumidores e do respetivo desfasamento de consumo</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-dev-ui-records.png" alt="Kafka Dev UI records" width="80%">
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
A Kafka Dev UI faz parte da interface de desenvolvimento do Quarkus e só está disponível no modo de desenvolvimento.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kubernetes-service-bindings"><a class="anchor" href="#kubernetes-service-bindings"></a>20. Vinculações de Serviços do Kubernetes</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A extensão Quarkus Kafka oferece suporte à <a href="deploying-to-kubernetes">Especificação de Vinculação de Serviço para Kubernetes</a>. Você pode ativar isso adicionando a extensão <code>quarkus-kubernetes-service-binding</code> à sua aplicação.</p>
</div>
<div class="paragraph">
<p>Quando executada em clusters Kubernetes configurados adequadamente, a extensão Kafka extrairá sua configuração de conexão do broker Kafka da associação de serviços disponível dentro do cluster, sem a necessidade de configuração do usuário.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="execution-model"><a class="anchor" href="#execution-model"></a>21. Modelo de execução</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A Mensageria Reativa invoca os métodos do usuário em uma thread de I/O. Portanto, por padrão, os métodos não devem bloquear. Conforme descrito em <a href="#blocking-processing">Bloqueando o processamento</a>, você precisa adicionar a anotação <code>@Blocking</code> no método se ele bloquear a thread do chamador.</p>
</div>
<div class="paragraph">
<p>Consulte a <a href="quarkus-reactive-architecture">documentação da Arquitetura Reativa do Quarkus</a> para obter mais informações sobre este tópico.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="channel-decorators"><a class="anchor" href="#channel-decorators"></a>22. Decoradores de Canais</h2>
<div class="sectionbody">
<div class="paragraph">
<p>SmallRye Reactive Messaging supports decorating incoming and outgoing channels for implementing cross-cutting concerns such as monitoring, tracing or message interception. For more information on implementing decorators and message interceptors see the <a href="http://smallrye.io/smallrye-reactive-messaging/3.19.1/concepts/decorators/">SmallRye Reactive Messaging documentation</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-configuration"><a class="anchor" href="#kafka-configuration"></a>23. Referência de configuração</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Mais detalhes sobre a configuração da Mensageria Reativa do SmallRye podem ser encontrados na <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/kafka/#using-the-kafka-connector">documentação da Mensageria Reativa do SmallRye - Conector Kafka</a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Cada canal pode ser desativado através da configuração utilizando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.[incoming|outgoing].[channel].enabled=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Os atributos mais importantes são enumerados nos quadros seguintes:</p>
</div>
<div class="sect2">
<h3 id="incoming-channel-configuration-polling-from-kafka"><a class="anchor" href="#incoming-channel-configuration-polling-from-kafka"></a>23.1. Configuração do canal de entrada (sondagem a partir do Kafka)</h3>
<div class="paragraph">
<p>Os seguintes atributos são configurados utilizando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.your-channel-name.attribute=value</code></pre>
</div>
</div>
<div class="paragraph">
<p>Algumas propriedades têm apelidos que podem ser configurados globalmente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Você também pode passar qualquer propriedade suportada pelo <a href="https://kafka.apache.org/documentation/#consumerconfigs">consumidor Kafka</a> subjacente.</p>
</div>
<div class="paragraph">
<p>Por exemplo, para configurar a propriedade <code>max.poll.records</code>, utilize:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.[channel].max.poll.records=1000</code></pre>
</div>
</div>
<div class="paragraph">
<p>Algumas propriedades do cliente consumidor são configuradas com valores predefinidos sensíveis:</p>
</div>
<div class="paragraph">
<p>Se não estiver definido, <code>reconnect.backoff.max.ms</code> é definido para <code>10000</code> para evitar uma carga elevada ao desconectar.</p>
</div>
<div class="paragraph">
<p>Se não for definido, <code>key.deserializer</code> é definido como <code>org.apache.kafka.common.serialization.StringDeserializer</code>.</p>
</div>
<div class="paragraph">
<p>O consumidor <code>client.id</code> é configurado de acordo com o número de clientes a criar utilizando a propriedade <code>mp.messaging.incoming.[channel].partitions</code>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Se for fornecido um <code>client.id</code>, este é usado como está ou sufixado com o índice do cliente se a propriedade <code>partitions</code> estiver definida.</p>
</li>
<li>
<p>Se não for fornecido um <code>client.id</code>, este é gerado como <code>[client-id-prefix][channel-name][-index]</code>.</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Atributos de entrada do conector 'smallrye-kafka'</caption>
<colgroup>
<col style="width: 27.7777%;">
<col style="width: 33.3333%;">
<col style="width: 16.6666%;">
<col style="width: 22.2224%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Atributo (<em>alias</em>)</th>
<th class="tableblock halign-left valign-top">Descrição</th>
<th class="tableblock halign-left valign-top">Obrigatório</th>
<th class="tableblock halign-left valign-top">Padrão</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>bootstrap.servers</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(kafka.bootstrap.servers)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uma lista separada por vírgulas de host:port a ser usada para estabelecer a conexão inicial com o cluster Kafka.</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>localhost:9092</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O tema Kafka consumido/populado. Se nem essa propriedade nem as propriedades 'topics' estiverem definidas, o nome do canal será usado</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o relatório de integridade está habilitado (padrão) ou desabilitado</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o relatório de integridade de prontidão está habilitado (padrão) ou desabilitado</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-topic-verification</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - Se a verificação de prontidão deve verificar se os tópicos existem no broker. O padrão é false. Habilitá-lo requer uma conexão de administrador. Deprecated: use 'health-topic-verification-enabled' em vez disso.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - Durante a verificação de integridade de prontidão, o conector se conecta ao broker e recupera a lista de tópicos. Esse atributo especifica a duração máxima (em ms) para a recuperação. Se excedido, o canal é considerado não pronto. Preterido: use 'health-topic-verification-timeout' em vez disso.</p>
<p class="tableblock">Tipo: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se a verificação de inicialização e prontidão deve verificar se os tópicos existem no broker. O padrão é false. Habilitá-lo requer uma conexão de cliente administrador.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Durante a verificação de integridade de inicialização e preparação, o conector se conecta ao agente e recupera a lista de tópicos. Esse atributo especifica a duração máxima (em ms) para a recuperação. Se excedido, o canal é considerado não pronto.</p>
<p class="tableblock">Tipo: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>tracing-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o rastreamento está habilitado (padrão) ou desabilitado</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>client-id-prefix</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Prefix for Kafka client <code>client.id</code> attribute. If defined configured or generated <code>client.id</code> will be prefixed with the given value, otherwise <code>kafka-consumer-</code> is the prefix.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>checkpoint.state-store</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">While using the <code>checkpoint</code> commit-strategy, the name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.StateStore.Factory</code> to specify the state store implementation.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>checkpoint.state-type</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">While using the <code>checkpoint</code> commit-strategy, the fully qualified type name of the state object to persist in the state store. When provided, it can be used by the state store implementation to help persisting the processing state object.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>checkpoint.unsynced-state-max-age.ms</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">While using the <code>checkpoint</code> commit-strategy, specify the max age in milliseconds that the processing state must be persisted before the connector is marked as unhealthy. Setting this attribute to <code>0</code> disables this monitoring.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>10000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilita (padrão) ou desabilita o suporte a Cloud Event. Se habilitado em um canal <em>incoming</em>, o conector analisará os registros de entrada e tentará criar metadados do Cloud Event. Se habilitado em um <em>outgoing</em>, o conector enviará as mensagens de saída como Cloud Event se a mensagem incluir Metadados de Evento de Nuvem.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>kafka-configuration</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identificador de um bean CDI que fornece a configuração padrão do consumidor/produtor Kafka para esse canal. A configuração do canal ainda pode substituir qualquer atributo. O bean deve ter um tipo de Map&lt;String, Object&gt; e deve usar o qualificador @io.smallrye.common.annotation.Identifier para definir o identificador.</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topics</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A comma-separating list of topics to be consumed. Cannot be used with the <code>topic</code> or <code>pattern</code> properties</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>pattern</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Indicate that the <code>topic</code> property is a regular expression. Must be used with the <code>topic</code> property. Cannot be used with the <code>topics</code> property</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key.deserializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The deserializer classname used to deserialize the record&#8217;s key</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>org.apache.kafka.common.serialization.StringDeserializer</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>lazy-client</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o cliente Kafka é criado preguiçosamente ou ansiosamente.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value.deserializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The deserializer classname used to deserialize the record&#8217;s value</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>fetch.min.bytes</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum amount of data the server should return for a fetch request. The default setting of 1 byte means that fetch requests are answered as soon as a single byte of data is available or the fetch request times out waiting for data to arrive.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>group.id</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A unique string that identifies the consumer group the application belongs to.</p>
<p class="tableblock">If not set, defaults to the application name as set by the <code>quarkus.application.name</code> configuration property.</p>
<p class="tableblock">If that is not set either, a unique, generated id is used.</p>
<p class="tableblock">It is recommended to always define a <code>group.id</code>, the automatic generation is only a convenient feature for development.
You can explicitly ask for automatically generated unique id by setting this property to <code>${quarkus.uuid}</code>.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>enable.auto.commit</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If enabled, consumer&#8217;s offset will be periodically committed in the background by the underlying Kafka client, ignoring the actual processing outcome of the records. It is recommended to NOT enable this setting and let Reactive Messaging handles the commit.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the connection to the broker is re-attempted in case of failure</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry-attempts</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The maximum number of reconnection before failing. -1 means infinite retry</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry-max-wait</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The max delay (in seconds) between 2 reconnects</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>30</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>broadcast</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the Kafka records should be dispatched to multiple consumer</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>auto.offset.reset</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">What to do when there is no initial offset in Kafka.Accepted values are earliest, latest and none</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>latest</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>failure-strategy</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Specify the failure strategy to apply when a message produced from a record is acknowledged negatively (nack). Values can be <code>fail</code> (default), <code>ignore</code>, or <code>dead-letter-queue</code></p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>fail</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>commit-strategy</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Specify the commit strategy to apply when a message produced from a record is acknowledged. Values can be <code>latest</code>, <code>ignore</code> or <code>throttled</code>. If <code>enable.auto.commit</code> is true then the default is <code>ignore</code> otherwise it is <code>throttled</code></p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>throttled.unprocessed-record-max-age.ms</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">While using the <code>throttled</code> commit-strategy, specify the max age in milliseconds that an unprocessed message can be before the connector is marked as unhealthy. Setting this attribute to 0 disables this monitoring.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>60000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When the <code>failure-strategy</code> is set to <code>dead-letter-queue</code> indicates on which topic the record is sent. Defaults is <code>dead-letter-topic-$channel</code></p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.key.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When the <code>failure-strategy</code> is set to <code>dead-letter-queue</code> indicates the key serializer to use. If not set the serializer associated to the key deserializer is used</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.value.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When the <code>failure-strategy</code> is set to <code>dead-letter-queue</code> indicates the value serializer to use. If not set the serializer associated to the value deserializer is used</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>partitions</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of partitions to be consumed concurrently. The connector creates the specified amount of Kafka consumers. It should match the number of partition of the targeted topic</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>requests</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When <code>partitions</code> is greater than 1, this attribute allows configuring how many records are requested by each consumer every time.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>128</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>consumer-rebalance-listener.name</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code>. If set, this rebalance listener is applied to the consumer.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key-deserialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler</code>. If set, deserialization failure happening when deserializing keys are delegated to this handler which may retry or provide a fallback value.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value-deserialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler</code>. If set, deserialization failure happening when deserializing values are delegated to this handler which may retry or provide a fallback value.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>fail-on-deserialization-failure</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When no deserialization failure handler is set and a deserialization failure happens, report the failure and mark the application as unhealthy. If set to <code>false</code> and a deserialization failure happens, a <code>null</code> value is forwarded.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>graceful-shutdown</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether a graceful shutdown should be attempted when the application terminates.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>poll-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The polling timeout in milliseconds. When polling records, the poll will wait at most that duration before returning records. Default is 1000ms</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>pause-if-no-requests</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the polling must be paused when the application does not request items and resume when it does. This allows implementing back-pressure based on the application capacity. Note that polling is not stopped, but will not retrieve any records when paused.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>batch</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the Kafka records are consumed in batch. The channel injection point must consume a compatible type, such as <code>List&lt;Payload&gt;</code> or <code>KafkaRecordBatch&lt;Payload&gt;</code>.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>max-queue-size-factor</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier factor to determine maximum number of records queued for processing, using <code>max.poll.records</code> * <code>max-queue-size-factor</code>. Defaults to 2. In <code>batch</code> mode <code>max.poll.records</code> is considered <code>1</code>.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="outgoing-channel-configuration-writing-to-kafka"><a class="anchor" href="#outgoing-channel-configuration-writing-to-kafka"></a>23.2. Configuração do canal de saída (escrevendo no Kafka)</h3>
<div class="paragraph">
<p>Os seguintes atributos são configurados utilizando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.your-channel-name.attribute=value</code></pre>
</div>
</div>
<div class="paragraph">
<p>Algumas propriedades têm apelidos que podem ser configurados globalmente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Você também pode passar qualquer propriedade suportada pelo <a href="https://kafka.apache.org/documentation/#producerconfigs">produtor Kafka</a> subjacente.</p>
</div>
<div class="paragraph">
<p>Por exemplo, para configurar a propriedade <code>max.block.ms</code>, utilize:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.[channel].max.block.ms=10000</code></pre>
</div>
</div>
<div class="paragraph">
<p>Algumas propriedades do cliente produtor são configuradas para valores predefinidos sensíveis:</p>
</div>
<div class="paragraph">
<p>Se não estiver definido, <code>reconnect.backoff.max.ms</code> é definido para <code>10000</code> para evitar uma carga elevada ao desconectar.</p>
</div>
<div class="paragraph">
<p>Se não for definido, <code>key.serializer</code> é definido como <code>org.apache.kafka.common.serialization.StringSerializer</code>.</p>
</div>
<div class="paragraph">
<p>Se não for definido, o produtor <code>client.id</code> é gerado como <code>[client-id-prefix][channel-name]</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Atributos de saída do conector 'smallrye-kafka'</caption>
<colgroup>
<col style="width: 27.7777%;">
<col style="width: 33.3333%;">
<col style="width: 16.6666%;">
<col style="width: 22.2224%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Atributo (<em>alias</em>)</th>
<th class="tableblock halign-left valign-top">Descrição</th>
<th class="tableblock halign-left valign-top">Obrigatório</th>
<th class="tableblock halign-left valign-top">Padrão</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>acks</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O número de reconhecimentos que o produtor exige que o líder tenha recebido antes de considerar um pedido completo. Isso controla a durabilidade dos registros que são enviados. Os valores aceitos são: 0, 1, todos</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>bootstrap.servers</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(kafka.bootstrap.servers)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uma lista separada por vírgulas de host:port a ser usada para estabelecer a conexão inicial com o cluster Kafka.</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>localhost:9092</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>client-id-prefix</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Prefixo para o atributo 'client.id' do cliente Kafka. Se definido configurado ou gerado 'client.id' será prefixado com o valor dado, caso contrário 'kafka-producer-' é o prefixo.</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>buffer.memory</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O total de bytes de memória que o produtor pode usar para armazenar em buffer registros aguardando para serem enviados ao servidor.</p>
<p class="tableblock">Tipo: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>33554432</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>close-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A quantidade de milissegundos à espera de um desligamento gracioso do produtor de Kafka</p>
<p class="tableblock">Tipo: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>10000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilita (padrão) ou desabilita o suporte a Cloud Event. Se habilitado em um canal <em>incoming</em>, o conector analisará os registros de entrada e tentará criar metadados do Cloud Event. Se habilitado em um <em>outgoing</em>, o conector enviará as mensagens de saída como Cloud Event se a mensagem incluir Metadados de Evento de Nuvem.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-data-content-type</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-data-content-type)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configura o atributo 'datacontenttype' padrão do evento de nuvem de saída. Requer que 'cloud-events' seja definido como 'true'. Esse valor será usado se a mensagem não configurar o próprio atributo 'datacontenttype'</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-data-schema</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-data-schema)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configura o atributo 'dataschema' padrão do evento de nuvem de saída. Requer que 'cloud-events' seja definido como 'true'. Esse valor será usado se a mensagem não configurar o próprio atributo 'dataschema'</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-insert-timestamp</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-timestamp)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o conector deve inserir automaticamente o atributo 'time' no evento de nuvem de saída. Requer que 'cloud-events' seja definido como 'true'. Esse valor será usado se a mensagem não configurar o próprio atributo 'time'</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-mode</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O modo Cloud Event ('estruturado' ou 'binário' (padrão)). Indica como são gravados os eventos de nuvem no registro de saída</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>binary</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-source</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-source)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure o atributo 'source' padrão do evento de nuvem de saída. Requer que 'cloud-events' seja definido como 'true'. Esse valor será usado se a mensagem não configurar o próprio atributo 'source'</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-subject</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-subject)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure o atributo 'subject' padrão do evento de nuvem de saída. Requer que 'cloud-events' seja definido como 'true'. Esse valor será usado se a mensagem não configurar o próprio atributo 'subject'</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-type</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-type)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure o atributo 'type' padrão do evento de nuvem de saída. Requer que 'cloud-events' seja definido como 'true'. Esse valor será usado se a mensagem não configurar o próprio atributo 'type'</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o relatório de integridade está habilitado (padrão) ou desabilitado</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o relatório de integridade de prontidão está habilitado (padrão) ou desabilitado</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - Durante a verificação de integridade de prontidão, o conector se conecta ao broker e recupera a lista de tópicos. Esse atributo especifica a duração máxima (em ms) para a recuperação. Se excedido, o canal é considerado não pronto. Preterido: use 'health-topic-verification-timeout' em vez disso.</p>
<p class="tableblock">Tipo: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-topic-verification</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - Se a verificação de prontidão deve verificar se os tópicos existem no broker. O padrão é false. Habilitá-lo requer uma conexão de administrador. Deprecated: use 'health-topic-verification-enabled' em vez disso.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se a verificação de inicialização e prontidão deve verificar se os tópicos existem no broker. O padrão é false. Habilitá-lo requer uma conexão de cliente administrador.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Durante a verificação de integridade de inicialização e preparação, o conector se conecta ao agente e recupera a lista de tópicos. Esse atributo especifica a duração máxima (em ms) para a recuperação. Se excedido, o canal é considerado não pronto.</p>
<p class="tableblock">Tipo: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>kafka-configuration</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identificador de um bean CDI que fornece a configuração padrão do consumidor/produtor Kafka para esse canal. A configuração do canal ainda pode substituir qualquer atributo. O bean deve ter um tipo de Map&lt;String, Object&gt; e deve usar o qualificador @io.smallrye.common.annotation.Identifier para definir o identificador.</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uma chave a ser usada ao gravar o registro</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key-serialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O nome definido em '@Identifier' de um bean que implementa 'io.smallrye.reactive.messaging.kafka.SerializationFailureHandler'. Se definido, a falha de serialização que ocorre quando as chaves de serialização são delegadas a esse manipulador, que pode fornecer um valor de fallback.</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O nome da classe do serializador usado para serializar a chave do registro</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>org.apache.kafka.common.serialization.StringSerializer</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>lazy-client</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o cliente Kafka é criado preguiçosamente ou ansiosamente.</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>max-inflight-messages</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O número máximo de mensagens a serem gravadas em Kafka simultaneamente. Ele limita o número de mensagens aguardando para serem escritas e reconhecidas pelo corretor. Você pode definir esse atributo como '0' remover o limite</p>
<p class="tableblock">Tipo: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1024</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>merge</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o conector deve permitir vários upstreams</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>partition</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O id da partição de destino. -1 para permitir que o cliente determine a partição</p>
<p class="tableblock">Tipo: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>propagate-headers</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uma lista separada por vírgulas de cabeçalhos de registro de entrada a serem propagados para o registro de saída</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>propagate-record-key</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Propagar a chave de registro de entrada para o registro de saída</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retries</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se definido como um número positivo, o conector tentará reenviar qualquer registro que não tenha sido entregue com êxito (com um erro potencialmente transitório) até que o número de tentativas seja atingido. Se definido como 0, as novas tentativas serão desabilitadas. Se não estiver definido, o conector tentará reenviar qualquer registro que não tenha sido entregue (devido a um erro potencialmente transitório) durante um período de tempo configurado por 'delivery.timeout.ms'.</p>
<p class="tableblock">Tipo: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2147483647</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O tema Kafka consumido/populado. Se nem essa propriedade nem as propriedades 'topics' estiverem definidas, o nome do canal será usado</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>tracing-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o rastreamento está habilitado (padrão) ou desabilitado</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value-serialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O nome definido em '@Identifier' de um bean que implementa 'io.smallrye.reactive.messaging.kafka.SerializationFailureHandler'. Se definido, a falha de serialização que ocorre quando os valores de serialização são delegados a esse manipulador, que pode fornecer um valor de fallback.</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">O nome da classe do serializador usado para serializar a carga útil</p>
<p class="tableblock">Tipo: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>waitForWriteCompletion</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Se o cliente espera que Kafka reconheça o registro escrito antes de reconhecer a mensagem</p>
<p class="tableblock">Tipo: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">falso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="kafka-configuration-resolution"><a class="anchor" href="#kafka-configuration-resolution"></a>23.3. Resolução de Configuração do Kafka</h3>
<div class="paragraph">
<p>O Quarkus expõe todas as propriedades da aplicação relacionadas ao Kafka, prefixadas com <code>kafka.</code> ou <code>KAFKA_</code> dentro de um mapa de configuração com o nome <code>default-kafka-broker</code>. Essa configuração é usada para estabelecer a conexão com o broker Kafka.</p>
</div>
<div class="paragraph">
<p>Além desta configuração predefinida, você pode configurar o nome do produtor <code>Map</code> utilizando o atributo <code>kafka-configuration</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.my-channel.connector=smallrye-kafka
mp.messaging.incoming.my-channel.kafka-configuration=my-configuration</code></pre>
</div>
</div>
<div class="paragraph">
<p>Nesse caso, o conector procura o <code>Map</code> associado ao nome <code>my-configuration</code>. Se <code>kafka-configuration</code> não estiver definido, será feita uma pesquisa opcional de um <code>Map</code> exposto com o nome do canal (<code>my-channel</code> no exemplo anterior).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Produces
@ApplicationScoped
@Identifier("my-configuration")
Map&lt;String, Object&gt; outgoing() {
    return Map.ofEntries(
            Map.entry("value.serializer", ObjectMapperSerializer.class.getName())
    );
}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Se <code>kafka-configuration</code> estiver definido e não for possível encontrar <code>Map</code>, a implantação falha.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Os valores dos atributos são resolvidos da seguinte forma:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>o atributo é definido diretamente na configuração do canal (<code>mp.messaging.incoming.my-channel.attribute=value</code>),</p>
</li>
<li>
<p>se não estiver definido, o conector procura um <code>Map</code> com o nome do canal ou o <code>kafka-configuration</code> configurado (se definido) e o valor é obtido a partir desse <code>Map</code></p>
</li>
<li>
<p>Se o <code>Map</code> resolvido não contém o valor, é utilizado o <code>Map</code> padrão (exposto com o nome <code>default-kafka-broker</code>)</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="integrating-with-kafka-common-patterns"><a class="anchor" href="#integrating-with-kafka-common-patterns"></a>24. Integrando com o Kafka - Padrões comuns</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="writing-to-kafka-from-an-http-endpoint"><a class="anchor" href="#writing-to-kafka-from-an-http-endpoint"></a>24.1. Escrever no Kafka a partir de um endpoint HTTP</h3>
<div class="paragraph">
<p>Para enviar mensagens para o Kafka a partir de um endpoint HTTP, injete um <code>Emitter</code> (ou um <code>MutinyEmitter</code>) no seu endpoint:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;String&gt; emitter;          <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public CompletionStage&lt;Void&gt; send(String payload) { <i class="conum" data-value="2"></i><b>(2)</b>
        return emitter.send(payload);                   <i class="conum" data-value="3"></i><b>(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Injete um <code>Emitter&lt;String&gt;</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>O método HTTP recebe o conteúdo e devolve um <code>CompletionStage</code> concluído quando a mensagem é escrita no Kafka</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Envie a mensagem para o Kafka, o método <code>send</code> devolve um <code>CompletionStage</code></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>O endpoint envia a conteúdo passado (de uma requisição HTTP <code>POST</code>) para o emissor. O canal do emissor é mapeado para um tópico do Kafka no arquivo <code>application.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.kafka.connector=smallrye-kafka
mp.messaging.outgoing.kafka.topic=my-topic</code></pre>
</div>
</div>
<div class="paragraph">
<p>O endpoint retorna um <code>CompletionStage</code> indicando a natureza assíncrona do método. O método <code>emitter.send</code> retorna um <code>CompletionStage&lt;Void&gt;</code>. O future retornado é concluído quando a mensagem tiver sido gravada no Kafka. Se a gravação falhar, o <code>CompletionStage</code> retornado será concluído excepcionalmente.</p>
</div>
<div class="paragraph">
<p>Se o endpoint não devolver um <code>CompletionStage</code>, a resposta HTTP pode ser escrita antes de a mensagem ser enviada para o Kafka, e então as falhas não serão comunicadas ao usuário.</p>
</div>
<div class="paragraph">
<p>Se você precisa enviar um registro Kafka, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import io.smallrye.reactive.messaging.kafka.Record;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;Record&lt;String,String&gt;&gt; emitter;  <i class="conum" data-value="1"></i><b>(1)</b>


    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public CompletionStage&lt;Void&gt; send(String payload) {
        return emitter.send(Record.of("my-key", payload));    <i class="conum" data-value="2"></i><b>(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Note a utilização de um <code>Emitter&lt;Record&lt;K, V&gt;&gt;</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Crie o registro usando <code>Record.of(k, v)</code></td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="persisting-kafka-messages-with-hibernate-with-panache"><a class="anchor" href="#persisting-kafka-messages-with-hibernate-with-panache"></a>24.2. Persistindo mensagens Kafka com o Hibernate com Panache</h3>
<div class="paragraph">
<p>Para persistir objetos recebidos do Kafka numa base de dados, você pode utilizar o Hibernate com o Panache.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Se você estiver usando o Hibernate Reactive, veja <a href="#persisting-kafka-messages-with-hibernate-reactive">Persistência de mensagens Kafka com o Hibernate Reativo</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Vamos imaginar que você receba objetos <code>Fruit</code>. Para fins de simplificação, nossa classe <code>Fruit</code> é bastante simples:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.persistence.Entity;

import io.quarkus.hibernate.orm.panache.PanacheEntity;

@Entity
public class Fruit extends PanacheEntity {

    public String name;

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para consumir instâncias do <code>Fruit</code> armazenadas num tópico do Kafka e mantê-las numa base de dados, você pode utilizar a seguinte abordagem:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.enterprise.context.ApplicationScoped;
import javax.transaction.Transactional;

import org.eclipse.microprofile.reactive.messaging.Incoming;

import io.smallrye.common.annotation.Blocking;

@ApplicationScoped
public class FruitConsumer {

    @Incoming("fruits")                                     <i class="conum" data-value="1"></i><b>(1)</b>
    @Transactional                                          <i class="conum" data-value="2"></i><b>(2)</b>
    public void persistFruits(Fruit fruit) {                <i class="conum" data-value="3"></i><b>(3)</b>
        fruit.persist();                                    <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configurando o canal de entrada. Este canal lê a partir do Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Como estamos escrevendo em um banco de dados, devemos estar em uma transação. Essa anotação inicia uma nova transação e a confirma quando o método retorna. O Quarkus considera automaticamente o método como <em>blocante</em>. De fato, a gravação em um banco de dados usando o Hibernate clássico é blocante. Portanto, o Quarkus chama o método em um thread de trabalho que pode ser bloqueado (e não em um thread de E/S).</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>O método recebe cada Fruit. Note que seria necessário um desserializador para reconstruir as instâncias Fruit a partir dos registros Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Persiste o objeto <code>fruit</code> recebido.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Conforme mencionado em &lt;4&gt;, você precisa de um desserializador que possa criar um <code>Fruit</code> a partir do registro. Isso pode ser feito usando um desserializador Jackson:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>A configuração associada seria:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.fruits.connector=smallrye-kafka
mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Consulte <a href="#jackson-serialization">Serialização via Jackson</a> para mais detalhes sobre o uso do Jackson com o Kafka. Também é possível utilizar Avro.</p>
</div>
</div>
<div class="sect2">
<h3 id="persisting-kafka-messages-with-hibernate-reactive"><a class="anchor" href="#persisting-kafka-messages-with-hibernate-reactive"></a>24.3. Persistência de mensagens Kafka com o Hibernate Reativo</h3>
<div class="paragraph">
<p>Para persistir objetos recebidos do Kafka numa base de dados, você pode utilizar o Hibernate Reativo com Panache.</p>
</div>
<div class="paragraph">
<p>Vamos imaginar que você receba objetos <code>Fruit</code>. Para fins de simplificação, nossa classe <code>Fruit</code> é bastante simples:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.persistence.Entity;

import io.quarkus.hibernate.reactive.panache.PanacheEntity;  <i class="conum" data-value="1"></i><b>(1)</b>

@Entity
public class Fruit extends PanacheEntity {

    public String name;

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Certifique-se de que utiliza a variante reativa</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Para consumir instâncias do <code>Fruit</code> armazenadas num tópico do Kafka e mantê-las numa base de dados, você pode utilizar a seguinte abordagem:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.context.control.ActivateRequestContext;

import org.eclipse.microprofile.reactive.messaging.Incoming;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;

@ApplicationScoped
public class FruitStore {

    @Inject
    Mutiny.Session session;                    <i class="conum" data-value="1"></i><b>(1)</b>

    @Incoming("in")
    @ActivateRequestContext <i class="conum" data-value="2"></i><b>(2)</b>
    public Uni&lt;Void&gt; consume(Fruit entity) {
        return session.withTransaction(t -&gt; {  <i class="conum" data-value="3"></i><b>(3)</b>
            return entity.persistAndFlush()    <i class="conum" data-value="4"></i><b>(4)</b>
                    .replaceWithVoid();        <i class="conum" data-value="5"></i><b>(5)</b>
        }).onTermination().call(() -&gt; session.close()); <i class="conum" data-value="6"></i><b>(6)</b>
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Injete a <code>Session</code> do Hibernate Reativo</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>As APIs <code>Session</code> e <code>Panache</code> do Hibernate Reativo exigem um Contexto de Requisição CDI ativo. A anotação <code>@ActivateRequestContext</code> cria um novo contexto de requisição e o destrói quando o <code>Uni</code> retorno do método é concluído. Se o <code>Panache</code> não for usado, o <code>Mutiny.SessionFactory</code> poderá ser injetado e usado de forma semelhante, sem a necessidade de ativar o contexto de requisição ou fechar a sessão manualmente.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Solicita uma nova transação. A transação é concluída quando a ação passada é concluída.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Persiste a entidade. Devolve um <code>Uni&lt;Fruit&gt;</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Troque de volta para um <code>Uni&lt;Void&gt;</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Feche a sessão - isto é, fechar a conexão com a base de dados. A conexão pode então ser reciclada.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Diferentemente do Hibernate <em>clássico</em>, você não pode usar <code>@Transactional</code>. Em vez disso, usamos <code>session.withTransaction</code> e persistimos nossa entidade. O <code>map</code> é usado para retornar um <code>Uni&lt;Void&gt;</code> e não um <code>Uni&lt;Fruit&gt;</code>.</p>
</div>
<div class="paragraph">
<p>Você precisa de um desserializador que possa criar um <code>Fruit</code> a partir do registro. Isso pode ser feito usando um desserializador Jackson:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>A configuração associada seria:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.fruits.connector=smallrye-kafka
mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Consulte <a href="#jackson-serialization">Serialização via Jackson</a> para mais detalhes sobre o uso do Jackson com o Kafka. Também é possível utilizar Avro.</p>
</div>
</div>
<div class="sect2">
<h3 id="writing-entities-managed-by-hibernate-to-kafka"><a class="anchor" href="#writing-entities-managed-by-hibernate-to-kafka"></a>24.4. Escrevendo entidades gerenciadas pelo Hibernate no Kafka</h3>
<div class="paragraph">
<p>Vamos imaginar o seguinte processo:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>VocêrRecebe uma requisição HTTP com um conteúdo,</p>
</li>
<li>
<p>Você uma instância de entidade Hibernate a partir deste conteúdo,</p>
</li>
<li>
<p>Você persiste essa entidade numa base de dados,</p>
</li>
<li>
<p>Você envia a entidade para um tópico do Kafka</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Se você estiver usando Hibernate Reactive, veja <a href="#writing-entities-managed-by-hibernate-reactive-to-kafka">Escrevendo entidades gerenciadas pelo Hibernate Reativo no Kafka</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Como gravamos em um banco de dados, precisamos executar esse método em uma transação. No entanto, o envio da entidade para o Kafka ocorre de forma assíncrona. A operação retorna um relatório <code>CompletionStage</code> (ou um <code>Uni</code> se você usar um <code>MutinyEmitter</code>) quando a operação for concluída. Precisamos ter certeza de que a transação ainda está em execução até que o objeto seja gravado. Caso contrário, você poderá acessar o objeto fora da transação, o que não é permitido.</p>
</div>
<div class="paragraph">
<p>Para implementar este processo, é necessária a seguinte abordagem:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.transaction.Transactional;
import javax.ws.rs.POST;
import javax.ws.rs.Path;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;Fruit&gt; emitter;

    @POST
    @Path("/fruits")
    @Transactional                                                      <i class="conum" data-value="1"></i><b>(1)</b>
    public CompletionStage&lt;Void&gt; storeAndSendToKafka(Fruit fruit) {     <i class="conum" data-value="2"></i><b>(2)</b>
        fruit.persist();
        return emitter.send(fruit);                                     <i class="conum" data-value="3"></i><b>(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Como estamos escrevendo para a base de dados, certifique-se de que executamos dentro de uma transação</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>O método recebe a instância de fruit a ser persistida. Devolve um <code>CompletionStage</code> que é utilizado para a demarcação da transação. A transação é confirmada quando o retorno <code>CompletionStage</code> é concluído. No nosso caso, é quando a mensagem é escrita no Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Send the managed instance to Kafka. Make sure we wait for the message to complete before closing the transaction.</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="writing-entities-managed-by-hibernate-reactive-to-kafka"><a class="anchor" href="#writing-entities-managed-by-hibernate-reactive-to-kafka"></a>24.5. Escrevendo entidades gerenciadas pelo Hibernate Reativo no Kafka</h3>
<div class="paragraph">
<p>Para enviar para entidades Kafka gerenciadas pelo Hibernate Reativo, recomendamos usar:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>RESTEasy Reativo para servir requisições HTTP</p>
</li>
<li>
<p>Um <code>MutinyEmitter</code> para enviar mensagens para um canal, para que possa ser facilmente integrado com a API do Mutiny exposta pelo Hibernate Reativo ou Hibernate Reativo com Panache.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>O exemplo a seguir demonstra como receber um conteúdo, armazená-lo na base de dados utilizando o Hibernate Reativo com Panache e enviar a entidade persistente para o Kafka:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.ws.rs.POST;
import javax.ws.rs.Path;

import org.eclipse.microprofile.reactive.messaging.Channel;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.MutinyEmitter;

@Path("/")
public class ReactiveGreetingResource {

    @Channel("kafka") MutinyEmitter&lt;Fruit&gt; emitter;     <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    public Uni&lt;Void&gt; sendToKafka(Fruit fruit) {         <i class="conum" data-value="2"></i><b>(2)</b>
        return Panache.withTransaction(() -&gt;            <i class="conum" data-value="3"></i><b>(3)</b>
            fruit.&lt;Fruit&gt;persist()
        )
            .chain(f -&gt; emitter.send(f));               <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Injete um <code>MutinyEmitter</code> que expõe uma API do Mutiny. Ele simplifica a integração com a API do Mutiny exposta pelo Hibernate Reativo com Panache.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>O método HTTP que recebe o conteúdo devolve um <code>Uni&lt;Void&gt;</code>. A resposta HTTP é escrita quando a operação é concluída (a entidade é persistida e escrita no Kafka).</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Temos de escrever a entidade na base de dados numa transação.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Uma vez concluída a operação de persistência, enviamos a entidade para o Kafka. O método <code>send</code> devolve um <code>Uni&lt;Void&gt;</code>.</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="streaming-kafka-topics-as-server-sent-events"><a class="anchor" href="#streaming-kafka-topics-as-server-sent-events"></a>24.6. Transmitindo tópicos do Kafka como eventos enviados pelo servidor</h3>
<div class="paragraph">
<p>A transmissão de um tópico do Kafka como eventos enviados pelo servidor (SSE) é simples:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Você injeta o canal que representa o tópico Kafka no seu endpoint HTTP</p>
</li>
<li>
<p>Você devolve esse canal como <code>Publisher</code> ou <code>Multi</code> a partir do método HTTP</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>O código seguinte apresenta um exemplo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Channel("fruits")
Multi&lt;Fruit&gt; fruits;

@GET
@Produces(MediaType.SERVER_SENT_EVENTS)
public Multi&lt;Fruit&gt; stream() {
    return fruits;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alguns ambientes cortam a conexão SSE quando não há atividade suficiente. A solução alternativa consiste em enviar mensagens de <em>ping</em> (ou objetos vazios) periodicamente.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Channel("fruits")
Multi&lt;Fruit&gt; fruits;

@Inject
ObjectMapper mapper;

@GET
@Produces(MediaType.SERVER_SENT_EVENTS)
public Multi&lt;String&gt; stream() {
    return Multi.createBy().merging()
            .streams(
                    fruits.map(this::toJson),
                    emitAPeriodicPing()
            );
}

Multi&lt;String&gt; emitAPeriodicPing() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(10))
            .onItem().transform(x -&gt; "{}");
}

private String toJson(Fruit f) {
    try {
        return mapper.writeValueAsString(f);
    } catch (JsonProcessingException e) {
        throw new RuntimeException(e);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>A solução alternativa é um pouco mais complexa, pois além de enviar os fruits provenientes do Kafka, precisamos enviar pings periodicamente. Para isso, mesclamos o fluxo proveniente do Kafka e um fluxo periódico que emite <code>{}</code> a cada 10 segundos.</p>
</div>
</div>
<div class="sect2">
<h3 id="chaining-kafka-transactions-with-hibernate-reactive-transactions"><a class="anchor" href="#chaining-kafka-transactions-with-hibernate-reactive-transactions"></a>24.7. Encadeando Transações do Kafka com transações Reativas do Hibernate</h3>
<div class="paragraph">
<p>Ao encadear uma transação do Kafka com uma transação reativa do Hibernate, é possível enviar registros para uma transação do Kafka, realizar atualizações do banco de dados e confirmar a transação do Kafka somente se a transação do banco de dados for bem-sucedida.</p>
</div>
<div class="paragraph">
<p>O exemplo a seguir demonstra isso:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Recebe um conteúdo servindo requisições HTTP utilizando o RESTEasy Reativo,</p>
</li>
<li>
<p>Limita a concorrência desse endpoint HTTP usando a Tolerância a Falhas do Smallrye,</p>
</li>
<li>
<p>Inicia uma transação Kafka e envia o conteúdo para o registro Kafka,</p>
</li>
<li>
<p>Armazenaoa conteúdo na base de dados utilizando Hibernate Reativo com Panache,</p>
</li>
<li>
<p>Confirma a transação Kafka apenas se a entidade for persistida com êxito.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.faulttolerance.Bulkhead;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.hibernate.reactive.mutiny.Mutiny;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@Path("/")
public class FruitProducer {

    @Channel("kafka") KafkaTransactions&lt;Fruit&gt; kafkaTx; <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    @Consumes(MediaType.APPLICATION_JSON)
    @Bulkhead(1) <i class="conum" data-value="2"></i><b>(2)</b>
    public Uni&lt;Void&gt; post(Fruit fruit) { <i class="conum" data-value="3"></i><b>(3)</b>
        return kafkaTx.withTransaction(emitter -&gt; { <i class="conum" data-value="4"></i><b>(4)</b>
            emitter.send(fruit); <i class="conum" data-value="5"></i><b>(5)</b>
            return Panache.withTransaction(() -&gt; { <i class="conum" data-value="6"></i><b>(6)</b>
                return fruit.&lt;Fruit&gt;persist(); <i class="conum" data-value="7"></i><b>(7)</b>
            });
        }).replaceWithVoid();
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Injeta um <code>KafkaTransactions</code> que expõe uma API do Mutiny. Isso permite a integração com a API do Mutiny exposta pelo Hibernate Reativo com Panache.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Limita a concorrência do endpoint HTTP a "1", impedindo o início de várias transações num determinado momento.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>O método HTTP que recebe o conteúdo devolve um <code>Uni&lt;Void&gt;</code>. A resposta HTTP é escrita quando a operação é concluída (a entidade é persistida e a transação Kafka é confirmada).</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Inicia uma transação Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Envia o contéudo para o Kafka dentro da transação Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Persiste a entidade na base de dados numa transação reativa do Hibernate.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Quando a operação de persistência for concluída e não houver erros, a transação do Kafka será confirmada. O resultado é omitido e retornado como resposta HTTP.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>No exemplo anterior, a transação do banco de dados (interna) será confirmada seguida pela transação do Kafka (externa). Se você quiser confirmar a transação do Kafka primeiro e a transação do banco de dados depois, precisará aninhá-las na ordem inversa.</p>
</div>
<div class="paragraph">
<p>O próximo exemplo demonstra isso utilizando a API reativa do Hibernate (sem o Panache):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.inject.Inject;
import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.faulttolerance.Bulkhead;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.hibernate.reactive.mutiny.Mutiny;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;
import io.vertx.mutiny.core.Context;
import io.vertx.mutiny.core.Vertx;

@Path("/")
public class FruitProducer {

    @Channel("kafka") KafkaTransactions&lt;Fruit&gt; kafkaTx;

    @Inject Mutiny.SessionFactory sf; <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    @Consumes(MediaType.APPLICATION_JSON)
    @Bulkhead(1)
    public Uni&lt;Void&gt; post(Fruit fruit) {
        Context context = Vertx.currentContext(); <i class="conum" data-value="2"></i><b>(2)</b>
        return sf.withTransaction(session -&gt; <i class="conum" data-value="3"></i><b>(3)</b>
                kafkaTx.withTransaction(emitter -&gt; <i class="conum" data-value="4"></i><b>(4)</b>
                        session.persist(fruit).invoke(() -&gt; emitter.send(fruit)) <i class="conum" data-value="5"></i><b>(5)</b>
                ).emitOn(context::runOnContext) <i class="conum" data-value="6"></i><b>(6)</b>
        );
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Injeta o <code>SessionFactory</code> do Hibernate Reativo.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Captura o contexto Vert.x do chamador.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Inicia uma transação Reativa do Hibernate.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Inicia uma transação Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Persiste o conteúdo e envia a entidade para o Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>A transação do Kafka é encerrada no thread do emissor produtor do Kafka. Precisamos mudar para o contexto Vert.x capturado anteriormente para encerrar a transação do Hibernate Reativo no mesmo contexto em que a iniciamos.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="logging"><a class="anchor" href="#logging"></a>25. Registrando</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Para reduzir a quantidade de registros escritos pelo cliente Kafka, o Quarkus define o nível das seguintes categorias de registros para <code>WARNING</code>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>org.apache.kafka.clients</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.utils</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.metrics</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>É possível substituir a configuração adicionando as seguintes linhas ao arquivo <code>application.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.log.category."org.apache.kafka.clients".level=INFO
quarkus.log.category."org.apache.kafka.common.utils".level=INFO
quarkus.log.category."org.apache.kafka.common.metrics".level=INFO</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="connecting-to-managed-kafka-clusters"><a class="anchor" href="#connecting-to-managed-kafka-clusters"></a>26. Conectando a clusters do Kafka Gerenciados</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Esta seção explica como conectar aos notórios Kafka Cloud Services.</p>
</div>
<div class="sect2">
<h3 id="azure-event-hub"><a class="anchor" href="#azure-event-hub"></a>26.1. Hubs de Eventos do Azure</h3>
<div class="paragraph">
<p><a href="https://learn.microsoft.com/pt-br/azure/event-hubs/azure-event-hubs-kafka-overview">O Hub de Eventos do Azure</a> fornece um endpoint compatível com o Apache Kafka.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Os Hubs de Eventos do Azure para Kafka não estão disponíveis na camada <em>básica</em>. Você precisa de pelo menos a camada <em>padrão</em> para usar o Kafka. Consulte <a href="https://azure.microsoft.com/pt-br/pricing/details/event-hubs/">Preços do Hubs de Eventos do Azure</a> para ver as outras opções.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Para se conectar ao Hub de Eventos do Azure, utilizando o protocolo Kafka com TLS, você precisa da seguinte configuração:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=my-event-hub.servicebus.windows.net:9093 <i class="conum" data-value="1"></i><b>(1)</b>
kafka.security.protocol=SASL_SSL
kafka.sasl.mechanism=PLAIN
kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \ <i class="conum" data-value="2"></i><b>(2)</b>
    username="$ConnectionString" \ <i class="conum" data-value="3"></i><b>(3)</b>
    password="&lt;YOUR.EVENTHUBS.CONNECTION.STRING&gt;"; <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>A porta é <code>9093</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Você precisa usar o JAAS <code>PlainLoginModule</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>O nome de usuário é a string <code>$ConnectionString</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>A cadeia de conexão do Hub de Eventos fornecida pelo Azure.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Substitua <code>&lt;YOUR.EVENTHUBS.CONNECTION.STRING&gt;</code> pela cadeia de conexão do seu namespace do Hub de Eventos. Para obter instruções sobre como obter a cadeia de conexão, consulte <a href="https://docs.microsoft.com/pt-br/azure/event-hubs/event-hubs-get-connection-string">Obter uma cadeia de conexão dos Hubs de Evento</a>. O resultado seria algo como:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
    username="$ConnectionString" \
    password="Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=XXXXXXXXXXXXXXXX";</code></pre>
</div>
</div>
<div class="paragraph">
<p>Esta configuração pode ser global (como acima), ou definida na configuração do canal:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.$channel.bootstrap.servers=my-event-hub.servicebus.windows.net:9093
mp.messaging.incoming.$channel.security.protocol=SASL_SSL
mp.messaging.incoming.$channel.sasl.mechanism=PLAIN
mp.messaging.incoming.$channel.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
    username="$ConnectionString" \
    password="Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=...";</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="red-hat-openshift-streams-for-apache-kafka"><a class="anchor" href="#red-hat-openshift-streams-for-apache-kafka"></a>26.2. Red Hat OpenShift Streams for Apache Kafka</h3>
<div class="paragraph">
<p><a href="https://cloud.redhat.com/">O Red Hat OpenShift Streams for Apache Kafka</a> fornece brokers Kafka gerenciados. Primeiro, siga as instruções de <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3">Getting started with the <code>rhoas</code> CLI for Red Hat OpenShift Streams for Apache Kafka</a> para criar sua instância de broker Kafka. Certifique-se de copiar o ID do cliente e o segredo do cliente associados à <em>ServiceAccount</em> que você criou.</p>
</div>
<div class="paragraph">
<p>Em seguida, pode configurar a aplicação Quarkus para se conectar ao broker da seguinte forma:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=&lt;connection url&gt; <i class="conum" data-value="1"></i><b>(1)</b>
kafka.security.protocol=SASL_SSL
kafka.sasl.mechanism=PLAIN
kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="${KAFKA_USERNAME}" \ <i class="conum" data-value="2"></i><b>(2)</b>
  password="${KAFKA_PASSWORD}"; <i class="conum" data-value="3"></i><b>(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>A cadeia de conexão, fornecida no console de administração, tal como <code>demo-c--​bjsv-ldd-cvavkc-a.bf2.kafka.rhcloud.com:443</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>O nome de usuário do kafka (o id do cliente da conta de serviço)</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>a senha do kafka (o segredo do cliente da conta de serviço)</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Em geral, estas propriedades são prefixadas com <code>%prod</code> para as ativar apenas quando são executadas em modo de produção.
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Conforme explicado em <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3">Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka</a>, para usar o Red Hat OpenShift Streams for Apache Kafka, você deve criar o tópico antecipadamente, criar uma <em>Service Account</em> e fornecer permissões para ler e escrever no seu tópico a partir dessa conta de serviço. Os dados de autenticação (ID do cliente e segredo) estão relacionados à conta de serviço, o que significa que você pode implementar permissões detalhadas e restringir o acesso ao tópico.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Ao utilizar o Kubernetes, recomenda-se que defina o ID do cliente e o segredo num segredo do Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: kafka-credentials
stringData:
  KAFKA_USERNAME: "..."
  KAFKA_PASSWORD: "..."</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para permitir que a sua aplicação Quarkus utilize esse segredo, adicione a seguinte linha ao arquivo <code>application.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.quarkus.openshift.env.secrets=kafka-credentials</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="red-hat-openshift-service-registry"><a class="anchor" href="#red-hat-openshift-service-registry"></a>26.2.1. Red Hat OpenShift Service Registry</h4>
<div class="paragraph">
<p>O <a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-service-registry">Red Hat OpenShift Service Registry</a> fornece um registro de serviço totalmente gerenciado para lidar com esquemas Kafka.</p>
</div>
<div class="paragraph">
<p>Você pode seguir as instruções de <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/ab1894d1-cae0-4d11-b185-81d62b4aabc7#_60472331-fa00-48ec-a621-bbd039500c7d">Introdução ao Red Hat OpenShift Service Registry</a> ou usar a CLI do <code>rhoas</code> para criar uma nova instância de registro de serviço:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rhoas service-registry create --name my-schema-registry</code></pre>
</div>
</div>
<div class="paragraph">
<p>Não se esqueça de anotar o <em>URL do Registro</em> da instância criada. Para autenticação, você pode usar a mesma <em>ServiceAccount</em> que criou anteriormente. É necessário certificar-se de que ela tenha as permissões necessárias para acessar o registro de serviço.</p>
</div>
<div class="paragraph">
<p>Por exemplo, usando a CLI <code>rhoas</code>, é possível conceder o papel <code>MANAGER</code> à conta de serviço:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rhoas service-registry role add --role manager --service-account [SERVICE_ACCOUNT_CLIENT_ID]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Em seguida, pode configurar a aplicação Quarkus para se conectar ao registro de esquemas da seguinte forma:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.connector.smallrye-kafka.apicurio.registry.url=${RHOAS_SERVICE_REGISTRY_URL} <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.service.token.endpoint=${RHOAS_OAUTH_TOKEN_ENDPOINT} <i class="conum" data-value="2"></i><b>(2)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.client.id=${RHOAS_CLIENT_ID} <i class="conum" data-value="3"></i><b>(3)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.client.secret=${RHOAS_CLIENT_ID} <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>A URL do registro de serviço, fornecida no console de administração, como <code><a href="https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2" class="bare">https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2</a></code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>O URL do endpoint de token OAuth, como <code><a href="https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token" class="bare">https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token</a></code></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>O ID do cliente (da conta de serviço)</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>O segredo do cliente (da conta de serviço)</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="binding-red-hat-openshift-managed-services-to-quarkus-application-using-the-service-binding-operator"><a class="anchor" href="#binding-red-hat-openshift-managed-services-to-quarkus-application-using-the-service-binding-operator"></a>26.2.2. Vinculando serviços gerenciados do Red Hat OpenShift a aplicação Quarkus usando o Operador de Vinculação de Serviço</h4>
<div class="paragraph">
<p>Se a sua aplicação Quarkus for implantada em um cluster Kubernetes ou OpenShift com o <a href="https://github.com/redhat-developer/service-binding-operator">Operador de Vinculação de Serviço</a> e os operadores do <a href="https://github.com/redhat-developer/app-services-operator/tree/main/docs">Serviços de Aplicação do OpenShift</a> instalados, as configurações necessárias para acessar o Red Hat OpenShift Streams for Apache Kafka e o Service Registry podem ser injetadas na aplicação usando a <a href="deploying-to-kubernetes#service_binding">Vinculação de Serviços do Kubernetes</a>.</p>
</div>
<div class="paragraph">
<p>Para configurar a Vinculação de Serviço, primeiro você precisa conectar os serviços gerenciados do OpenShift ao seu cluster. Para um cluster do OpenShift, você pode seguir as instruções de <a href="https://github.com/redhat-developer/app-services-guides/tree/main/docs/registry/service-binding-registry#connecting-a-kafka-and-service-registry-instance-to-your-openshift-cluster">Connecting a Kafka and Service Registry instance to your OpenShift cluster</a>.</p>
</div>
<div class="paragraph">
<p>Depois de conectar o seu cluster às instâncias do RHOAS Kafka e do Service Registry, certifique-se de que concedeu as permissões necessárias à conta de serviço recém-criada.</p>
</div>
<div class="paragraph">
<p>Em seguida, usando a extensão <a href="deploying-to-kubernetes#service_binding">Vinculação de Serviço Kubernetes</a>, você pode configurar a aplicação Quarkus para gerar recursos <code>ServiceBinding</code> para esses serviços:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kubernetes-service-binding.detect-binding-resources=true

quarkus.kubernetes-service-binding.services.kafka.api-version=rhoas.redhat.com/v1alpha1
quarkus.kubernetes-service-binding.services.kafka.kind=KafkaConnection
quarkus.kubernetes-service-binding.services.kafka.name=my-kafka

quarkus.kubernetes-service-binding.services.serviceregistry.api-version=rhoas.redhat.com/v1alpha1
quarkus.kubernetes-service-binding.services.serviceregistry.kind=ServiceRegistryConnection
quarkus.kubernetes-service-binding.services.serviceregistry.name=my-schema-registry</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para este exemplo, a compilação do Quarkus irá gerar os seguintes recursos <code>ServiceBinding</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: my-app-kafka
spec:
  application:
    group: apps.openshift.io
    name: my-app
    version: v1
    kind: DeploymentConfig
  services:
    - group: rhoas.redhat.com
      version: v1alpha1
      kind: KafkaConnection
      name: my-kafka
  detectBindingResources: true
  bindAsFiles: true
---
apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: my-app-serviceregistry
spec:
  application:
    group: apps.openshift.io
    name: my-app
    version: v1
    kind: DeploymentConfig
  services:
    - group: rhoas.redhat.com
      version: v1alpha1
      kind: ServiceRegistryConnection
      name: my-schema-registry
  detectBindingResources: true
  bindAsFiles: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Você pode seguir <a href="deploying-to-kubernetes#openshift">Implantando no OpenShift</a> para implantar sua aplicação, incluindo os recursos gerados do <code>ServiceBinding</code>. As propriedades de configuração necessárias para acessar as instâncias do Kafka e do Schema Registry serão injetadas na aplicação automaticamente durante a implantação.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="going-further"><a class="anchor" href="#going-further"></a>27. Indo mais longe</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Este guia mostrou como você pode interagir com o Kafka usando o Quarkus. Ele utiliza a Mensageria Reativa do SmallRye para criar aplicações de streaming de dados.</p>
</div>
<div class="paragraph">
<p>Se quiser ir mais longe, consulte a documentação da <a href="#https://smallrye.io/smallrye-reactive-messaging">Mensageria Reativa do SmallRye</a>, a implementação utilizada no Quarkus.</p>
</div>
</div>
</div>
        </div>
        <div class="grid__item width-4-12 width-12-12-m tocwrapper">
            <div class="hide-mobile toc"><ul class="sectlevel1">
<li><a href="#introduction">1. Introdução</a></li>
<li><a href="#quarkus-extension-for-apache-kafka">2. Extensão Quarkus para o Apache Kafka</a></li>
<li><a href="#configuring-smallrye-kafka-connector">3. Configurando o Conector Kafka Smallrye</a></li>
<li><a href="#receiving-messages-from-kafka">4. Recebendo mensagens do Kafka</a>
<ul class="sectlevel2">
<li><a href="#blocking-processing">4.1. Bloqueando o processamento</a></li>
<li><a href="#acknowledgment-strategies">4.2. Estratégias de Reconhecimento</a></li>
<li><a href="#commit-strategies">4.3. Estratégias de Confirmação</a></li>
<li><a href="#error-handling">4.4. Estratégias de Tratamento de Erros</a></li>
<li><a href="#consumer-groups">4.5. Grupos de Consumidores</a></li>
<li><a href="#receiving-kafka-records-in-batches">4.6. Recebendo Registros Kafka em Lotes</a></li>
<li><a href="#stateful-processing-with-checkpointing">4.7. Processamento com estado com Ponto de Verificação</a></li>
</ul>
</li>
<li><a href="#sending-messages-to-kafka">5. Enviando mensagens para o Kafka</a>
<ul class="sectlevel2">
<li><a href="#sending-messages-with-emitter">5.1. Enviando mensagens com @Emitter</a></li>
<li><a href="#write-acknowledgement">5.2. Escrever Reconhecimento</a></li>
<li><a href="#backpressure">5.3. Contrapressão</a></li>
<li><a href="#retrying-message-dispatch">5.4. Nova tentativa de envio de mensagens</a></li>
<li><a href="#handling-serialization-failures">5.5. Tratando Falhas de Serialização</a></li>
<li><a href="#in-memory-channels">5.6. Canais na memória</a></li>
<li><a href="#broadcasting-messages-on-multiple-consumers">5.7. Difusão de mensagens em vários consumidores</a></li>
<li><a href="#kafka-transactions">5.8. Transações Kafka</a></li>
</ul>
</li>
<li><a href="#processing-messages">6. Processando Mensagens</a>
<ul class="sectlevel2">
<li><a href="#propagating-record-key">6.1. Propagando a Chave de Registro</a></li>
<li><a href="#exactly-once-processing">6.2. Processamento Exactly-Once (Exatamente Único)</a></li>
</ul>
</li>
<li><a href="#kafka-bare-clients">7. Acessando clientes Kafka diretamente</a></li>
<li><a href="#kafka-serialization">8. Serialização JSON</a>
<ul class="sectlevel2">
<li><a href="#jackson-serialization">8.1. Serialização via Jackson</a></li>
<li><a href="#jsonb-serialization">8.2. Serialização via JSON-B</a></li>
</ul>
</li>
<li><a href="#avro-serialization">9. Serialização Avro</a></li>
<li><a href="#serialization-autodetection">10. Detecção automática de serializador/desserializador</a></li>
<li><a href="#serialization-generation">11. Geração de serializador/desserializador JSON</a></li>
<li><a href="#using-schema-registry">12. Usando Registro de Esquemas</a></li>
<li><a href="#kafka-health-check">13. Verificações de Integridade</a>
<ul class="sectlevel2">
<li><a href="#kafka-broker-readiness-check">13.1. Verificação de Prontidão do Broker Kafka</a></li>
<li><a href="#kafka-reactive-messaging-health-checks">13.2. Verificações de Integridade da Mensageria Reativa do Kafka</a></li>
</ul>
</li>
<li><a href="#kafka-streams">14. Fluxos Kafka</a></li>
<li><a href="#using-snappy-for-message-compression">15. Usando Snappy para compressão de mensagens</a></li>
<li><a href="#authentication-with-oauth">16. Autenticação com OAuth</a></li>
<li><a href="#testing-a-kafka-application">17. Testando uma aplicação Kafka</a>
<ul class="sectlevel2">
<li><a href="#testing-without-a-broker">17.1. Testando sem um broker</a></li>
<li><a href="#testing-using-a-kafka-broker">17.2. Testando usando um broker Kafka</a></li>
</ul>
</li>
<li><a href="#kafka-dev-services">18. Dev Services para o Kafka</a>
<ul class="sectlevel2">
<li><a href="#enabling-disabling-dev-services-for-kafka">18.1. Ativar/desativar Dev Services para o Kafka</a></li>
<li><a href="#shared-broker">18.2. broker compartilhado</a></li>
<li><a href="#setting-the-port">18.3. Definindo a porta</a></li>
<li><a href="#configuring-the-image">18.4. Configurando a imagem</a></li>
<li><a href="#configuring-kafka-topics">18.5. Configurando os tópicos no Kafka</a></li>
<li><a href="#redpanda-transactions">18.6. Suporte aos producers transacionais e idempotentes</a></li>
</ul>
</li>
<li><a href="#kafka-dev-ui">19. Kafka Dev UI</a></li>
<li><a href="#kubernetes-service-bindings">20. Vinculações de Serviços do Kubernetes</a></li>
<li><a href="#execution-model">21. Modelo de execução</a></li>
<li><a href="#channel-decorators">22. Decoradores de Canais</a></li>
<li><a href="#kafka-configuration">23. Referência de configuração</a>
<ul class="sectlevel2">
<li><a href="#incoming-channel-configuration-polling-from-kafka">23.1. Configuração do canal de entrada (sondagem a partir do Kafka)</a></li>
<li><a href="#outgoing-channel-configuration-writing-to-kafka">23.2. Configuração do canal de saída (escrevendo no Kafka)</a></li>
<li><a href="#kafka-configuration-resolution">23.3. Resolução de Configuração do Kafka</a></li>
</ul>
</li>
<li><a href="#integrating-with-kafka-common-patterns">24. Integrando com o Kafka - Padrões comuns</a>
<ul class="sectlevel2">
<li><a href="#writing-to-kafka-from-an-http-endpoint">24.1. Escrever no Kafka a partir de um endpoint HTTP</a></li>
<li><a href="#persisting-kafka-messages-with-hibernate-with-panache">24.2. Persistindo mensagens Kafka com o Hibernate com Panache</a></li>
<li><a href="#persisting-kafka-messages-with-hibernate-reactive">24.3. Persistência de mensagens Kafka com o Hibernate Reativo</a></li>
<li><a href="#writing-entities-managed-by-hibernate-to-kafka">24.4. Escrevendo entidades gerenciadas pelo Hibernate no Kafka</a></li>
<li><a href="#writing-entities-managed-by-hibernate-reactive-to-kafka">24.5. Escrevendo entidades gerenciadas pelo Hibernate Reativo no Kafka</a></li>
<li><a href="#streaming-kafka-topics-as-server-sent-events">24.6. Transmitindo tópicos do Kafka como eventos enviados pelo servidor</a></li>
<li><a href="#chaining-kafka-transactions-with-hibernate-reactive-transactions">24.7. Encadeando Transações do Kafka com transações Reativas do Hibernate</a></li>
</ul>
</li>
<li><a href="#logging">25. Registrando</a></li>
<li><a href="#connecting-to-managed-kafka-clusters">26. Conectando a clusters do Kafka Gerenciados</a>
<ul class="sectlevel2">
<li><a href="#azure-event-hub">26.1. Hubs de Eventos do Azure</a></li>
<li><a href="#red-hat-openshift-streams-for-apache-kafka">26.2. Red Hat OpenShift Streams for Apache Kafka</a></li>
</ul>
</li>
<li><a href="#going-further">27. Indo mais longe</a></li>
</ul></div>
        </div>
    </div>
    </div>

  </div>

  <div class="content project-footer">
  <div class="footer-section">
    <div class="logo-wrapper">
      <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_reverse.svg" class="project-logo" title="Quarkus"></a>
    </div>
  </div>
  <div class="grid-wrapper">
    <p class="grid__item width-3-12">Quarkus is open. All dependencies of this project are available under the <a href='https://www.apache.org/licenses/LICENSE-2.0' target='_blank'>Apache Software License 2.0</a> or compatible license. <i class='fab fa-creative-commons'></i><i class='fab fa-creative-commons-by'></i> <a href='https://creativecommons.org/licenses/by/3.0/' target='_blank'>CC by 3.0</a><br /><br />This website was built with <a href='https://jekyllrb.com/' target='_blank'>Jekyll</a>, is hosted on <a href='https://pages.github.com/' target='_blank'>GitHub Pages</a> and is completely open source. If you want to make it better, <a href='https://github.com/quarkusio/quarkusio.github.io' target='_blank'>fork the website</a> and show us what you’ve got.</p>

    
      <div class="width-1-12 project-links">
        <span>Navigation</span>
        <ul class="footer-links">
          
          
            <li><a href="/" target="_blank">Home</a></li>
          
          
          
            <li><a href="/about" target="_blank">About</a></li>
          
          
          
            <li><a href="/blog" target="_blank">Blog</a></li>
          
          
          
            <li><a href="/insights" target="_blank">Podcast</a></li>
          
          
          
            <li><a href="/events" target="_blank">Eventos</a></li>
          
          
          
            <li><a href="/newsletter" target="_blank">Newsletter</a></li>
          
          
          
            <li><a href="/userstories" target="_blank">User Stories</a></li>
          
          
          
            <li><a href="https://github.com/orgs/quarkusio/projects/13/views/1" target="_blank">Roadmap</a></li>
          
          
          
            <li><a href="/security" target="_blank">Security&nbsp;policy</a></li>
          
          
          
            <li><a href="/usage" target="_blank">Usage</a></li>
          
          
          
            <li><a href="https://github.com/commonhaus/artwork/tree/main/projects/quarkus" target="_blank">Brand</a></li>
          
          
          
            <li><a href="/desktopwallpapers" target="_blank">Wallpapers</a></li>
          
          
          
            <li><a href="https://www.redhat.com/en/about/privacy-policy" target="_blank">Privacy Policy</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Follow Us</span>
        <ul class="footer-links">
          
          
            <li><a href="https://x.com/quarkusio" target="_blank">X</a></li>
          
          
          
            <li><a href="https://bsky.app/profile/quarkus.io" target="_blank">Bluesky</a></li>
          
          
          
            <li><a rel="me" href="https://fosstodon.org/@quarkusio" target="_blank">Mastodon</a></li>
            
          
          
            <li><a href="https://www.threads.com/@quarkusio" target="_blank">Threads</a></li>
          
          
          
            <li><a href="https://www.facebook.com/quarkusio" target="_blank">Facebook</a></li>
          
          
          
            <li><a href="https://www.linkedin.com/company/quarkusio/" target="_blank">Linkedin</a></li>
          
          
          
            <li><a href="https://www.youtube.com/channel/UCaW8QG_QoIk_FnjLgr5eOqg" target="_blank">Youtube</a></li>
          
          
          
            <li><a href="https://github.com/quarkusio" target="_blank">GitHub</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-2-12 project-links">
        <span>Get Help</span>
        <ul class="footer-links">
          
          
            <li><a href="/support" target="_blank">Support</a></li>
          
          
          
            <li><a href="/guides" target="_blank">Guias</a></li>
          
          
          
            <li><a href="/faq" target="_blank">FAQ</a></li>
          
          
          
            <li><a href="/get-started" target="_blank">Get Started</a></li>
          
          
          
            <li><a href="https://stackoverflow.com/questions/tagged/quarkus" target="_blank">Stack Overflow</a></li>
          
          
          
            <li><a href="https://github.com/quarkusio/quarkus/discussions" target="_blank">Discussions</a></li>
          
          
          
            <li><a href="https://groups.google.com/forum/#!forum/quarkus-dev" target="_blank">Development mailing list</a></li>
          
          
          
            <li><a href="https://stats.uptimerobot.com/ze1PfweT2p" target="_blank">Quarkus Service Status</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Languages</span>
        <ul class="footer-links">
          
          
            <li><a href="https://quarkus.io/" target="_blank">English</a></li>
          
          
          
            <li><a href="https://pt.quarkus.io/" target="_blank">Português&nbsp;(Brasileiro)</a></li>
          
          
          
            <li><a href="https://es.quarkus.io/" target="_blank">Español</a></li>
          
          
          
            <li><a href="https://cn.quarkus.io/" target="_blank">简体中文</a></li>
          
          
          
            <li><a href="https://ja.quarkus.io/" target="_blank">日本語</a></li>
          
          
        </ul>
      </div>
    

    
      <div class="width-4-12 more-links">
        <span>Quarkus is made of community projects</span>
        <ul class="footer-links">
          
            <li><a blah href="https://vertx.io/" target="_blank">Eclipse Vert.x</a></li>
          
            <li><a blah href="https://smallrye.io" target="_blank">SmallRye</a></li>
          
            <li><a blah href="https://hibernate.org" target="_blank">Hibernate</a></li>
          
            <li><a blah href="https://netty.io" target="_blank">Netty</a></li>
          
            <li><a blah href="https://resteasy.github.io" target="_blank">RESTEasy</a></li>
          
            <li><a blah href="https://camel.apache.org" target="_blank">Apache Camel</a></li>
          
            <li><a blah href="https://microprofile.io" target="_blank">Eclipse MicroProfile</a></li>
          
            <li><a blah href="https://code.quarkus.io/" target="_blank">And many more...</a></li>
          
        </ul>
      </div>
    
  </div>
</div>

  <div class="content cf-footer">
  <div class="flexcontainer">
    <div class="cf-logo">
      <a class="cf-logo" href="https://www.commonhaus.org/" target="_blank"><img src="https://raw.githubusercontent.com/commonhaus/artwork/main/foundation/brand/svg/CF_logo_horizontal_single_reverse.svg"/></a>
    </div>
    <div class="license">
      Copyright © Quarkus. All rights reserved. For details on our trademarks, please visit our <a href="https://www.commonhaus.org/policies/trademark-policy/">Trademark Policy</a> and <a href="https://www.commonhaus.org/trademarks/">Trademark List</a>. Trademarks of third parties are owned by their respective holders and their mention here does not suggest any endorsement or association.
    </div>
  </div>
</div>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
  <script type="text/javascript" src="/assets/javascript/mobile-nav.js"></script>
  <script type="text/javascript" src="/assets/javascript/scroll-down.js"></script>
  <script src="/assets/javascript/satellite.js" type="text/javascript"></script>
  <script src="/guides/javascript/config.js" type="text/javascript"></script>
  <script src="/assets/javascript/guides-version-dropdown.js" type="text/javascript"></script>
  <script src="/assets/javascript/back-to-top.js" type="text/javascript"></script>
  <script src="/assets/javascript/clipboard.min.js" type="text/javascript"></script>
  <script src="/assets/javascript/copy.js" type="text/javascript"></script>
  <script src="/assets/javascript/asciidoc-tabs.js" type="text/javascript"></script>
  <script src="/assets/javascript/future-date.js" type="text/javascript"></script>
  <script src="/assets/javascript/randomize.js" type="text/javascript"></script>
  <script src="/assets/javascript/time.js" type="text/javascript"></script>
</body>

</html>
